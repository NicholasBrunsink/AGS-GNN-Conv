{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bffbb0c",
   "metadata": {},
   "source": [
    "# Test Dataset to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c466d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu count:  32\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "NUM_PROCESSORS=multiprocessing.cpu_count()\n",
    "print(\"Cpu count: \",NUM_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a053e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as it turned out interactive shell (like Jupyter cannot handle CPU multiprocessing well so check which medium the code is runing)\n",
    "#we will write code in Jupyter for understanding purposes but final execuation will be in shell\n",
    "from ipynb.fs.full.Utils import isnotebook\n",
    "from ipynb.fs.full.Dataset import get_data\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "import torch_geometric.utils.homophily as homophily\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e61e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_sparse import SparseTensor\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "\n",
    "import random\n",
    "random.seed(12345)\n",
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd4d70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from multiprocessing.pool import ThreadPool, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3684fa",
   "metadata": {},
   "source": [
    "## Ideal Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7d866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdealWeight():\n",
    "    \n",
    "    def __init__(self, data, log=True):\n",
    "        \n",
    "        self.N = N = data.num_nodes\n",
    "        self.E = E = data.num_edges\n",
    "        self.data = data\n",
    "        self.log =log\n",
    "\n",
    "        self.adj = SparseTensor(\n",
    "            row=data.edge_index[0], col=data.edge_index[1],\n",
    "            value=torch.arange(E, device=data.edge_index.device),\n",
    "            sparse_sizes=(N, N))\n",
    "        \n",
    "    def node_weight(self,u):\n",
    "    \n",
    "        row, col, edge_index = self.adj[u,:].coo()        \n",
    "        y_true = self.data.y[u]        \n",
    "        y_neighbor=self.data.y[col.tolist()]\n",
    "        \n",
    "        gains = (y_neighbor==y_true).int().tolist()        \n",
    "        S_G = [g if g >0 else 0.01 for g in gains]\n",
    "        S_edge=edge_index.tolist()\n",
    "            \n",
    "        return S_G, S_edge\n",
    "\n",
    "    def get_ideal_weight(self):\n",
    "        if self.log:\n",
    "            pbar = tqdm(total=self.N)\n",
    "            pbar.set_description(f'Nodes')\n",
    "\n",
    "        edge_weight=[]\n",
    "        edge_index=[]\n",
    "\n",
    "        for u in range(self.N):            \n",
    "            weight, e_index = self.node_weight(u)\n",
    "            edge_weight.extend(weight)\n",
    "            edge_index.extend(e_index)\n",
    "            if self.log:\n",
    "                pbar.update(1)\n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "        \n",
    "        assert len(edge_index)==self.E\n",
    "        \n",
    "        weight=torch.zeros(len(edge_index))        \n",
    "        weight[edge_index]=torch.Tensor(edge_weight)        \n",
    "\n",
    "        return weight\n",
    "    \n",
    "    def process_block(self, list_u):\n",
    "        \n",
    "        #print(\"Processing :\",len(list_u), list_u[0], list_u[-1])\n",
    "        \n",
    "        edge_weight = []\n",
    "        edge_index = []\n",
    "        \n",
    "        for u in list_u:        \n",
    "            weight, e_index = self.node_weight(u)            \n",
    "            edge_weight.extend(weight)\n",
    "            edge_index.extend(e_index)\n",
    "            \n",
    "        #print(\"Done :\",len(list_u), list_u[0], list_u[-1])\n",
    "            \n",
    "        return edge_weight, edge_index, len(list_u)\n",
    "    \n",
    "    #multiprocessing\n",
    "    def get_ideal_weight_multiproces(self):\n",
    "        \n",
    "        edge_weight=[]\n",
    "        edge_index=[]        \n",
    "        \n",
    "        N = self.N\n",
    "        #N = 1000\n",
    "        \n",
    "        #elem_size=1000\n",
    "        #num_blocks = int(N/elem_size)\n",
    "        num_blocks = NUM_PROCESSORS\n",
    "        elem_size = int(N/num_blocks)\n",
    "        \n",
    "        \n",
    "        nodes = np.arange(num_blocks*elem_size).reshape(num_blocks,-1).tolist()\n",
    "        \n",
    "        if num_blocks*elem_size<N:\n",
    "            nodes.append(list(range(num_blocks*elem_size,N)))        \n",
    "        \n",
    "        pool_size = NUM_PROCESSORS        \n",
    "        if self.log:\n",
    "            print(\"Pool Size: \", pool_size)        \n",
    "        pool = Pool(pool_size)\n",
    "        \n",
    "        if self.log:\n",
    "            pbar = tqdm(total=N)\n",
    "            pbar.set_description(f'Nodes')  \n",
    "                \n",
    "        for (weight, e_index, num_el) in pool.imap_unordered(self.process_block, nodes):            \n",
    "            edge_weight.extend(weight)\n",
    "            edge_index.extend(e_index)\n",
    "            \n",
    "            if self.log:\n",
    "                pbar.update(num_el)\n",
    "        \n",
    "        if self.log:\n",
    "            pbar.close()\n",
    "        \n",
    "        assert len(edge_index)==self.E        \n",
    "        \n",
    "        weight=torch.zeros(len(edge_index))        \n",
    "        weight[edge_index]=torch.Tensor(edge_weight)\n",
    "        \n",
    "        return weight\n",
    "    \n",
    "    \n",
    "    def compute_weights(self):   \n",
    "        #if isnotebook():\n",
    "        #weight = self.get_knn_weight()\n",
    "        \n",
    "        if self.data.num_nodes<10000:\n",
    "            weight = self.get_ideal_weight()    \n",
    "        else:\n",
    "            weight = self.get_ideal_weight_multiproces()\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbb922",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec49c506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory:  /scratch/gilbreth/das90/Dataset/\n",
      "Result directory: /scratch/gilbreth/das90/Dataset/RESULTS/\n",
      "\n",
      "Dataset: Genius(1):\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 12\n",
      "Number of classes: 2\n",
      "\n",
      "Data(x=[421961, 12], edge_index=[2, 984979], y=[421961], train_mask=[421961], val_mask=[421961], test_mask=[421961])\n",
      "===========================================================================================================\n",
      "Number of nodes: 421961\n",
      "Number of edges: 984979\n",
      "Average node degree: 2.33\n",
      "Number of training nodes: 253176\n",
      "Training node label rate: 0.60\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Pool Size:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 421961/421961 [00:04<00:00, 91556.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  4.990048170089722\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    \n",
    "    data, dataset = get_data('genius')\n",
    "    \n",
    "    ideal_weight = IdealWeight(data)\n",
    "\n",
    "    start = time.time()    \n",
    "    data.weight = ideal_weight.compute_weights()\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end-start)\n",
    "    \n",
    "#     if 'weight' in data:\n",
    "#         cp_data= copy.deepcopy(data)\n",
    "#         G = to_networkx(cp_data, to_undirected=True, edge_attrs=['weight'])\n",
    "#         to_remove = [(a,b) for a, b, attrs in G.edges(data=True) if attrs[\"weight\"] <1.0 ]\n",
    "#         G.remove_edges_from(to_remove)\n",
    "#         updated_data = from_networkx(G)\n",
    "\n",
    "#         print(\"Node Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='node'))\n",
    "#         print(\"Edge Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='edge'))\n",
    "#         print(\"Edge_insensitive Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='edge_insensitive'))    \n",
    "        \n",
    "    \n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd288dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
