{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd0c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Datasets introduced in the Geom-GCN paper.\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "from dgl.convert import graph\n",
    "from dgl.data.dgl_dataset import DGLBuiltinDataset\n",
    "from dgl.data.utils import _get_dgl_url\n",
    "\n",
    "\n",
    "class GeomGCNDataset(DGLBuiltinDataset):\n",
    "    r\"\"\"Datasets introduced in\n",
    "    `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Name of the dataset.\n",
    "    raw_dir : str\n",
    "        Raw file directory to store the processed data.\n",
    "    force_reload : bool\n",
    "        Whether to re-download the data source.\n",
    "    verbose : bool\n",
    "        Whether to print progress information.\n",
    "    transform : callable\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, raw_dir, force_reload, verbose, transform):\n",
    "        url = _get_dgl_url(f\"dataset/{name}.zip\")\n",
    "        super(GeomGCNDataset, self).__init__(\n",
    "            name=name,\n",
    "            url=url,\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Load and process the data.\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\n",
    "                \"This dataset requires PyTorch to be the backend.\"\n",
    "            )\n",
    "\n",
    "        # Process node features and labels.\n",
    "        with open(f\"{self.raw_path}/out1_node_feature_label.txt\", \"r\") as f:\n",
    "            data = f.read().split(\"\\n\")[1:-1]\n",
    "        features = [\n",
    "            [float(v) for v in r.split(\"\\t\")[1].split(\",\")] for r in data\n",
    "        ]\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        labels = [int(r.split(\"\\t\")[2]) for r in data]\n",
    "        self._num_classes = max(labels) + 1\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Process graph structure.\n",
    "        with open(f\"{self.raw_path}/out1_graph_edges.txt\", \"r\") as f:\n",
    "            data = f.read().split(\"\\n\")[1:-1]\n",
    "            data = [[int(v) for v in r.split(\"\\t\")] for r in data]\n",
    "        dst, src = torch.tensor(data, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        self._g = graph((src, dst), num_nodes=features.size(0))\n",
    "        self._g.ndata[\"feat\"] = features\n",
    "        self._g.ndata[\"label\"] = labels\n",
    "\n",
    "        # Process 10 train/val/test node splits.\n",
    "        train_masks, val_masks, test_masks = [], [], []\n",
    "        for i in range(10):\n",
    "            filepath = f\"{self.raw_path}/{self.name}_split_0.6_0.2_{i}.npz\"\n",
    "            f = np.load(filepath)\n",
    "            train_masks += [torch.from_numpy(f[\"train_mask\"])]\n",
    "            val_masks += [torch.from_numpy(f[\"val_mask\"])]\n",
    "            test_masks += [torch.from_numpy(f[\"test_mask\"])]\n",
    "        self._g.ndata[\"train_mask\"] = torch.stack(train_masks, dim=1).bool()\n",
    "        self._g.ndata[\"val_mask\"] = torch.stack(val_masks, dim=1).bool()\n",
    "        self._g.ndata[\"test_mask\"] = torch.stack(test_masks, dim=1).bool()\n",
    "\n",
    "    def has_cache(self):\n",
    "        return os.path.exists(self.raw_path)\n",
    "\n",
    "    def load(self):\n",
    "        self.process()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx == 0, \"This dataset has only one graph.\"\n",
    "        if self._transform is None:\n",
    "            return self._g\n",
    "        else:\n",
    "            return self._transform(self._g)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes\n",
    "\n",
    "\n",
    "class ChameleonDataset(GeomGCNDataset):\n",
    "    r\"\"\"Wikipedia page-page network on chameleons from `Multi-scale Attributed\n",
    "    Node Embedding <https://arxiv.org/abs/1909.13021>`__ and later modified by\n",
    "    `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Nodes represent articles from the English Wikipedia, edges reflect mutual\n",
    "    links between them. Node features indicate the presence of particular nouns\n",
    "    in the articles. The nodes were classified into 5 classes in terms of their\n",
    "    average monthly traffic.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 2277\n",
    "    - Edges: 36101\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 1092\n",
    "        - Val: 729\n",
    "        - Test: 456\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from dgl.data import ChameleonDataset\n",
    "    >>> dataset = ChameleonDataset()\n",
    "    >>> g = dataset[0]\n",
    "    >>> num_classes = dataset.num_classes\n",
    "\n",
    "    >>> # get node features\n",
    "    >>> feat = g.ndata[\"feat\"]\n",
    "\n",
    "    >>> # get data split\n",
    "    >>> train_mask = g.ndata[\"train_mask\"]\n",
    "    >>> val_mask = g.ndata[\"val_mask\"]\n",
    "    >>> test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    >>> # get labels\n",
    "    >>> label = g.ndata['label']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(ChameleonDataset, self).__init__(\n",
    "            name=\"chameleon\",\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SquirrelDataset(GeomGCNDataset):\n",
    "    r\"\"\"Wikipedia page-page network on squirrels from `Multi-scale Attributed\n",
    "    Node Embedding <https://arxiv.org/abs/1909.13021>`__ and later modified by\n",
    "    `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Nodes represent articles from the English Wikipedia, edges reflect mutual\n",
    "    links between them. Node features indicate the presence of particular nouns\n",
    "    in the articles. The nodes were classified into 5 classes in terms of their\n",
    "    average monthly traffic.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 5201\n",
    "    - Edges: 217073\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 2496\n",
    "        - Val: 1664\n",
    "        - Test: 1041\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from dgl.data import SquirrelDataset\n",
    "    >>> dataset = SquirrelDataset()\n",
    "    >>> g = dataset[0]\n",
    "    >>> num_classes = dataset.num_classes\n",
    "\n",
    "    >>> # get node features\n",
    "    >>> feat = g.ndata[\"feat\"]\n",
    "\n",
    "    >>> # get data split\n",
    "    >>> train_mask = g.ndata[\"train_mask\"]\n",
    "    >>> val_mask = g.ndata[\"val_mask\"]\n",
    "    >>> test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    >>> # get labels\n",
    "    >>> label = g.ndata['label']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(SquirrelDataset, self).__init__(\n",
    "            name=\"squirrel\",\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class CornellDataset(GeomGCNDataset):\n",
    "    r\"\"\"Cornell subset of\n",
    "    `WebKB <http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-11/www/wwkb/>`__,\n",
    "    later modified by `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Nodes represent web pages. Edges represent hyperlinks between them. Node\n",
    "    features are the bag-of-words representation of web pages. The web pages\n",
    "    are manually classified into the five categories, student, project, course,\n",
    "    staff, and faculty.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 183\n",
    "    - Edges: 298\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 87\n",
    "        - Val: 59\n",
    "        - Test: 37\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from dgl.data import CornellDataset\n",
    "    >>> dataset = CornellDataset()\n",
    "    >>> g = dataset[0]\n",
    "    >>> num_classes = dataset.num_classes\n",
    "\n",
    "    >>> # get node features\n",
    "    >>> feat = g.ndata[\"feat\"]\n",
    "\n",
    "    >>> # get data split\n",
    "    >>> train_mask = g.ndata[\"train_mask\"]\n",
    "    >>> val_mask = g.ndata[\"val_mask\"]\n",
    "    >>> test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    >>> # get labels\n",
    "    >>> label = g.ndata['label']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(CornellDataset, self).__init__(\n",
    "            name=\"cornell\",\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TexasDataset(GeomGCNDataset):\n",
    "    r\"\"\"Texas subset of\n",
    "    `WebKB <http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-11/www/wwkb/>`__,\n",
    "    later modified by `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Nodes represent web pages. Edges represent hyperlinks between them. Node\n",
    "    features are the bag-of-words representation of web pages. The web pages\n",
    "    are manually classified into the five categories, student, project, course,\n",
    "    staff, and faculty.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 183\n",
    "    - Edges: 325\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 87\n",
    "        - Val: 59\n",
    "        - Test: 37\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from dgl.data import TexasDataset\n",
    "    >>> dataset = TexasDataset()\n",
    "    >>> g = dataset[0]\n",
    "    >>> num_classes = dataset.num_classes\n",
    "\n",
    "    >>> # get node features\n",
    "    >>> feat = g.ndata[\"feat\"]\n",
    "\n",
    "    >>> # get data split\n",
    "    >>> train_mask = g.ndata[\"train_mask\"]\n",
    "    >>> val_mask = g.ndata[\"val_mask\"]\n",
    "    >>> test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    >>> # get labels\n",
    "    >>> label = g.ndata['label']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(TexasDataset, self).__init__(\n",
    "            name=\"texas\",\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class WisconsinDataset(GeomGCNDataset):\n",
    "    r\"\"\"Wisconsin subset of\n",
    "    `WebKB <http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-11/www/wwkb/>`__,\n",
    "    later modified by `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`__\n",
    "\n",
    "    Nodes represent web pages. Edges represent hyperlinks between them. Node\n",
    "    features are the bag-of-words representation of web pages. The web pages\n",
    "    are manually classified into the five categories, student, project, course,\n",
    "    staff, and faculty.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 251\n",
    "    - Edges: 515\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 120\n",
    "        - Val: 80\n",
    "        - Test: 51\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from dgl.data import WisconsinDataset\n",
    "    >>> dataset = WisconsinDataset()\n",
    "    >>> g = dataset[0]\n",
    "    >>> num_classes = dataset.num_classes\n",
    "\n",
    "    >>> # get node features\n",
    "    >>> feat = g.ndata[\"feat\"]\n",
    "\n",
    "    >>> # get data split\n",
    "    >>> train_mask = g.ndata[\"train_mask\"]\n",
    "    >>> val_mask = g.ndata[\"val_mask\"]\n",
    "    >>> test_mask = g.ndata[\"test_mask\"]\n",
    "\n",
    "    >>> # get labels\n",
    "    >>> label = g.ndata['label']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(WisconsinDataset, self).__init__(\n",
    "            name=\"wisconsin\",\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead562b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    import DeviceDir\n",
    "    \n",
    "    DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "    device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "    \n",
    "    dataset = ChameleonDataset(raw_dir = DIR)\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
