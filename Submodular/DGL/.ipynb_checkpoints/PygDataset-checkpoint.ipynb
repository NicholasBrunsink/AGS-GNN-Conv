{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ffef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "kernel_name = os.path.basename(sys.executable.replace(\"/bin/python\",\"\"))\n",
    "\n",
    "if kernel_name == 'py38cu11':\n",
    "    import ctypes\n",
    "    ctypes.cdll.LoadLibrary(\"/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64/libcusparse.so.11\");\n",
    "    ctypes.cdll.LoadLibrary(\"/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64/libcublas.so.11\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4b641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.datasets import Reddit, Reddit2, Flickr, Yelp, AmazonProducts, PPI,  OGB_MAG,  FakeDataset, Amazon, Coauthor\n",
    "\n",
    "#import ipynb.fs.full.utils.MoonGraph as MoonGraph\n",
    "# import utils.MoonGraph as MoonGraph\n",
    "import torch_geometric.utils.homophily as homophily\n",
    "import torch_geometric.utils.subgraph as subgraph\n",
    "\n",
    "#import torch_geometric.utils.assortativity as assortativity #pytorch geometric's latest version has this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c20145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gamma, uniform, expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e02fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj, SparseTensor\n",
    "from torch_geometric.utils import coalesce, degree\n",
    "from torch_geometric.utils.to_dense_adj import to_dense_adj\n",
    "\n",
    "\n",
    "def assortativity(edge_index: Adj) -> float:\n",
    "    if isinstance(edge_index, SparseTensor):\n",
    "        adj: SparseTensor = edge_index\n",
    "        row, col, _ = adj.coo()\n",
    "    else:\n",
    "        assert isinstance(edge_index, Tensor)\n",
    "        row, col = edge_index\n",
    "\n",
    "    device = row.device\n",
    "    out_deg = degree(row, dtype=torch.long)\n",
    "    in_deg = degree(col, dtype=torch.long)\n",
    "    degrees = torch.unique(torch.cat([out_deg, in_deg]))\n",
    "    mapping = row.new_zeros(degrees.max().item() + 1)\n",
    "    mapping[degrees] = torch.arange(degrees.size(0), device=device)\n",
    "\n",
    "    # Compute degree mixing matrix (joint probability distribution) `M`\n",
    "    num_degrees = degrees.size(0)\n",
    "    src_deg = mapping[out_deg[row]]\n",
    "    dst_deg = mapping[in_deg[col]]\n",
    "\n",
    "    pairs = torch.stack([src_deg, dst_deg], dim=0)\n",
    "    occurrence = torch.ones(pairs.size(1), device=device)\n",
    "    pairs, occurrence = coalesce(pairs, occurrence)\n",
    "    M = to_dense_adj(pairs, edge_attr=occurrence, max_num_nodes=num_degrees)[0]\n",
    "    # normalization\n",
    "    M /= M.sum()\n",
    "\n",
    "    # numeric assortativity coefficient, computed by\n",
    "    # Pearson correlation coefficient of the node degrees\n",
    "    x = y = degrees.float()\n",
    "    a, b = M.sum(0), M.sum(1)\n",
    "\n",
    "    vara = (a * x**2).sum() - ((a * x).sum())**2\n",
    "    varb = (b * x**2).sum() - ((b * x).sum())**2\n",
    "    xy = torch.outer(x, y)\n",
    "    ab = torch.outer(a, b)\n",
    "    out = (xy * (M - ab)).sum() / (vara * varb).sqrt()\n",
    "    return out.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6c6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/SitaoLuan/ACM-GNN/tree/main/synthetic-experiments\n",
    "#https://github.com/siddhartha047/Geom_GCN_pytorch_implementation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def func(feature):\n",
    "\n",
    "    f = list(map(int, feature.split(',')))\n",
    "    \n",
    "    return f\n",
    "\n",
    "def get_heterophily(root, DATASET_NAME='texas', train=0.6, val=0.2, test=0.2):\n",
    "    \n",
    "    edge_file = root+'/'+DATASET_NAME+'/out1_graph_edges.txt'\n",
    "    id_feature_label_file = root+'/'+DATASET_NAME+'/out1_node_feature_label.txt'\n",
    "    \n",
    "    edges = pd.read_csv(edge_file, sep='\\t', header=0)\n",
    "    id_feature_label = pd.read_csv(id_feature_label_file, sep='\\t', header=0)\n",
    "    \n",
    "#     print(edges)\n",
    "#     print(id_feature_label)\n",
    "    \n",
    "    edge_index = torch.LongTensor(edges.values.tolist()).T\n",
    "    node_id  = torch.LongTensor(id_feature_label['node_id'].values.tolist())\n",
    "    y = torch.LongTensor(id_feature_label['label'].values.tolist())\n",
    "    x = id_feature_label['feature'].apply(func)\n",
    "    x = torch.Tensor(x.values.tolist())\n",
    "    \n",
    "    N = len(node_id)\n",
    "    indexs = list(range(N))\n",
    "    \n",
    "    train_index, test_index = train_test_split(indexs, test_size=val+test, random_state=1)\n",
    "    val_index, test_index = train_test_split(test_index, test_size=test/(val+test), random_state=1)\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=bool)\n",
    "    train_mask[train_index]=True    \n",
    "    val_mask = torch.zeros(N, dtype=bool)\n",
    "    val_mask[val_index]=True\n",
    "    test_mask = torch.zeros(N, dtype=bool)\n",
    "    test_mask[test_index]=True\n",
    "\n",
    "    \n",
    "    data = Data(edge_index=edge_index, \n",
    "                x=x, node_id=node_id, \n",
    "                y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#get_heterophily('/scratch/gilbreth/das90/Dataset/heterophily/','squirrel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd02868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_film(root, DATASET_NAME='film', train=0.6, val=0.2, test=0.2):\n",
    "    \n",
    "    file = root+DATASET_NAME+'/'    \n",
    "    f = open(file+'class_map.json')\n",
    "    class_map = json.load(f)\n",
    "    class_map = {int(key):int(value) for key, value in class_map.items()}\n",
    "    #print(class_map)\n",
    "    f.close()    \n",
    "    \n",
    "    y = list(class_map.values())\n",
    "    x = np.load(file+'feats.npy')    \n",
    "    #print(x.shape)\n",
    "    \n",
    "#     f = open(file+'id_map.json')\n",
    "#     id_map = json.load(f)\n",
    "#     id_map = {int(key):int(value) for key, value in id_map.items()}    \n",
    "#     #print(id_map)\n",
    "#     f.close()\n",
    "    \n",
    "    #target = pd.read_csv(file+'film_target.csv', sep=',', header=0)\n",
    "    #print(target)\n",
    "    #target['new_id']=target['id'].apply(lambda x: id_map[x])\n",
    "    \n",
    "    \n",
    "    edges = pd.read_csv(file+'film_edges.csv', sep=',', header=0)\n",
    "    \n",
    "    u = edges['id1'].values.tolist()\n",
    "    v = edges['id2'].values.tolist()\n",
    "    \n",
    "    edge_index=[u,v]\n",
    "    \n",
    "    x = torch.Tensor(x)\n",
    "    y = torch.LongTensor(y)\n",
    "    edge_index = torch.LongTensor(edge_index)\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    indexs = list(range(N))\n",
    "    train_index, test_index = train_test_split(indexs, test_size=val+test, random_state=1)\n",
    "    val_index, test_index = train_test_split(test_index, test_size=test/(val+test), random_state=1)\n",
    "\n",
    "#     train_index, test_index = train_test_split(indexs, test_size=val+test)\n",
    "#     val_index, test_index = train_test_split(test_index, test_size=test/(val+test))\n",
    "    \n",
    "    train_mask = torch.zeros(N, dtype=bool)\n",
    "    train_mask[train_index]=True    \n",
    "    val_mask = torch.zeros(N, dtype=bool)\n",
    "    val_mask[val_index]=True\n",
    "    test_mask = torch.zeros(N, dtype=bool)\n",
    "    test_mask[test_index]=True\n",
    "\n",
    "    \n",
    "    data = Data(edge_index=edge_index, \n",
    "                x=x,\n",
    "                y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#get_film('/scratch/gilbreth/das90/Dataset/heterophily/','film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c29260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroDataset(Dataset):\n",
    "    def __init__(self, root, dataset_name, train=0.6, val=0.2, test=0.2,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.root = root\n",
    "        self.dataset_name=dataset_name\n",
    "        self.degree=degree\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.test=test\n",
    "        \n",
    "        if dataset_name == 'film':\n",
    "            self.data = get_film(root,dataset_name, train, val, test)\n",
    "        else:\n",
    "            self.data = get_heterophily(root,dataset_name, train, val, test)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return self.dataset_name\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return self.root\n",
    "\n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return self.data.x.shape[1]\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return max(self.data.y).item()+1\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "# dataset = HeteroDataset('/scratch/gilbreth/das90/Dataset/heterophily/','texas')\n",
    "# data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c51d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_mask(data, train=0.6, val=0.2, test=0.2, random_state=False):\n",
    "    \n",
    "    N = data.x.shape[0]\n",
    "    indexs = list(range(N))\n",
    "    \n",
    "    if random_state:\n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test))\n",
    "    else:        \n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test, random_state=1)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test), random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=bool)\n",
    "    train_mask[train_index]=True    \n",
    "    val_mask = torch.zeros(N, dtype=bool)\n",
    "    val_mask[val_index]=True\n",
    "    test_mask = torch.zeros(N, dtype=bool)\n",
    "    test_mask[test_index]=True\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2767bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(DATASET_NAME='Cora', DIR=None, params=None, train=None, random_state=False, log=True, h_score=False, split_no=0):\n",
    "    \n",
    "    if DIR is not None:\n",
    "        print('Looking at: ',DIR)    \n",
    "    elif os.uname()[1].find('gilbreth')==0: ##if not darwin(mac/locallaptop)\n",
    "        DIR='/scratch/gilbreth/das90/Dataset/'\n",
    "    elif os.uname()[1].find('unimodular')==0:\n",
    "        DIR='/scratch2/das90/Dataset/'\n",
    "    elif os.uname()[1].find('Siddharthas')==0:\n",
    "        DIR='/Users/siddharthashankardas/Purdue/Dataset/'  \n",
    "    else:\n",
    "        DIR='./Dataset/'\n",
    "\n",
    "    Path(DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    RESULTS_DIR=DIR+'RESULTS/'\n",
    "    Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if log:\n",
    "        print(\"Data directory: \", DIR)\n",
    "        print(\"Result directory:\", RESULTS_DIR)\n",
    "    \n",
    "    from torch_geometric.datasets import Planetoid,  KarateClub, CitationFull\n",
    "    from torch_geometric.transforms import NormalizeFeatures\n",
    "    from torch_geometric.datasets import Reddit, Reddit2\n",
    "    \n",
    "    #DATASET_NAME='Cora' #\"Cora\", \"CiteSeer\", \"PubMed\"\n",
    "\n",
    "    if DATASET_NAME in [\"Cora\", \"CiteSeer\", \"PubMed\"]:\n",
    "        dataset = Planetoid(root=DIR+'Planetoid', name=DATASET_NAME, transform=NormalizeFeatures())\n",
    "    \n",
    "    elif DATASET_NAME in ['cora', 'cora_ml', 'citeseer', 'dblp', 'pubmed']:\n",
    "        #['cora', 'cora_ml', 'citeseer', 'dblp', 'pubmed']\n",
    "        dataset = CitationFull(root=DIR+'Citation', name=DATASET_NAME, transform=NormalizeFeatures())\n",
    "    \n",
    "    elif DATASET_NAME == \"Reddit2\":\n",
    "        #dataset = Reddit2(root=DIR+'Reddit2', transform=NormalizeFeatures())\n",
    "        dataset = Reddit2(root=DIR+'Reddit2')\n",
    "\n",
    "    elif DATASET_NAME == \"Reddit\":\n",
    "        #dataset = Reddit(root=DIR+'Reddit', transform=NormalizeFeatures())\n",
    "        dataset = Reddit(root=DIR+'Reddit')\n",
    "        \n",
    "    elif DATASET_NAME == \"AmazonProducts\":\n",
    "        #dataset = AmazonProducts(root=DIR+'AmazonProducts', transform=NormalizeFeatures())\n",
    "        dataset = AmazonProducts(root=DIR+'AmazonProducts')\n",
    "        \n",
    "    elif DATASET_NAME in ['Computers', 'Photo']:\n",
    "        #dataset = Amazon(root=DIR+'AmazonProducts', transform=NormalizeFeatures())\n",
    "        dataset = Amazon(root=DIR+'Amazon/', name = DATASET_NAME)        \n",
    "        \n",
    "\n",
    "    elif DATASET_NAME in ['CS', 'Physics']:\n",
    "        dataset = Coauthor(root=DIR+'Coauthor/', name = DATASET_NAME)        \n",
    "\n",
    "        \n",
    "    elif DATASET_NAME == \"Moon\":\n",
    "        dataset = MoonGraph.MoonDataset(n_samples=100, degree=5, train=0.5)    \n",
    "        G, data =dataset[0]\n",
    "    \n",
    "    elif DATASET_NAME == \"karate\":\n",
    "        dataset = KarateClub()        \n",
    "        data = dataset[0]\n",
    "        data.val_mask = ~data.train_mask\n",
    "        data.test_mask = data.val_mask\n",
    "    \n",
    "    elif DATASET_NAME == \"Fake\":\n",
    "        dataset = FakeDataset(num_graphs = 1, \n",
    "                              avg_num_nodes = 2000, \n",
    "                              avg_degree = 10, \n",
    "                              num_channels = 64, \n",
    "                              edge_dim = 0, \n",
    "                              num_classes = 10, \n",
    "                              task = 'auto', \n",
    "                              is_undirected = True,                               \n",
    "                              transform=NormalizeFeatures())\n",
    "        \n",
    "    elif DATASET_NAME == \"OGB_MAG\":\n",
    "        #dataset = OGB_MAG(root=DIR+'OGB_MAG', preprocess='metapath2vec', transform=NormalizeFeatures())\n",
    "        dataset = OGB_MAG(root=DIR+'OGB_MAG2', preprocess='metapath2vec')\n",
    "        data = dataset[0]        \n",
    "        print(dataset, data, data['paper'])\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    elif DATASET_NAME == \"Flickr\":\n",
    "        dataset = Flickr(root=DIR+'Flickr')\n",
    "    \n",
    "    elif DATASET_NAME == \"Yelp\":\n",
    "        dataset = Yelp(root=DIR+'Yelp')\n",
    "    \n",
    "    elif DATASET_NAME == \"PPI\":\n",
    "        \n",
    "        dataset = PPI(root=DIR+'PPI')\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    ###heterophilic dataset\n",
    "    #https://github.com/pyg-team/pytorch_geometric/blob/master/examples/linkx.py\n",
    "    elif DATASET_NAME in [\"penn94\", \"reed98\", \"amherst41\", \"cornell5\", \"johnshopkins55\", \"genius\"]:\n",
    "        from ipynb.fs.full.HeterophilousDataset import LINKXDataset\n",
    "        \n",
    "        dataset = LINKXDataset(DIR+'/Heterophilous/', DATASET_NAME)    \n",
    "        #transform=NormalizeFeatures())\n",
    "        \n",
    "    elif DATASET_NAME in [\"Roman-empire\", \"Amazon-ratings\", \"Minesweeper\", \"Tolokers\", \"Questions\"]:\n",
    "        from ipynb.fs.full.HeterophilousDataset import HeterophilousGraphDataset\n",
    "        \n",
    "        dataset = HeterophilousGraphDataset(DIR+'/Heterophilous/', DATASET_NAME)    \n",
    "        #transform=NormalizeFeatures())\n",
    "    elif DATASET_NAME == 'Actor':\n",
    "        from ipynb.fs.full.HeterophilousDataset import Actor\n",
    "        \n",
    "        dataset = Actor(root=DIR+'/Heterophilous/Actor')\n",
    "        #transform=NormalizeFeatures())\n",
    "    \n",
    "    elif DATASET_NAME in [\"Cornell\", \"Texas\", \"Wisconsin\"]:\n",
    "        from ipynb.fs.full.HeterophilousDataset import WebKB\n",
    "        \n",
    "        dataset = WebKB(DIR+'/Heterophilous/', DATASET_NAME)\n",
    "        #transform=NormalizeFeatures())\n",
    "        \n",
    "    elif DATASET_NAME in [\"Chameleon\", \"Crocodile\", \"Squirrel\"]:\n",
    "        from ipynb.fs.full.HeterophilousDataset import WikipediaNetwork\n",
    "        \n",
    "        if DATASET_NAME == 'Crocodile':\n",
    "            dataset = WikipediaNetwork(DIR+'/Heterophilous/', DATASET_NAME.lower(), geom_gcn_preprocess= False)\n",
    "        else:        \n",
    "            dataset = WikipediaNetwork(DIR+'/Heterophilous/', DATASET_NAME.lower())\n",
    "            #transform=NormalizeFeatures())\n",
    "    \n",
    "    #implemented heterophily\n",
    "    elif DATASET_NAME in ['chameleon','cornell','film', 'squirrel', 'texas','wisconsin']:\n",
    "        dataset = HeteroDataset(DIR+'/heterophily/', DATASET_NAME)       \n",
    "    \n",
    "    else:    \n",
    "        raise Exception('dataset not found')\n",
    "\n",
    "    if DATASET_NAME in ['Moon', 'karate']:\n",
    "        #MoonGraph.draw_blobs_data(G, data)        \n",
    "        None\n",
    "    else:\n",
    "        data = dataset[0]  # Get the first graph object.\n",
    "        if 'train_mask' not in data:\n",
    "            data = train_val_test_mask(data, train=0.6, val=0.2, test=0.2, random_state=random_state)\n",
    "            \n",
    "        elif data.train_mask.dim()>1:\n",
    "            data.train_mask = data.train_mask[:,split_no]\n",
    "            data.val_mask = data.val_mask[:,split_no]\n",
    "            data.test_mask = data.test_mask[:,split_no]\n",
    "            \n",
    "        \n",
    "    if train is not None:\n",
    "        val = (1-train)/2.0\n",
    "        data = train_val_test_mask(data, train=train, val=val, test=1-(train+val), random_state=random_state)\n",
    "        \n",
    "    if log:\n",
    "        print()\n",
    "        print(f'Dataset: {dataset}:')\n",
    "        print('======================')\n",
    "        print(f'Number of graphs: {len(dataset)}')\n",
    "        print(f'Number of features: {dataset.num_features}')\n",
    "        print(f'Number of classes: {dataset.num_classes}')\n",
    "        print()\n",
    "        print(data)\n",
    "        print('===========================================================================================================')\n",
    "\n",
    "        # Gather some statistics about the graph.\n",
    "        print(f'Number of nodes: {data.num_nodes}')\n",
    "        print(f'Number of edges: {data.num_edges}')\n",
    "        print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "        print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "        print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "        print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "        print(f'Has self-loops: {data.has_self_loops()}')\n",
    "        print(f'Is undirected: {data.is_undirected()}')\n",
    "    \n",
    "    if len(data.y.shape) == 1:\n",
    "        labels = data.y\n",
    "    else:\n",
    "        if log: print(\"Testing homophily by converting multi-label to one-label\")\n",
    "        labels = data.y.argmax(dim=1)\n",
    "    \n",
    "    if h_score:\n",
    "        print(homophily(data.edge_index, labels, method='node'),homophily(data.edge_index, labels, method='edge'), end=' ')\n",
    "        \n",
    "        try:\n",
    "            esen = homophily(data.edge_index, labels, method='edge_insensitive')\n",
    "        except:\n",
    "            esen = -1        \n",
    "        print(esen, end=' ')            \n",
    "        print(assortativity(data.edge_index))\n",
    "        \n",
    "    \n",
    "    return data, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da8603c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'karate','Moon','Fake',\n",
    "    \"Cora\", \"CiteSeer\", \"PubMed\",'cora', 'cora_ml', 'citeseer', 'dblp', 'pubmed',\n",
    "    'chameleon','cornell','film', 'squirrel', 'texas','wisconsin',\n",
    "    'Computers', 'Photo',\n",
    "    'CS', 'Physics',\n",
    "    'Flickr','Yelp',\n",
    "    \"penn94\", \"reed98\", \"amherst41\", \"cornell5\", \"johnshopkins55\", \"genius\",\n",
    "    \"Roman-empire\", \"Amazon-ratings\", \"Minesweeper\", \"Tolokers\", \"Questions\",\n",
    "    \"Actor\", \n",
    "    \"Cornell\", \"Texas\", \"Wisconsin\", \n",
    "    \"Chameleon\", \"Squirrel\", #\"Crocodile\",\n",
    "    'Reddit',\n",
    "    'Reddit2',\n",
    "    'AmazonProducts' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd8f096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory:  /scratch/gilbreth/das90/Dataset/\n",
      "Result directory: /scratch/gilbreth/das90/Dataset/RESULTS/\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A10\n",
      "cuda\n",
      "Cpu count:  32\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'DataEdgeAttr' on <module 'torch_geometric.data.data' from '/home/das90/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/torch_geometric/data/data.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:   \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     data, dataset = get_data('karate', log=True, h_score = True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     print(sum(torch.where(data.train_mask==True)))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     data, dataset = get_data('Cora', train=0.2, random_state=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     print(sum(torch.where(data.train_mask==True)))\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     data, dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWisconsin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(DATASET_NAME, DIR, params, train, random_state, log, h_score, split_no)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m DATASET_NAME \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCornell\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWisconsin\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfull\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHeterophilousDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebKB\n\u001b[0;32m--> 120\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mWebKB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIR\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Heterophilous/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET_NAME\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m#transform=NormalizeFeatures())\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m DATASET_NAME \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChameleon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrocodile\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSquirrel\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/GNNcodes/CVE2020/GNN-NC/Graph-Sparsification/Submodular/DGL/HeterophilousDataset.ipynb:585\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, root, name, transform, pre_transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m220c565f\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m      8\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      9\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport DeviceDir\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIR, RESULTS_DIR = DeviceDir.get_directory()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice, NUM_PROCESSORS = DeviceDir.get_device()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m    ]\n\u001b[1;32m     15\u001b[0m   },\n\u001b[1;32m     16\u001b[0m   {\n\u001b[1;32m     17\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     19\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4ce76277\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     21\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     22\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom typing import Optional\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch import Tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef one_hot(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    index: Tensor,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_classes: Optional[int] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dtype: Optional[torch.dtype] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) -> Tensor:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTaskes a one-dimensional :obj:`index` tensor and returns a one-hot\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoded representation of it with shape :obj:`[*, num_classes]` that has\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    zeros everywhere except where the index of last dimension matches the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    corresponding value of the input tensor, in which case it will be :obj:`1`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    .. note::\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        This is a more memory-efficient version of\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :meth:`torch.nn.functional.one_hot` as you can customize the output\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :obj:`dtype`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        index (torch.Tensor): The one-dimensional input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_classes (int, optional): The total number of classes. If set to\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`None`, the number of classes will be inferred as one greater\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            than the largest class value in the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dtype (torch.dtype, optional): The :obj:`dtype` of the output tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if index.dim() != 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        raise ValueError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m tensor needs to be one-dimensional\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if num_classes is None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_classes = int(index.max()) + 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    out = torch.zeros((index.size(0), num_classes), dtype=dtype,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                      device=index.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return out.scatter_(1, index.unsqueeze(1), 1)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m    ]\n\u001b[1;32m     62\u001b[0m   },\n\u001b[1;32m     63\u001b[0m   {\n\u001b[1;32m     64\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     66\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m08e2295e\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     68\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     69\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os.path as osp\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport ssl\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport sys\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport urllib\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom typing import Optional\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.data.makedirs import makedirs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef download_url(url: str, folder: str, log: bool = True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 filename: Optional[str] = None):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDownloads the content of an URL to a specific folder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        url (str): The URL.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        folder (str): The folder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        log (bool, optional): If :obj:`False`, will not print anything to the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            console. (default: :obj:`True`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if filename is None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        filename = url.rpartition(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[2]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        filename = filename if filename[0] == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m else filename.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    path = osp.join(folder, filename)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if osp.exists(path):  # pragma: no cover\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if log and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not in sys.modules:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing existing file \u001b[39m\u001b[38;5;132;01m{filename}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, file=sys.stderr)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return path\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if log and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not in sys.modules:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, file=sys.stderr)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    makedirs(folder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    context = ssl._create_unverified_context()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    data = urllib.request.urlopen(url, context=context)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with open(path, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # workaround for https://bugs.python.org/issue42853\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        while True:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            chunk = data.read(10 * 1024 * 1024)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if not chunk:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                break\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            f.write(chunk)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return path\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m    ]\n\u001b[1;32m    119\u001b[0m   },\n\u001b[1;32m    120\u001b[0m   {\n\u001b[1;32m    121\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m    123\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9b7b200d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    125\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    126\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os.path as osp\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom typing import Callable, List, Optional\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.data import Data, InMemoryDataset #download_url\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#from torch_geometric.utils import one_hot\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass LINKXDataset(InMemoryDataset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mA variety of non-homophilous graph datasets from the `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mLarge Scale\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m <https://arxiv.org/abs/2110.14446>`_ paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    .. note::\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Some of the datasets provided in :class:`LINKXDataset` are from other\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sources, but have been updated with new features and/or labels.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root (str): Root directory where the dataset should be saved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name (str): The name of the dataset (:obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mreed98\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mamherst41\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcornell5\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mjohnshopkins55\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mgenius\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform (callable, optional): A function/transform that takes in an\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`torch_geometric.data.Data` object and returns a transformed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            version. The data object will be transformed before every access.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform (callable, optional): A function/transform that takes in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            an :obj:`torch_geometric.data.Data` object and returns a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            transformed version. The data object will be transformed before\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            being saved to disk. (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    github_url = (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/CUAI/Non-Homophily-Large-Scale/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                  \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw/master/data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    gdrive_url = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://drive.google.com/uc?confirm=t&\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    facebook_datasets = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreed98\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamherst41\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcornell5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjohnshopkins55\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    datasets = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/facebook100/Penn94.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreed98\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/facebook100/Reed98.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamherst41\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/facebook100/Amherst41.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcornell5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/facebook100/Cornell5.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjohnshopkins55\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/facebook100/Johns\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Hopkins55.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenius\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/genius.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_views2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{gdrive_url}\u001b[39;00m\u001b[38;5;124mid=1p5DlVHrnFgYm3VsNIzahSsvCD424AyvP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_edges2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{gdrive_url}\u001b[39;00m\u001b[38;5;124mid=14X7FlkjrlUgmnsYtPwdh-gGuFla4yb5u\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_features2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{gdrive_url}\u001b[39;00m\u001b[38;5;124mid=1ySNspxbK-snNoAZM7oxiWGvOnTRdSyEK\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    splits = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{github_url}\u001b[39;00m\u001b[38;5;124m/splits/fb100-Penn94-splits.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, root: str, name: str,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 pre_transform: Optional[Callable] = None):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.name = name.lower()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert self.name in self.datasets.keys()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__(root, transform, pre_transform)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.data, self.slices = torch.load(self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_file_names(self) -> List[str]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        names = list(self.datasets[self.name].keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.name in self.splits:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            names += [self.splits[self.name].split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[-1]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return names\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def download(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for filename, path in self.datasets[self.name].items():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(path, self.raw_dir, filename=filename)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.name in self.splits:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(self.splits[self.name], self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def _process_wiki(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        paths = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mx.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[-1]: x for x in self.raw_paths}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = torch.load(paths[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_features2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        edge_index = torch.load(paths[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_edges2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        y = torch.load(paths[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki_views2M.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return Data(x=x, edge_index=edge_index, y=y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def _process_facebook(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        from scipy.io import loadmat\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mat = loadmat(self.raw_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        A = mat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].tocsr().tocoo()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        row = torch.from_numpy(A.row).to(torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        col = torch.from_numpy(A.col).to(torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        edge_index = torch.stack([row, col], dim=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        metadata = torch.from_numpy(mat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_info\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].astype(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        xs = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        y = metadata[:, 1] - 1  # gender label, -1 means unlabeled\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = torch.cat([metadata[:, :1], metadata[:, 2:]], dim=-1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i in range(x.size(1)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            _, out = x[:, i].unique(return_inverse=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            xs.append(one_hot(out))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = torch.cat(xs, dim=-1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = Data(x=x, edge_index=edge_index, y=y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.name in self.splits:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            splits = np.load(self.raw_paths[1], allow_pickle=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            sizes = (data.num_nodes, len(splits))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data.train_mask = torch.zeros(sizes, dtype=torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data.val_mask = torch.zeros(sizes, dtype=torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data.test_mask = torch.zeros(sizes, dtype=torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for i, split in enumerate(splits):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data.train_mask[:, i][torch.tensor(split[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])] = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data.val_mask[:, i][torch.tensor(split[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])] = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data.test_mask[:, i][torch.tensor(split[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])] = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def _process_genius(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        from scipy.io import loadmat\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mat = loadmat(self.raw_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        edge_index = torch.from_numpy(mat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = torch.from_numpy(mat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_feat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.float)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        y = torch.from_numpy(mat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).squeeze().to(torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return Data(x=x, edge_index=edge_index, y=y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def process(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.name in self.facebook_datasets:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self._process_facebook()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        elif self.name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenius\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self._process_genius()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        elif self.name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwiki\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self._process_wiki()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            raise NotImplementedError(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mchosen dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not implemented\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.pre_transform is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self.pre_transform(data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        torch.save(self.collate([data]), self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __repr__(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mself.name.capitalize()}(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mlen(self)})\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m    ]\n\u001b[1;32m    310\u001b[0m   },\n\u001b[1;32m    311\u001b[0m   {\n\u001b[1;32m    312\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    313\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m11\u001b[39m,\n\u001b[1;32m    314\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me8dc746e\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    316\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    317\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os.path as osp\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom typing import Callable, Optional\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.data import Data, InMemoryDataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#, download_url\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.utils import to_undirected\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass HeterophilousGraphDataset(InMemoryDataset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mThe heterophilous graphs :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRoman-empire\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAmazon-ratings\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mMinesweeper\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTolokers\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m` and\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m` from the `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mA Critical Look at the Evaluation of GNNs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    under Heterophily: Are We Really Making Progress?\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    <https://arxiv.org/abs/2302.11640>`_ paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root (str): Root directory where the dataset should be saved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name (str): The name of the dataset (:obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRoman-empire\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAmazon-ratings\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mMinesweeper\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTolokers\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform (callable, optional): A function/transform that takes in an\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`torch_geometric.data.Data` object and returns a transformed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            version. The data object will be transformed before every access.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform (callable, optional): A function/transform that takes in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            an :obj:`torch_geometric.data.Data` object and returns a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            transformed version. The data object will be transformed before\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            being saved to disk. (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    **STATS:**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    .. list-table::\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :widths: 10 10 10 10 10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :header-rows: 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Name\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #nodes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #edges\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #classes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Roman-empire\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 22,662\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 32,927\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 300\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 18\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Amazon-ratings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 24,492\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 93,050\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 300\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Minesweeper\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 10,000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 39,402\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 7\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Tolokers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 11,758\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 519,000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Questions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 48,921\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 153,540\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 301\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    url = (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/yandex-research/heterophilous-graphs/raw/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m           \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain/data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root: str,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name: str,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.name = name.lower().replace(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert self.name in [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroman_empire\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamazon_ratings\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminesweeper\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtolokers\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__(root, transform, pre_transform)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.data, self.slices = torch.load(self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def download(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.url}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def process(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        raw = np.load(self.raw_paths[0], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        y = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        edge_index = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        edge_index = to_undirected(edge_index, num_nodes=x.size(0))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_mask = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_masks\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        val_mask = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_masks\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        test_mask = torch.from_numpy(raw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_masks\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = Data(x=x, y=y, edge_index=edge_index, train_mask=train_mask,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    val_mask=val_mask, test_mask=test_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.pre_transform is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self.pre_transform(data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        torch.save(self.collate([data]), self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __repr__(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.__class__.__name__}\u001b[39;00m\u001b[38;5;124m(name=\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m    ]\n\u001b[1;32m    449\u001b[0m   },\n\u001b[1;32m    450\u001b[0m   {\n\u001b[1;32m    451\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m13\u001b[39m,\n\u001b[1;32m    453\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42724f11\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    454\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    455\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    456\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom typing import Callable, List, Optional\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.data import Data, InMemoryDataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch_geometric.utils import coalesce\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Actor(InMemoryDataset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mThe actor-only induced subgraph of the film-director-actor-writer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    network used in the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mGeom-GCN: Geometric Graph Convolutional Networks\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    <https://openreview.net/forum?id=S1e2agrFvS>`_ paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Each node corresponds to an actor, and the edge between two nodes denotes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    co-occurrence on the same Wikipedia page.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Node features correspond to some keywords in the Wikipedia pages.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    The task is to classify the nodes into five categories in term of words of\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    actor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Wikipedia.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root (str): Root directory where the dataset should be saved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform (callable, optional): A function/transform that takes in an\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`torch_geometric.data.Data` object and returns a transformed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            version. The data object will be transformed before every access.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform (callable, optional): A function/transform that takes in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            an :obj:`torch_geometric.data.Data` object and returns a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            transformed version. The data object will be transformed before\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            being saved to disk. (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    **STATS:**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    .. list-table::\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :widths: 10 10 10 10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :header-rows: 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - #nodes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #edges\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #classes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - 7,600\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 30,019\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 932\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    url = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, root: str, transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 pre_transform: Optional[Callable] = None):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__(root, transform, pre_transform)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.data, self.slices = torch.load(self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_file_names(self) -> List[str]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_node_feature_label.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_graph_edges.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                ] + [f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilm_split_0.6_0.2_\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for i in range(10)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def download(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_file_names[:2]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.url}\u001b[39;00m\u001b[38;5;124m/new_data/film/\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_file_names[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.url}\u001b[39;00m\u001b[38;5;124m/splits/\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def process(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with open(self.raw_paths[0], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = [x.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) for x in f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            rows, cols = [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for n_id, col, _ in data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                col = [int(x) for x in col.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                rows += [int(n_id)] * len(col)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                cols += col\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            row, col = torch.tensor(rows), torch.tensor(cols)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = torch.zeros(int(row.max()) + 1, int(col.max()) + 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x[row, col] = 1.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = torch.empty(len(data), dtype=torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for n_id, _, label in data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                y[int(n_id)] = int(label)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with open(self.raw_paths[1], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = [[int(v) for v in r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)] for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = torch.tensor(data, dtype=torch.long).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = coalesce(edge_index, num_nodes=x.size(0))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_masks, val_masks, test_masks = [], [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_paths[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tmp = np.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            val_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            test_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_mask = torch.stack(train_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        val_mask = torch.stack(val_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        test_mask = torch.stack(test_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    val_mask=val_mask, test_mask=test_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = data if self.pre_transform is None else self.pre_transform(data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        torch.save(self.collate([data]), self.processed_paths[0])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m    ]\n\u001b[1;32m    565\u001b[0m   },\n\u001b[1;32m    566\u001b[0m   {\n\u001b[1;32m    567\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    568\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m    569\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m850982fd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    570\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    571\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    572\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass WebKB(InMemoryDataset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mThe WebKB datasets used in the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mGeom-GCN: Geometric Graph Convolutional Networks\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    <https://openreview.net/forum?id=S1e2agrFvS>`_ paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Nodes represent web pages and edges represent hyperlinks between them.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Node features are the bag-of-words representation of web pages.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    The task is to classify the nodes into one of the five categories, student,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    project, course, staff, and faculty.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root (str): Root directory where the dataset should be saved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name (str): The name of the dataset (:obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCornell\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTexas\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mWisconsin\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform (callable, optional): A function/transform that takes in an\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`torch_geometric.data.Data` object and returns a transformed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            version. The data object will be transformed before every access.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform (callable, optional): A function/transform that takes in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            an :obj:`torch_geometric.data.Data` object and returns a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            transformed version. The data object will be transformed before\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            being saved to disk. (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    **STATS:**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    .. list-table::\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :widths: 10 10 10 10 10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :header-rows: 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Name\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #nodes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #edges\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - #classes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Cornell\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 183\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 298\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 1,703\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Texas\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 183\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 325\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 1,703\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        * - Wisconsin\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 251\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 515\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 1,703\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m          - 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    url = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root: str,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name: str,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.name = name.lower()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert self.name in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcornell\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwisconsin\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__(root, transform, pre_transform)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.data, self.slices = torch.load(self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_file_names(self) -> List[str]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        out = [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_node_feature_label.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_graph_edges.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        out += [f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m_split_0.6_0.2_\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for i in range(10)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return out\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def download(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_file_names[:2]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.url}\u001b[39;00m\u001b[38;5;124m/new_data/\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_file_names[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.url}\u001b[39;00m\u001b[38;5;124m/splits/\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def process(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with open(self.raw_paths[0], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = [[float(v) for v in r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1].split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)] for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = torch.tensor(x, dtype=torch.float)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = [int(r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[2]) for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = torch.tensor(y, dtype=torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with open(self.raw_paths[1], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = [[int(v) for v in r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)] for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = torch.tensor(data, dtype=torch.long).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = coalesce(edge_index, num_nodes=x.size(0))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_masks, val_masks, test_masks = [], [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for f in self.raw_paths[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tmp = np.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            val_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            test_masks += [torch.from_numpy(tmp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.bool)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_mask = torch.stack(train_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        val_mask = torch.stack(val_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        test_mask = torch.stack(test_masks, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    val_mask=val_mask, test_mask=test_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data = data if self.pre_transform is None else self.pre_transform(data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        torch.save(self.collate([data]), self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __repr__(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    694\u001b[0m    ]\n\u001b[1;32m    695\u001b[0m   },\n\u001b[1;32m    696\u001b[0m   {\n\u001b[1;32m    697\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    698\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m17\u001b[39m,\n\u001b[1;32m    699\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma25ef160\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    700\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    701\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    702\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass WikipediaNetwork(InMemoryDataset):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    r\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mThe Wikipedia networks introduced in the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mMulti-scale Attributed Node Embedding\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    <https://arxiv.org/abs/1909.13021>`_ paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Nodes represent web pages and edges represent hyperlinks between them.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Node features represent several informative nouns in the Wikipedia pages.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    The task is to predict the average daily traffic of the web page.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        root (str): Root directory where the dataset should be saved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        name (str): The name of the dataset (:obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mchameleon\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`, :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124msquirrel\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        geom_gcn_preprocess (bool): If set to :obj:`True`, will load the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            pre-processed data as introduced in the `\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mGeom-GCN: Geometric\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            Graph Convolutional Networks\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m <https://arxiv.org/abs/2002.05287>_`,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            in which the average monthly traffic of the web page is converted\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            into five categories to predict.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            If set to :obj:`True`, the dataset :obj:`\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m` is not\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            available.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        transform (callable, optional): A function/transform that takes in an\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            :obj:`torch_geometric.data.Data` object and returns a transformed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            version. The data object will be transformed before every access.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pre_transform (callable, optional): A function/transform that takes in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            an :obj:`torch_geometric.data.Data` object and returns a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            transformed version. The data object will be transformed before\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            being saved to disk. (default: :obj:`None`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    raw_url = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://graphmining.ai/datasets/ptg/wiki\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    processed_url = (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/graphdml-uiuc-jlu/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                     \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, root: str, name: str, geom_gcn_preprocess: bool = True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 transform: Optional[Callable] = None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 pre_transform: Optional[Callable] = None):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.name = name.lower()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.geom_gcn_preprocess = geom_gcn_preprocess\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert self.name in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchameleon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquirrel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if geom_gcn_preprocess and self.name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            raise AttributeError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mThe dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not available in \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                                 \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcase \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom_gcn_preprocess=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__(root, transform, pre_transform)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.data, self.slices = torch.load(self.processed_paths[0])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.geom_gcn_preprocess:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_dir(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.geom_gcn_preprocess:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return osp.join(self.root, self.name, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def raw_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.geom_gcn_preprocess:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return ([\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_node_feature_label.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1_graph_edges.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] +\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    [f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m_split_0.6_0.2_\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for i in range(10)])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @property\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def processed_file_names(self) -> str:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def download(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.geom_gcn_preprocess:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for filename in self.raw_file_names[:2]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                url = f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.processed_url}\u001b[39;00m\u001b[38;5;124m/new_data/\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{filename}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                download_url(url, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for filename in self.raw_file_names[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                url = f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.processed_url}\u001b[39;00m\u001b[38;5;124m/splits/\u001b[39m\u001b[38;5;132;01m{filename}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                download_url(url, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            download_url(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{self.raw_url}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, self.raw_dir)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def process(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.geom_gcn_preprocess:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            with open(self.raw_paths[0], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data = f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = [[float(v) for v in r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1].split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)] for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = torch.tensor(x, dtype=torch.float)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = [int(r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[2]) for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = torch.tensor(y, dtype=torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            with open(self.raw_paths[1], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data = f.read().split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)[1:-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                data = [[int(v) for v in r.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)] for r in data]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = torch.tensor(data, dtype=torch.long).t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = coalesce(edge_index, num_nodes=x.size(0))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_masks, val_masks, test_masks = [], [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for filepath in self.raw_paths[2:]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                f = np.load(filepath)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                train_masks += [torch.from_numpy(f[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                val_masks += [torch.from_numpy(f[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                test_masks += [torch.from_numpy(f[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_mask = torch.stack(train_masks, dim=1).to(torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            val_mask = torch.stack(val_masks, dim=1).to(torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            test_mask = torch.stack(test_masks, dim=1).to(torch.bool)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                        val_mask=val_mask, test_mask=test_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = np.load(self.raw_paths[0], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, allow_pickle=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = torch.from_numpy(data[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.float)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = torch.from_numpy(data[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.long)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = edge_index.t().contiguous()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            edge_index = coalesce(edge_index, num_nodes=x.size(0))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            y = torch.from_numpy(data[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]).to(torch.float)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = Data(x=x, edge_index=edge_index, y=y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.pre_transform is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            data = self.pre_transform(data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        torch.save(self.collate([data]), self.processed_paths[0])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    828\u001b[0m    ]\n\u001b[1;32m    829\u001b[0m   },\n\u001b[1;32m    830\u001b[0m   {\n\u001b[1;32m    831\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    832\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m21\u001b[39m,\n\u001b[1;32m    833\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8f8093e9\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    834\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    835\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    836\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif __name__ == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mreed98\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mamherst41\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcornell5\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mjohnshopkins55\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mgenius\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #dataset = LINKXDataset(root=DIR, name = \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mpenn94\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)      \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRoman-empire\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAmazon-ratings\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mMinesweeper\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTolokers\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #dataset = HeterophilousGraphDataset(root=DIR, name = \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRoman-empire\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #dataset = Actor(root=DIR+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCornell\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTexas\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mWisconsin\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #dataset = WebKB(root=DIR, name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCornell\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    #\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mchameleon\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124msquirrel\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dataset = WikipediaNetwork(root=DIR, name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquirrel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m    ]\n\u001b[1;32m    859\u001b[0m   },\n\u001b[1;32m    860\u001b[0m   {\n\u001b[1;32m    861\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    863\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5f304545\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    864\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    865\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    866\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m    867\u001b[0m   }\n\u001b[1;32m    868\u001b[0m  ],\n\u001b[1;32m    869\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    870\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    871\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy38cu11\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    872\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    873\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy38cu11\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m   },\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    876\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    879\u001b[0m    },\n\u001b[1;32m    880\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    881\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    882\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    883\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    884\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    885\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.8.13\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    886\u001b[0m   }\n\u001b[1;32m    887\u001b[0m  },\n\u001b[1;32m    888\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    889\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    890\u001b[0m }\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/torch/serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    606\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/torch/serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    881\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 882\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/torch/serialization.py:875\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod_name, name):\n\u001b[1;32m    874\u001b[0m     mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'DataEdgeAttr' on <module 'torch_geometric.data.data' from '/home/das90/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/torch_geometric/data/data.py'>"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':   \n",
    "#     data, dataset = get_data('karate', log=True, h_score = True)\n",
    "#     print(sum(torch.where(data.train_mask==True)))\n",
    "#     data, dataset = get_data('Cora', train=0.2, random_state=True)\n",
    "#     print(sum(torch.where(data.train_mask==True)))\n",
    "    \n",
    "    data, dataset = get_data('Wisconsin', log=True, h_score = True)\n",
    "    \n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766100a2",
   "metadata": {},
   "source": [
    "## Homophily plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99973697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MoonGraph.MoonDataset(n_samples=1000, degree=5, train=0.5)    \n",
    "# G, data =dataset[0] \n",
    "# # MoonGraph.draw_blobs_data(G,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7173632f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'Cora'\n",
    "# data, dataset = get_data(DATASET_NAME)\n",
    "# # data.y = data.y.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae5b5f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hp_compute(data):\n",
    "    \n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "    \n",
    "    adj = SparseTensor(\n",
    "        row=data.edge_index[0], col=data.edge_index[1],\n",
    "        value=torch.arange(E, device=data.edge_index.device),\n",
    "        sparse_sizes=(N, N))\n",
    "    \n",
    "    hp_data=np.zeros(N)\n",
    "    \n",
    "    pbar = tqdm(total=N)\n",
    "    pbar.set_description(f'Nodes')\n",
    "        \n",
    "    for i in range(N):\n",
    "        row, col, edge = adj[i,:].coo()      \n",
    "        \n",
    "        if len(col) == 0: \n",
    "            pbar.update(1)\n",
    "            continue\n",
    "        \n",
    "        y_current = data.y[i]\n",
    "        y_neighbors = data.y[col]\n",
    "        \n",
    "        match  = (y_neighbors==y_current).type(torch.int).sum()\n",
    "        \n",
    "        hp_data[i] = match.item()/len(y_neighbors)\n",
    "        \n",
    "        #print(y_current, y_neighbors, match, hp_data[i])\n",
    "        \n",
    "        pbar.update(1)\n",
    "            \n",
    "    pbar.close()\n",
    "    \n",
    "    return hp_data\n",
    "\n",
    "#hp_data = hp_compute(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f86059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_hist(data, DATASET_NAME=''):\n",
    "    # Generate some random data\n",
    "    #data = np.random.normal(size=1000)\n",
    "    # Calculate the probability density function\n",
    "    density, bins, _ = plt.hist(data, density=True, bins=25)\n",
    "\n",
    "    # Plot the probability density function\n",
    "    plt.plot(bins[:-1], density)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Probability Density Function'+' '+DATASET_NAME)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "#hp_data = [0.01, 0.1,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e81ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_data = hp_compute(data)\n",
    "# pd_hist(hp_data, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a0669",
   "metadata": {},
   "source": [
    "## Gephi Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e694ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "# from ipynb.fs.full.utils.GNNutils import save_gephi_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d9c8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gephi_graph(data, DATASET_NAME):\n",
    "    G_fillename = '/scratch/gilbreth/das90/Dataset/GephiGraphs/'+DATASET_NAME\n",
    "\n",
    "    if os.path.exists(G_fillename)==False:\n",
    "        print(\"Graph is not found, creating it....\")\n",
    "        G = to_networkx(data, to_undirected=True)\n",
    "        nx.write_gpickle(G, G_fillename)\n",
    "        print(\"Done\")\n",
    "    else:\n",
    "        print(\"Loading Saved graph...\")\n",
    "        G = nx.read_gpickle(G_fillename)\n",
    "        print(\"Done\")\n",
    "    \n",
    "    graph_name = '/scratch/gilbreth/das90/Dataset/GephiGraphs/'+DATASET_NAME+'_original'\n",
    "    save_gephi_graph(G, data.y, graph_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992277c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [\n",
    "#     'karate','Moon','Fake',\n",
    "#     \"Cora\", \"CiteSeer\", \"PubMed\",'cora', 'cora_ml', 'citeseer', 'dblp', 'pubmed',\n",
    "#     'chameleon','cornell','film', 'squirrel', 'texas','wisconsin',\n",
    "#     'Computers', 'Photo',\n",
    "#     'CS', 'Physics',\n",
    "#     'Flickr','Yelp',\n",
    "#     \"penn94\", \"reed98\", \"amherst41\", \"cornell5\", \"johnshopkins55\", \"genius\",\n",
    "#     \"Roman-empire\", \"Amazon-ratings\", \"Minesweeper\", \"Tolokers\", \"Questions\",\n",
    "#     \"Actor\", \n",
    "#     \"Cornell\", \"Texas\", \"Wisconsin\", \n",
    "#     \"Chameleon\", \"Squirrel\", #\"Crocodile\",\n",
    "#     'Reddit',\n",
    "#     'Reddit2',\n",
    "#     'AmazonProducts' \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85647b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for DATASET_NAME in datasets:\n",
    "#     #DATASET_NAME = 'karate'\n",
    "#     print('-'*20,DATASET_NAME,'-'*20)\n",
    "#     data, dataset = get_data(DATASET_NAME)\n",
    "#     if data.y.ndim >1:\n",
    "#         data.y = data.y.argmax(dim=1)\n",
    "#     create_gephi_graph(data,DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75f1377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_gephi_graph(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ab45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.Tensor([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "# y = torch.LongTensor([0,0,0, 1, 1, 1, 1])\n",
    "# edge_index = torch.LongTensor([[1,2],[1,4],[1,5],[2,1],[3,6],[3,7],[4,5],[4,1],[4,6],[4,7],[5,1],[5,4],[5,6],[6,3],[6,4],[6,5],[6,7],[7,3],[7,4],[7,6]]).T\n",
    "# edge_index = edge_index-1\n",
    "# data = Data(x=x, y=y, edge_index = edge_index)\n",
    "# draw_graph(edge_index, y, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907de0f",
   "metadata": {},
   "source": [
    "# Create Synthetic Graphs of different homophily scores and degree of different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa26cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, dataset = get_data('karate', log=True, h_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a98a0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_class(data):\n",
    "    \n",
    "    unique_elements, counts = torch.unique(data.y, return_counts=True)\n",
    "#     print(unique_elements)\n",
    "#     print(counts)\n",
    "    mincount = min(counts).item()\n",
    "#     print(mincount)\n",
    "\n",
    "    subset = []\n",
    "\n",
    "    for i in unique_elements:\n",
    "        indexes = ((data.y == i).nonzero()).view(-1).numpy()\n",
    "#         print(len(indexes))\n",
    "#         print(indexes)\n",
    "        samples = np.random.choice(indexes, mincount, replace=False)\n",
    "        subset.extend(samples)\n",
    "\n",
    "#     print(len(subset), mincount*num_classes)\n",
    "\n",
    "    node_idx = torch.tensor(subset)\n",
    "    edge_index = subgraph(node_idx, data.edge_index)[0]\n",
    "    \n",
    "#     print(node_idx, edge_index)\n",
    "    \n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "\n",
    "    data.num_nodes = node_idx.size(0)\n",
    "    data.edge_index = edge_index\n",
    "\n",
    "    for key, item in data:\n",
    "        if key in ['edge_index', 'num_nodes']:\n",
    "            continue\n",
    "        if isinstance(item, torch.Tensor) and item.size(0) == N:\n",
    "            data[key] = item[node_idx]\n",
    "        elif isinstance(item, torch.Tensor) and item.size(0) == E:\n",
    "            data[key] = item[edge_idx]\n",
    "        else:\n",
    "            data[key] = item\n",
    "    \n",
    "    return data\n",
    "\n",
    "# print(data.edge_index)\n",
    "# data = balance_class(data)\n",
    "# print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd20078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic(data, d=5, h=0.8, train=0.6, random_state=None, log=True, balance = False):\n",
    "    \n",
    "    if balance:\n",
    "        data = balance_class(data)\n",
    "        \n",
    "    num_class = max(data.y)+1\n",
    "    cluster_vertices = {}\n",
    "    for c in range(num_class):\n",
    "        indices = torch.where(data.y == c)[0]\n",
    "        cluster_vertices[c]=indices\n",
    "    \n",
    "    n = data.num_nodes\n",
    "    \n",
    "#     intra_d = np.random.multinomial(n*d*h, np.ones(n)/n, size=1)[0]\n",
    "#     inter_d = np.random.multinomial(n*d*(1-h), np.ones(n)/n, size=1)[0]\n",
    "    \n",
    "    intra_d = np.round(np.ones(n)*(d*h)).astype(int)\n",
    "    inter_d = np.round(np.ones(n)*(d*(1-h))).astype(int)\n",
    "    \n",
    "#     print(intra_d, inter_d)\n",
    "    \n",
    "    edge_index = [[],[]]\n",
    "    \n",
    "    for c in range(num_class):\n",
    "        intra_vertices = cluster_vertices[c]\n",
    "        inter_vertices = torch.cat([value for key, value in cluster_vertices.items() if key!=c])\n",
    "        \n",
    "        intra_vertices = intra_vertices.numpy()\n",
    "        inter_vertices = inter_vertices.numpy()\n",
    "        \n",
    "#         print('Class:', c)\n",
    "#         print(intra_vertices)\n",
    "#         print(inter_vertices)\n",
    "        \n",
    "        for u in intra_vertices:\n",
    "            \n",
    "            ## remove self-loop\n",
    "            #intra_vertices_u = \n",
    "            \n",
    "            intra_v = np.random.choice(intra_vertices, min(len(intra_vertices),intra_d[u]), replace=False)\n",
    "            inter_v = np.random.choice(inter_vertices, min(len(inter_vertices),inter_d[u]), replace=False)\n",
    "            \n",
    "            Vs = np.append(intra_v,inter_v)\n",
    "            Us = np.repeat(u,len(Vs))\n",
    "            \n",
    "            unique_elements, counts = np.unique(inter_v, return_counts=True)\n",
    "            \n",
    "#             print(\"-\"*50)\n",
    "#             print(u)\n",
    "#             print(Vs)\n",
    "#             print(unique_elements)\n",
    "#             print(counts)\n",
    "#             print(\"-\"*50)\n",
    "            \n",
    "#             if len(unique_elements)< (num_class-1):\n",
    "#                 print('un du toa:')\n",
    "#                 print(unique_elements)\n",
    "#                 print(counts)\n",
    "            \n",
    "            edge_index[0].extend(Us)\n",
    "            edge_index[1].extend(Vs)\n",
    "             \n",
    "#             edge_index[1].extend(Us)\n",
    "#             edge_index[0].extend(Vs)\n",
    "    \n",
    "    data.edge_index = torch.LongTensor(edge_index)\n",
    "    \n",
    "    if train is not None:\n",
    "        val = (1-train)/2.0\n",
    "        data = train_val_test_mask(data, train=train, val=val, test=1-(train+val), random_state=random_state)\n",
    "    \n",
    "    if log:\n",
    "        print(f\"{homophily(data.edge_index, data.y, method='node'):0.4f}\",end=' ')\n",
    "        print(f\"{homophily(data.edge_index, data.y, method='edge'):0.4f}\",end=' ')\n",
    "        print(f\"{homophily(data.edge_index, data.y, method='edge_insensitive'):0.4f}\",end=' ')\n",
    "        print(f\"{assortativity(data.edge_index):0.4f}\", end=' ')\n",
    "        \n",
    "        unique_elements, counts = torch.unique(data.y, return_counts=True)\n",
    "        print(unique_elements.tolist(), counts.tolist(), end=' ')\n",
    "\n",
    "        print(f'{int(data.train_mask.sum()) / data.num_nodes:.4f}', end=' ')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# data = generate_synthetic(data, d=10, h=0.0, train=0.6, random_state=None, log=True, balance = True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae83985",
   "metadata": {},
   "source": [
    "# Diversity heterophily definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbd5ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b65ef2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'chameleon'\n",
    "# data, dataset = get_data(DATASET_NAME, log = False)\n",
    "# data = generate_synthetic(data, d=10, h=0.0, train=0.6, random_state=1, log=True, balance = False)\n",
    "# num_classes = dataset.num_classes\n",
    "# print(num_classes)\n",
    "# N = data.num_nodes\n",
    "# E = data.num_edges\n",
    "\n",
    "# adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],\n",
    "#     value=torch.arange(E, device=data.edge_index.device),\n",
    "#     sparse_sizes=(N, N))\n",
    "\n",
    "# # if len(col)==0:\n",
    "# #     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11f4bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def given_uniformity(col_labels, num_classes, cur_y, log=True, ):    \n",
    "    if log:\n",
    "        print(col_labels)\n",
    "        print(cur_y)\n",
    "        \n",
    "    unique_elements, counts = np.unique(col_labels, return_counts=True)\n",
    "    \n",
    "    if log:\n",
    "        print(unique_elements)\n",
    "        print(counts)\n",
    "    \n",
    "    index = np.where(unique_elements == cur_y)[0]\n",
    "    unique_elements = np.delete(unique_elements, index)\n",
    "    counts = np.delete(counts, index)\n",
    "\n",
    "    if log: \n",
    "        print(unique_elements)\n",
    "        print(counts)\n",
    "        \n",
    "    if len(unique_elements)<(num_classes-1):\n",
    "        if log:\n",
    "            print('unexpted: ')\n",
    "            print(unique_elements)\n",
    "            print(counts)\n",
    "        return -1\n",
    "    \n",
    "    expected_frequency = sum(counts) / (num_classes-1)\n",
    "    observed_frequency = np.array(counts)\n",
    "\n",
    "    if log:\n",
    "        print(expected_frequency)\n",
    "        print(observed_frequency)\n",
    "\n",
    "    chi2, p_value = chisquare(observed_frequency, f_exp=expected_frequency)\n",
    "    \n",
    "    if log:\n",
    "        print(\"Chi-squared statistic:\", chi2)\n",
    "        print(\"p-value:\", p_value)\n",
    "\n",
    "    significance_level = 0.05\n",
    "    if p_value < significance_level:\n",
    "        if log:print(\"The distribution significantly deviates from the uniform distribution.\")\n",
    "        return 0\n",
    "    else:\n",
    "        if log:print(\"The distribution is similar to the uniform distribution.\")\n",
    "        return 1\n",
    "\n",
    "    \n",
    "# u = 0\n",
    "# row, col, ed = adj[u,:].coo()   \n",
    "# col_labels = data.y[col]\n",
    "\n",
    "# print(row)\n",
    "# print(col)\n",
    "# print(col_labels)\n",
    "# print(len(col_labels))\n",
    "\n",
    "# cur_y = data.y[u].item()\n",
    "# print(cur_y)\n",
    "# given_uniformity(col_labels, num_classes, cur_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bfed791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_uniformity(data, num_classes, log=True):\n",
    "    \n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "    \n",
    "    adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],\n",
    "        value=torch.arange(E, device=data.edge_index.device),\n",
    "        sparse_sizes=(N, N))\n",
    "    \n",
    "    if log:\n",
    "        pbar = tqdm(total=N)\n",
    "        pbar.set_description(f'Nodes')\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for u in range(N):            \n",
    "        row, col, edge_index = adj[u,:].coo()   \n",
    "        col_labels = data.y[col]\n",
    "        cur_y = data.y[u].item()\n",
    "        is_diverse = given_uniformity(col_labels, num_classes, cur_y, log = False)\n",
    "        \n",
    "#         if is_diverse ==-1:\n",
    "#             print(u)\n",
    "        \n",
    "        count+=max(0,is_diverse)\n",
    "        if log:\n",
    "            pbar.update(1)\n",
    "    if log:\n",
    "        pbar.close()\n",
    "    \n",
    "    return count, count/N\n",
    "    \n",
    "# test_uniformity(data, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f2a8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_homophily(data, matrix_tu = 'affinity'):\n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "\n",
    "    adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],\n",
    "        value=torch.arange(E, device=data.edge_index.device),\n",
    "        sparse_sizes=(N, N))\n",
    "\n",
    "    A = torch.zeros((N,N))\n",
    "    edges = data.edge_index.t()\n",
    "    A[edges[:,0], edges[:,1]] = 1\n",
    "    A[edges[:,1], edges[:,0]] = 1    \n",
    "    \n",
    "    I = torch.eye(N)\n",
    "    D = torch.diag(torch.Tensor(torch.sum(A,dim=1)))\n",
    "#     print(A)\n",
    "#     print(D)\n",
    "\n",
    "    Ai = A + I\n",
    "    DiInv = torch.diag(torch.Tensor(1/torch.sum(Ai,dim=1)))\n",
    "    Arw = torch.mm(DiInv, Ai)\n",
    "    \n",
    "    M = Arw\n",
    "    \n",
    "    if matrix_tu == 'affinity':\n",
    "        M = Arw\n",
    "    elif matrix_tu == 'laplacian':\n",
    "        M = I - Arw\n",
    "    \n",
    "    AX = torch.mm(M,data.x)\n",
    "    #print(AX)\n",
    "    SAX = torch.mm(AX,AX.T)    \n",
    "    #print(SAX)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for u in range(N):            \n",
    "        row, col, edge_index = adj[u,:].coo()\n",
    "        \n",
    "        col_labels = data.y[col]\n",
    "        cur_y = data.y[u]\n",
    "        \n",
    "#         print(col_labels)\n",
    "#         print(cur_y)\n",
    "        \n",
    "        zu_eq = col[torch.where(col_labels == cur_y)[0]]\n",
    "        zu_neq = col[torch.where(col_labels != cur_y)[0]]\n",
    "        #print(zu_eq, zu_neq)\n",
    "        \n",
    "        left_u = torch.mean(SAX[u,zu_eq])\n",
    "        right_u = torch.mean(SAX[u,zu_neq])\n",
    "        #print(left_u, right_u)\n",
    "        \n",
    "        if torch.isnan(right_u):\n",
    "            count+=1        \n",
    "                            \n",
    "        elif (left_u >= right_u):\n",
    "            count+=1\n",
    "        \n",
    "    return count/N\n",
    "    \n",
    "    \n",
    "# DATASET_NAME = 'karate'\n",
    "# data, dataset = get_data(DATASET_NAME, log=False)\n",
    "# data = generate_synthetic(data, d=10, h = 0.2, train=0.6, random_state=1, log=False, balance = True)\n",
    "# data.x = F.one_hot(data.y).float()\n",
    "\n",
    "# print(agg_homophily(data, 'affinity'))\n",
    "# print(agg_homophily(data, 'laplacian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ca993f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'karate'\n",
    "# data, dataset = get_data(DATASET_NAME, log=False)\n",
    "# data = generate_synthetic(data, d=10, h = 0.2, train=0.6, random_state=1, log=False, balance = True)\n",
    "\n",
    "# num_classes = dataset.num_classes\n",
    "# print(num_classes)\n",
    "# N = data.num_nodes\n",
    "# E = data.num_edges\n",
    "\n",
    "# adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],\n",
    "#     value=torch.arange(E, device=data.edge_index.device),\n",
    "#     sparse_sizes=(N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8a8184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def scipyentropy(labels, num_class = 10):\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_probs = class_counts / len(labels)\n",
    "    \n",
    "    print(class_probs)\n",
    "\n",
    "    # Calculate entropy\n",
    "    entropy_value = entropy(class_probs, base=2)\n",
    "    print(\"Entropy:\", entropy_value)\n",
    "    \n",
    "    return entropy_value\n",
    "\n",
    "# labels = [0, 1, 2, 0, 1, 1, 3, 2, 2, 4, 4, 5, 5, 6, 6, 6, 6]\n",
    "# scipyentropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86910536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_entropy(class_probabilities, num_classes):\n",
    "    entropy = 0.0\n",
    "    \n",
    "    for probability in class_probabilities:\n",
    "        if probability != 0.0:\n",
    "            entropy += -probability * math.log2(probability)\n",
    "\n",
    "    max_entropy = -math.log2(1/num_classes)\n",
    "    \n",
    "    #print(max_entropy)    \n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    \n",
    "    return normalized_entropy\n",
    "\n",
    "# Example usage\n",
    "# class_probabilities = [0.9, 0.0, 0.0, 0.0, 0.1]\n",
    "# entropy_value = compute_entropy(class_probabilities, len(class_probabilities))\n",
    "# print(\"Normalized Entropy:\", entropy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a0a2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_entropy(col_labels, num_classes, cur_y, log=True):    \n",
    "    if log:\n",
    "        print(col_labels)\n",
    "        print(cur_y)\n",
    "        \n",
    "    unique_elements, counts = np.unique(col_labels, return_counts=True)\n",
    "    \n",
    "    if log:\n",
    "        print(unique_elements)\n",
    "        print(counts)\n",
    "    \n",
    "    index = np.where(unique_elements == cur_y)[0]\n",
    "    unique_elements = np.delete(unique_elements, index)\n",
    "    counts = np.delete(counts, index)\n",
    "\n",
    "    if log: \n",
    "        print(unique_elements)\n",
    "        print(counts)\n",
    "        \n",
    "    \n",
    "    prob = counts/sum(counts)\n",
    "    if log: print(prob)\n",
    "    \n",
    "    return compute_entropy(prob, num_classes-1)\n",
    "\n",
    "\n",
    "# u = 0\n",
    "# row, col, ed = adj[u,:].coo()   \n",
    "# col_labels = data.y[col]\n",
    "\n",
    "# print(row)\n",
    "# print(col)\n",
    "# print(col_labels)\n",
    "# print(len(col_labels))\n",
    "\n",
    "# cur_y = data.y[u].item()\n",
    "# print(cur_y)\n",
    "# node_entropy(col_labels, num_classes, cur_y, log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3e7884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_entropy(data, num_classes, log=True):\n",
    "    \n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "    \n",
    "    adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],\n",
    "        value=torch.arange(E, device=data.edge_index.device),\n",
    "        sparse_sizes=(N, N))\n",
    "    \n",
    "    if log:\n",
    "        pbar = tqdm(total=N)\n",
    "        pbar.set_description(f'Nodes')\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for u in range(N):            \n",
    "        row, col, edge_index = adj[u,:].coo()   \n",
    "        col_labels = data.y[col]\n",
    "        cur_y = data.y[u].item()\n",
    "        is_diverse = node_entropy(col_labels, num_classes, cur_y, log = False)\n",
    "        \n",
    "#         if is_diverse ==-1:\n",
    "#             print(u)\n",
    "        \n",
    "        count+= is_diverse\n",
    "        if log:\n",
    "            pbar.update(1)\n",
    "    if log:\n",
    "        pbar.close()\n",
    "    \n",
    "    return count, count/N\n",
    "\n",
    "# total_entropy(data, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c29bcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hetero():\n",
    "    d = 20\n",
    "    for h in np.array(range(0,21))/20:\n",
    "        DATASET_NAME = 'Cora'\n",
    "        data, dataset = get_data(DATASET_NAME, log=False)\n",
    "        data = generate_synthetic(data, d=d, h = h, train=0.6, random_state=1, log=False, balance = True)\n",
    "        num_classes = dataset.num_classes\n",
    "        print('d ', d, ' h', h, end=' ')\n",
    "        count, score = test_uniformity(data, num_classes, log=False)\n",
    "        print(count, score, end = ' ')\n",
    "#         Hagg_aff = agg_homophily(data, matrix_tu = 'affinity')\n",
    "#         Hagg_lap = agg_homophily(data, matrix_tu = 'laplacian')\n",
    "#         print(Hagg_aff, Hagg_lap)\n",
    "        total_en, en_score = total_entropy(data, num_classes, log=False)\n",
    "        print(total_en, en_score)\n",
    "    \n",
    "# test_hetero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b24615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
