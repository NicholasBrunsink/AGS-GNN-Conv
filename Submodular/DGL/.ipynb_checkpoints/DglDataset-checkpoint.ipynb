{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e29758",
   "metadata": {},
   "source": [
    "## Deep Graph Library Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2eca0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "kernel_name = os.path.basename(sys.executable.replace(\"/bin/python\",\"\"))\n",
    "\n",
    "if kernel_name == 'py38cu11':\n",
    "    import ctypes\n",
    "    ctypes.cdll.LoadLibrary(\"/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64/libcusparse.so.11\");\n",
    "    ctypes.cdll.LoadLibrary(\"/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64/libcublas.so.11\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "840ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7aeeadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_val_test_mask(graph, train=0.6, val=0.2, test=0.2, random_state=False):\n",
    "    \n",
    "    N = graph.num_nodes()\n",
    "    indexs = list(range(N))\n",
    "    \n",
    "    if random_state:\n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test))\n",
    "    else:        \n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test, random_state=1)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test), random_state=1)\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=bool)\n",
    "    train_mask[train_index]=True    \n",
    "    val_mask = torch.zeros(N, dtype=bool)\n",
    "    val_mask[val_index]=True\n",
    "    test_mask = torch.zeros(N, dtype=bool)\n",
    "    test_mask[test_index]=True\n",
    "\n",
    "    graph.ndata['train_mask'] = train_mask\n",
    "    graph.ndata['val_mask'] = val_mask\n",
    "    graph.ndata['test_mask'] = test_mask\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72f35512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(DIR, DATASET_NAME, log = True):\n",
    "    \n",
    "    if DATASET_NAME == 'karate':\n",
    "        dataset = dgl.data.KarateClubDataset()\n",
    "        #custom train mask\n",
    "    \n",
    "    elif DATASET_NAME == 'Cora':\n",
    "        dataset = dgl.data.CoraGraphDataset(raw_dir = DIR)        \n",
    "\n",
    "    elif DATASET_NAME in ['CiteSeer']:\n",
    "        dataset = dgl.data.CiteseerGraphDataset(raw_dir = DIR)\n",
    "        \n",
    "    elif DATASET_NAME == 'PubMed':\n",
    "        dataset = dgl.data.PubmedGraphDataset(raw_dir = DIR)\n",
    "        \n",
    "    elif DATASET_NAME == 'cora':\n",
    "        dataset = dgl.data.CoraFullDataset(raw_dir = DIR)\n",
    "        #custom train mask\n",
    "    \n",
    "    elif DATASET_NAME == 'Computer':\n",
    "        dataset = dgl.data.AmazonCoBuyComputerDataset(raw_dir = DIR)\n",
    "        #custom train mask\n",
    "        \n",
    "    elif DATASET_NAME in ['Photos', 'Photo']:\n",
    "        dataset = dgl.data.AmazonCoBuyPhotoDataset(raw_dir = DIR)\n",
    "        #custom train mask\n",
    "        \n",
    "    elif DATASET_NAME in ['CS', 'CoauthorCS']:\n",
    "        dataset = dgl.data.CoauthorCSDataset(raw_dir = DIR)\n",
    "        #custom train mask\n",
    "        \n",
    "    elif DATASET_NAME in ['Physics', 'CoauthorPhysics']:\n",
    "        dataset = dgl.data.CoauthorPhysicsDataset(raw_dir = DIR)\n",
    "        #custom train mask\n",
    "        \n",
    "    elif DATASET_NAME == 'Reddit':\n",
    "        dataset = dgl.data.RedditDataset(raw_dir = DIR)\n",
    "        \n",
    "    elif DATASET_NAME == 'fraudyelp':\n",
    "        dataset = dgl.data.FraudDataset(raw_dir = DIR, name = 'yelp')\n",
    "        g = dataset[0]\n",
    "        g.ndata['feat'] = g.ndata['feature']\n",
    "        \n",
    "    elif DATASET_NAME in ['flickr','Flickr']:\n",
    "        dataset = dgl.data.FlickrDataset(raw_dir = DIR)\n",
    "    \n",
    "    elif DATASET_NAME  == 'yelp':\n",
    "        dataset = dgl.data.YelpDataset(raw_dir = DIR+'yelp/') \n",
    "               \n",
    "    elif DATASET_NAME  in ['Chameleon','chameleon']:\n",
    "        from ipynb.fs.full.HeterophilicDataset import ChameleonDataset\n",
    "        dataset = ChameleonDataset(raw_dir = DIR) \n",
    "        \n",
    "    elif DATASET_NAME  in ['Squirrel','squirrel']:\n",
    "        from ipynb.fs.full.HeterophilicDataset import SquirrelDataset\n",
    "        dataset = SquirrelDataset(raw_dir = DIR) \n",
    "    \n",
    "    elif DATASET_NAME  in ['Cornell','cornell']:\n",
    "        from ipynb.fs.full.HeterophilicDataset import CornellDataset\n",
    "        dataset = CornellDataset(raw_dir = DIR) \n",
    "    \n",
    "    elif DATASET_NAME  in ['Actor','actor','Film','film']:\n",
    "        from ipynb.fs.full.Actor import ActorDataset\n",
    "        dataset = ActorDataset(raw_dir = DIR) \n",
    "        \n",
    "    elif DATASET_NAME  in ['Texas', 'texas']:\n",
    "        from ipynb.fs.full.HeterophilicDataset import TexasDataset\n",
    "        dataset = TexasDataset(raw_dir = DIR)    \n",
    "    \n",
    "    elif DATASET_NAME  in ['Winconsin', 'winconsin']:\n",
    "        from ipynb.fs.full.HeterophilicDataset import WisconsinDataset\n",
    "        dataset = WisconsinDataset(raw_dir = DIR)  \n",
    "        \n",
    "    elif DATASET_NAME in ['ogbn-arxiv', 'arxiv']:\n",
    "        from ogb.nodeproppred import DglNodePropPredDataset\n",
    "        dataset = DglNodePropPredDataset(root = DIR, name=\"ogbn-arxiv\")\n",
    "        g, node_labels = dataset[0]\n",
    "        g = dgl.add_reverse_edges(g)\n",
    "        g.ndata[\"label\"] = node_labels[:, 0]\n",
    "        \n",
    "        return dataset, g\n",
    "        \n",
    "    g = dataset[0]\n",
    "    \n",
    "#     print(g)    \n",
    "#     print('--'*50)\n",
    "    \n",
    "    if 'train_mask' not in g.ndata:\n",
    "        train_val_test_mask(g, train=0.6, val=0.2, test=0.2, random_state=1)\n",
    "    if 'feat' not in g.ndata:\n",
    "        g.ndata['feat'] = torch.eye(g.num_nodes())\n",
    "    \n",
    "    if log:\n",
    "        \n",
    "        print(\"Class: \", dataset.num_classes)\n",
    "        print(\"Feature: \",g.ndata['feat'].shape)        \n",
    "        \n",
    "        print(\"Train Mask: \",g.ndata['train_mask'].shape)\n",
    "        print(\"Val Mask: \",g.ndata['val_mask'].shape)\n",
    "        print(\"Test Mask: \",g.ndata['test_mask'].shape)\n",
    "        print(\"Label Mask: \",g.ndata['label'].shape)\n",
    "                \n",
    "    return dataset, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ff1c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DeviceDir\n",
    "    \n",
    "# DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "# device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "754aa8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, graph = get_dataset(DIR, 'Chameleon')\n",
    "\n",
    "# graph = dataset[0]\n",
    "# print(graph.num_nodes())\n",
    "# print(graph.num_edges())\n",
    "# print(dataset.num_classes)\n",
    "# print(graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40ed251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pyg_as_dgl(DATASET_NAME='karate', DIR=None, params=None, train=None, random_state=False, log=True, h_score=False):\n",
    "    \n",
    "    from ipynb.fs.full.PygDataset import get_data\n",
    "    import torch_geometric\n",
    "    from ipynb.fs.full.PygLib import to_dgl\n",
    "    \n",
    "    data, dataset = get_data(DATASET_NAME=DATASET_NAME, DIR=DIR, params=params, train=train, random_state=random_state, log=log, h_score=h_score)\n",
    "    \n",
    "    ## This is only available in the latest pytorch geometric, 2.1.x\n",
    "    g = to_dgl(data)\n",
    "    \n",
    "    g.ndata['feat'] = g.ndata['x']\n",
    "    g.ndata['label'] = g.ndata['y']\n",
    "    \n",
    "    return dataset, g\n",
    "\n",
    "def get_dgl_as_pyg(DATASET_NAME='karate', DIR=None,log=True, split_no=0):    \n",
    "    import torch_geometric\n",
    "    from ipynb.fs.full.PygLib import from_dgl\n",
    "    \n",
    "    dataset, graph = get_dataset(DIR, DATASET_NAME, log = log)\n",
    "    \n",
    "    ## This is only available in the latest pytorch geometric, 2.1.x\n",
    "    g = from_dgl(graph)\n",
    "    \n",
    "    if g.train_mask.dim()>1:\n",
    "        g.train_mask = g.train_mask[:,split_no]\n",
    "        g.val_mask = g.val_mask[:,split_no]\n",
    "        g.test_mask = g.test_mask[:,split_no]\n",
    "    \n",
    "    g.x = g.feat\n",
    "    g.y = g.label\n",
    "    g.feat = None\n",
    "    g.label = None\n",
    "    \n",
    "    print(g)\n",
    "        \n",
    "    return dataset, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c234a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic(graph, dataset, d=5, h=0.8, train=0.6, random_state=None, log=True):\n",
    "    num_class = dataset.num_classes\n",
    "    \n",
    "    cluster_vertices = {}\n",
    "    for c in range(num_class):\n",
    "        indices = torch.where(graph.ndata['label'] == c)[0]\n",
    "        cluster_vertices[c]=indices\n",
    "    \n",
    "    n = graph.num_nodes()\n",
    "    intra_d = np.random.multinomial(n*d*h, np.ones(n)/n, size=1)[0]\n",
    "    inter_d = np.random.multinomial(n*d*(1-h), np.ones(n)/n, size=1)[0]\n",
    "    \n",
    "    edge_index = [[],[]]\n",
    "    \n",
    "    for c in range(num_class):\n",
    "        intra_vertices = cluster_vertices[c]\n",
    "        inter_vertices = torch.cat([value for key, value in cluster_vertices.items() if key!=c])\n",
    "        \n",
    "        for u in intra_vertices:\n",
    "            intra_v = np.random.choice(intra_vertices, min(len(intra_vertices),intra_d[u]), replace=False)\n",
    "            inter_v = np.random.choice(inter_vertices, min(len(intra_vertices),inter_d[u]), replace=False)\n",
    "            Vs = np.append(intra_v,inter_v)\n",
    "            Us = np.repeat(u.item(),len(Vs))\n",
    "            edge_index[0].extend(Us)\n",
    "            edge_index[1].extend(Vs)\n",
    "    \n",
    "    edge_index = torch.LongTensor(edge_index)    \n",
    "    graph.remove_edges(torch.arange(graph.number_of_edges()))\n",
    "    graph.add_edges(edge_index[0],edge_index[1])\n",
    "\n",
    "    \n",
    "    if train is not None:\n",
    "        val = (1-train)/2.0\n",
    "        train_val_test_mask(graph, train=train, val=val, test=1-(train+val), random_state=random_state)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# generate_synthetic(graph, dataset, d=10, h=0.3, train=0.6, random_state=None, log=True)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d40f9ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A10\n",
      "cuda\n",
      "Cpu count:  32\n",
      "Looking at:  /scratch/gilbreth/das90/Dataset/\n",
      "Data directory:  /scratch/gilbreth/das90/Dataset/\n",
      "Result directory: /scratch/gilbreth/das90/Dataset/RESULTS/\n",
      "\n",
      "Dataset: HeteroDataset():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 2089\n",
      "Number of classes: 5\n",
      "\n",
      "Data(x=[5201, 2089], edge_index=[2, 217073], y=[5201], node_id=[5201], train_mask=[5201], val_mask=[5201], test_mask=[5201])\n",
      "===========================================================================================================\n",
      "Number of nodes: 5201\n",
      "Number of edges: 217073\n",
      "Average node degree: 41.74\n",
      "Number of training nodes: 3120\n",
      "Training node label rate: 0.60\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: False\n",
      "Graph(num_nodes=5201, num_edges=217073,\n",
      "      ndata_schemes={'x': Scheme(shape=(2089,), dtype=torch.float32), 'node_id': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'y': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'feat': Scheme(shape=(2089,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "Class:  5\n",
      "Feature:  torch.Size([5201, 2089])\n",
      "Train Mask:  torch.Size([5201])\n",
      "Val Mask:  torch.Size([5201])\n",
      "Test Mask:  torch.Size([5201])\n",
      "Label Mask:  torch.Size([5201])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    import DeviceDir\n",
    "    \n",
    "    DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "    device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "    \n",
    "#     dataset, g = get_dataset(DIR, 'squirrel')\n",
    "        \n",
    "    dataset, g = get_pyg_as_dgl(DATASET_NAME='squirrel', DIR=DIR)\n",
    "    print(g)\n",
    "    \n",
    "    print(\"Class: \", dataset.num_classes)\n",
    "    print(\"Feature: \",g.ndata['feat'].shape)        \n",
    "\n",
    "    print(\"Train Mask: \",g.ndata['train_mask'].shape)\n",
    "    print(\"Val Mask: \",g.ndata['val_mask'].shape)\n",
    "    print(\"Test Mask: \",g.ndata['test_mask'].shape)\n",
    "    print(\"Label Mask: \",g.ndata['label'].shape)\n",
    "\n",
    "    None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6667fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A10\n",
      "cuda\n",
      "Cpu count:  32\n",
      "Done loading data from cached files.\n",
      "Class:  5\n",
      "Feature:  torch.Size([5201, 2089])\n",
      "Train Mask:  torch.Size([5201, 10])\n",
      "Val Mask:  torch.Size([5201, 10])\n",
      "Test Mask:  torch.Size([5201, 10])\n",
      "Label Mask:  torch.Size([5201])\n",
      "Data(edge_index=[2, 217073], train_mask=[5201], val_mask=[5201], test_mask=[5201], x=[5201, 2089], y=[5201])\n",
      "Data(edge_index=[2, 217073], train_mask=[5201], val_mask=[5201], test_mask=[5201], x=[5201, 2089], y=[5201])\n"
     ]
    }
   ],
   "source": [
    "# import DeviceDir\n",
    "    \n",
    "# DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "# device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "\n",
    "# dataset, g = get_dgl_as_pyg(DATASET_NAME='Squirrel', DIR=DIR, split_no=0)\n",
    "\n",
    "# print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86e362b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [        \n",
    "#     'cora', \n",
    "#     'Cora',\n",
    "#     'citeseer',\n",
    "#     'CiteSeer',\n",
    "#     'PubMed',\n",
    "#     'dblp',\n",
    "#     'Reddit','Reddit2',\n",
    "#     'Computers','Photo','CS',\n",
    "#     'Physics','Flickr',\n",
    "#     'film',\n",
    "#     'cornell',\n",
    "#     'texas',\n",
    "#     'wisconsin',\n",
    "#     'squirrel',\n",
    "#     'chameleon',\n",
    "#     'Fake',\n",
    "#     'Moon',\n",
    "#     'AmazonProducts',\n",
    "#     'Yelp',\n",
    "#     'karate',\n",
    "#     'ogbn-arxiv'\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff55729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71ae2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My py311cu117pyg200 Kernel)",
   "language": "python",
   "name": "py311cu117pyg200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
