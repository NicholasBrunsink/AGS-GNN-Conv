{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef46300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actor-only induced subgraph of the film-directoractor-writer network.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "from dgl.convert import graph\n",
    "from dgl.data.dgl_dataset import DGLBuiltinDataset\n",
    "from dgl.data.utils import _get_dgl_url\n",
    "\n",
    "\n",
    "class ActorDataset(DGLBuiltinDataset):\n",
    "    r\"\"\"Actor-only induced subgraph of the film-directoractor-writer network\n",
    "    from `Social Influence Analysis in Large-scale Networks\n",
    "    <https://dl.acm.org/doi/10.1145/1557019.1557108>`, introduced by\n",
    "    `Geom-GCN: Geometric Graph Convolutional Networks\n",
    "    <https://arxiv.org/abs/2002.05287>`\n",
    "\n",
    "    Nodes represent actors, and edges represent co-occurrence on the same\n",
    "    Wikipedia page. Node features correspond to some keywords in the Wikipedia\n",
    "    pages.\n",
    "\n",
    "    Statistics:\n",
    "\n",
    "    - Nodes: 7600\n",
    "    - Edges: 33391\n",
    "    - Number of Classes: 5\n",
    "    - 10 train/val/test splits\n",
    "\n",
    "        - Train: 3648\n",
    "        - Val: 2432\n",
    "        - Test: 1520\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str, optional\n",
    "        Raw file directory to store the processed data. Default: ~/.dgl/\n",
    "    force_reload : bool, optional\n",
    "        Whether to re-download the data source. Default: False\n",
    "    verbose : bool, optional\n",
    "        Whether to print progress information. Default: True\n",
    "    transform : callable, optional\n",
    "        A transform that takes in a :class:`~dgl.DGLGraph` object and returns\n",
    "        a transformed version. The :class:`~dgl.DGLGraph` object will be\n",
    "        transformed before every access. Default: None\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of node classes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph does not come with edges for both directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, raw_dir=None, force_reload=False, verbose=True, transform=None\n",
    "    ):\n",
    "        super(ActorDataset, self).__init__(\n",
    "            name=\"actor\",\n",
    "            url=_get_dgl_url(\"dataset/actor.zip\"),\n",
    "            raw_dir=raw_dir,\n",
    "            force_reload=force_reload,\n",
    "            verbose=verbose,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Load and process the data.\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\n",
    "                \"This dataset requires PyTorch to be the backend.\"\n",
    "            )\n",
    "\n",
    "        # Process node features and labels.\n",
    "        with open(f\"{self.raw_path}/out1_node_feature_label.txt\", \"r\") as f:\n",
    "            data = [x.split(\"\\t\") for x in f.read().split(\"\\n\")[1:-1]]\n",
    "\n",
    "            rows, cols = [], []\n",
    "            labels = torch.empty(len(data), dtype=torch.long)\n",
    "            for n_id, col, label in data:\n",
    "                col = [int(x) for x in col.split(\",\")]\n",
    "                rows += [int(n_id)] * len(col)\n",
    "                cols += col\n",
    "\n",
    "                labels[int(n_id)] = int(label)\n",
    "\n",
    "            row, col = torch.tensor(rows), torch.tensor(cols)\n",
    "            features = torch.zeros(len(data), int(col.max()) + 1)\n",
    "            features[row, col] = 1.0\n",
    "\n",
    "            self._num_classes = int(labels.max().item()) + 1\n",
    "\n",
    "        # Process graph structure.\n",
    "        with open(f\"{self.raw_path}/out1_graph_edges.txt\", \"r\") as f:\n",
    "            data = f.read().split(\"\\n\")[1:-1]\n",
    "            data = [[int(v) for v in r.split(\"\\t\")] for r in data]\n",
    "        dst, src = torch.tensor(data, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        self._g = graph((src, dst), num_nodes=features.size(0))\n",
    "        self._g.ndata[\"feat\"] = features\n",
    "        self._g.ndata[\"label\"] = labels\n",
    "\n",
    "        # Process 10 train/val/test node splits.\n",
    "        train_masks, val_masks, test_masks = [], [], []\n",
    "        for i in range(10):\n",
    "            filepath = f\"{self.raw_path}/{self.name}_split_0.6_0.2_{i}.npz\"\n",
    "            f = np.load(filepath)\n",
    "            train_masks += [torch.from_numpy(f[\"train_mask\"])]\n",
    "            val_masks += [torch.from_numpy(f[\"val_mask\"])]\n",
    "            test_masks += [torch.from_numpy(f[\"test_mask\"])]\n",
    "        self._g.ndata[\"train_mask\"] = torch.stack(train_masks, dim=1).bool()\n",
    "        self._g.ndata[\"val_mask\"] = torch.stack(val_masks, dim=1).bool()\n",
    "        self._g.ndata[\"test_mask\"] = torch.stack(test_masks, dim=1).bool()\n",
    "\n",
    "    def has_cache(self):\n",
    "        return os.path.exists(self.raw_path)\n",
    "\n",
    "    def load(self):\n",
    "        self.process()\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx == 0, \"This dataset has only one graph.\"\n",
    "        if self._transform is None:\n",
    "            return self._g\n",
    "        else:\n",
    "            return self._transform(self._g)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    import DeviceDir\n",
    "    \n",
    "    DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "    device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "    \n",
    "    dataset = ActorDataset(raw_dir = DIR)\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
