{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "739cce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3055f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from layers import GraphConvolution, MLP\n",
    "\n",
    "\n",
    "device = f\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "large_datasets = [\n",
    "    \"deezer-europe\",\n",
    "    \"yelp-chi\",\n",
    "    \"Penn94\",\n",
    "    \"arxiv-year\",\n",
    "    \"pokec\",\n",
    "    \"snap-patents\",\n",
    "    \"genius\",\n",
    "    \"twitch-gamer\",\n",
    "    \"wiki\",\n",
    "]\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nfeat,\n",
    "        nhid,\n",
    "        nclass,\n",
    "        nlayers,\n",
    "        nnodes,\n",
    "        dropout,\n",
    "        model_type,\n",
    "        structure_info,\n",
    "        variant=False,\n",
    "        init_layers_X=1,\n",
    "    ):\n",
    "        super(GCN, self).__init__()\n",
    "        if model_type == \"acmgcnpp\":\n",
    "            self.mlpX = MLP(nfeat, nhid, nhid, num_layers=init_layers_X, dropout=0)\n",
    "        self.gcns, self.mlps = nn.ModuleList(), nn.ModuleList()\n",
    "        self.model_type, self.structure_info, self.nlayers, self.nnodes = (\n",
    "            model_type,\n",
    "            structure_info,\n",
    "            nlayers,\n",
    "            nnodes,\n",
    "        )\n",
    "\n",
    "        if (\n",
    "            self.model_type == \"acmgcn\"\n",
    "            or self.model_type == \"acmgcnp\"\n",
    "            or self.model_type == \"acmgcnpp\"\n",
    "        ):\n",
    "            self.gcns.append(\n",
    "                GraphConvolution(\n",
    "                    nfeat,\n",
    "                    nhid,\n",
    "                    nnodes,\n",
    "                    model_type=model_type,\n",
    "                    variant=variant,\n",
    "                    structure_info=structure_info,\n",
    "                )\n",
    "            )\n",
    "            self.gcns.append(\n",
    "                GraphConvolution(\n",
    "                    1 * nhid,\n",
    "                    nclass,\n",
    "                    nnodes,\n",
    "                    model_type=model_type,\n",
    "                    output_layer=1,\n",
    "                    variant=variant,\n",
    "                    structure_info=structure_info,\n",
    "                )\n",
    "            )\n",
    "        elif self.model_type == \"acmsgc\":\n",
    "            self.gcns.append(GraphConvolution(nfeat, nclass, model_type=model_type))\n",
    "        elif self.model_type == \"acmsnowball\":\n",
    "            for k in range(nlayers):\n",
    "                self.gcns.append(\n",
    "                    GraphConvolution(\n",
    "                        k * nhid + nfeat, nhid, model_type=model_type, variant=variant\n",
    "                    )\n",
    "                )\n",
    "            self.gcns.append(\n",
    "                GraphConvolution(\n",
    "                    nlayers * nhid + nfeat,\n",
    "                    nclass,\n",
    "                    model_type=model_type,\n",
    "                    variant=variant,\n",
    "                )\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "        self.fea_param, self.xX_param = Parameter(\n",
    "            torch.FloatTensor(1, 1).to(device)\n",
    "        ), Parameter(torch.FloatTensor(1, 1).to(device))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.model_type == \"acmgcnpp\":\n",
    "            self.mlpX.reset_parameters()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def forward(self, x, adj_low, adj_high, adj_low_unnormalized):\n",
    "\n",
    "        if (\n",
    "            self.model_type == \"acmgcn\"\n",
    "            or self.model_type == \"acmsgc\"\n",
    "            or self.model_type == \"acmsnowball\"\n",
    "            or self.model_type == \"acmgcnp\"\n",
    "            or self.model_type == \"acmgcnpp\"\n",
    "        ):\n",
    "\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            if self.model_type == \"acmgcnpp\":\n",
    "                xX = F.dropout(\n",
    "                    F.relu(self.mlpX(x, input_tensor=True)),\n",
    "                    self.dropout,\n",
    "                    training=self.training,\n",
    "                )\n",
    "        if self.model_type == \"acmsnowball\":\n",
    "            list_output_blocks = []\n",
    "            for layer, layer_num in zip(self.gcns, np.arange(self.nlayers)):\n",
    "                if layer_num == 0:\n",
    "                    list_output_blocks.append(\n",
    "                        F.dropout(\n",
    "                            F.relu(layer(x, adj_low, adj_high)),\n",
    "                            self.dropout,\n",
    "                            training=self.training,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    list_output_blocks.append(\n",
    "                        F.dropout(\n",
    "                            F.relu(\n",
    "                                layer(\n",
    "                                    torch.cat([x] + list_output_blocks[0:layer_num], 1),\n",
    "                                    adj_low,\n",
    "                                    adj_high,\n",
    "                                )\n",
    "                            ),\n",
    "                            self.dropout,\n",
    "                            training=self.training,\n",
    "                        )\n",
    "                    )\n",
    "            return self.gcns[-1](\n",
    "                torch.cat([x] + list_output_blocks, 1), adj_low, adj_high\n",
    "            )\n",
    "\n",
    "        fea1 = self.gcns[0](x, adj_low, adj_high, adj_low_unnormalized)\n",
    "\n",
    "        if (\n",
    "            self.model_type == \"acmgcn\"\n",
    "            or self.model_type == \"acmgcnp\"\n",
    "            or self.model_type == \"acmgcnpp\"\n",
    "        ):\n",
    "\n",
    "            fea1 = F.dropout((F.relu(fea1)), self.dropout, training=self.training)\n",
    "\n",
    "            if self.model_type == \"acmgcnpp\":\n",
    "                fea2 = self.gcns[1](fea1 + xX, adj_low, adj_high, adj_low_unnormalized)\n",
    "            else:\n",
    "                fea2 = self.gcns[1](fea1, adj_low, adj_high, adj_low_unnormalized)\n",
    "        return fea2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e15b02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcns): ModuleList(\n",
       "    (0): GraphConvolution (2 -> 2)\n",
       "    (1): GraphConvolution (2 -> 2)\n",
       "  )\n",
       "  (mlps): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = GCN(nfeat=2,\n",
    "        nhid=2,\n",
    "        nclass=2,\n",
    "        nlayers=2,\n",
    "        nnodes=7,\n",
    "        dropout=0.2,\n",
    "        model_type='acmgcn',\n",
    "        structure_info=0,\n",
    "        variant=False,\n",
    "        init_layers_X=1,)\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9a17a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "x = torch.Tensor([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "y = torch.LongTensor([0,0,0, 1, 1, 1, 1])\n",
    "edge_index = torch.LongTensor([[1,2],[1,4],[1,5],[2,1],[3,6],[3,7],[4,5],[4,1],[4,6],[4,7],[5,1],[5,4],[5,6],[6,3],[6,4],[6,5],[6,7],[7,3],[7,4],[7,6]]).T\n",
    "edge_index = edge_index-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c9338d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def normalize_tensor(mx, eqvar = None):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    mx = sp.csr_matrix(mx)\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    if eqvar:\n",
    "        r_inv = np.power(rowsum, -1.0/eqvar).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv, 0)\n",
    "        mx = r_mat_inv.dot(mx)    \n",
    "    else:\n",
    "        r_inv = np.power(rowsum, -1.0).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv, 0)\n",
    "        mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4adacc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2add8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to(device)\n",
    "adj_low_unnormalized = to_scipy_sparse_matrix(edge_index)\n",
    "adj_low = normalize_tensor(sp.identity(n) + adj_low_unnormalized)\n",
    "adj_high = sp.identity(n) - adj_low\n",
    "adj_low = sparse_mx_to_torch_sparse_tensor(adj_low).to(device)\n",
    "adj_high = sparse_mx_to_torch_sparse_tensor(adj_high).to(device)\n",
    "adj_low_unnormalized = sparse_mx_to_torch_sparse_tensor(adj_low_unnormalized).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69c9c14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8072, 0.1959],\n",
       "        [1.0825, 0.0491],\n",
       "        [0.4679, 0.0692],\n",
       "        [0.7088, 0.0584],\n",
       "        [0.7448, 0.0448],\n",
       "        [0.4905, 0.0839],\n",
       "        [0.4879, 0.0786]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.to(device), adj_low.to(device), adj_high.to(device), adj_low_unnormalized.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c4d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
