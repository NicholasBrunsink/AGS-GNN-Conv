{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fd74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not os.getcwd().endswith(\"Submodular\"):\n",
    "    sys.path.append('../Submodular')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb1d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b49419",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43fed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import get_data\n",
    "from ipynb.fs.full.Dataset import datasets as available_datasets\n",
    "from ipynb.fs.full.Utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69fbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "#set default arguments here\n",
    "def get_configuration():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--log_info', type=bool, default=True)\n",
    "    parser.add_argument('--pbar', type=bool, default=False)\n",
    "    parser.add_argument('--batch_size', type=int, default=2048)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    parser.add_argument('--dataset', type=str, default=\"Cora\", choices=available_datasets)\n",
    "    parser.add_argument('--use_normalization', action='store_false', default=True)\n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    return args, dict_args\n",
    "\n",
    "args, dict_args = get_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54682bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import init\n",
    "from random import shuffle, randint\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from torch_geometric.data import NeighborSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import logging\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b288b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719193d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370f0b6",
   "metadata": {},
   "source": [
    "## GCNConv, GATConv, GINConv, SAGEConv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fa6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, SAGEConv\n",
    "#GNNconv = GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=16, GNNconv = GCNConv):\n",
    "        super().__init__()        \n",
    "        ##GNN layer\n",
    "        if(GNNconv==GINConv):\n",
    "            self.MLP1 = nn.Linear(num_features,hidden_channels)\n",
    "            self.MLP2 = nn.Linear(hidden_channels,num_classes)\n",
    "            self.conv1 = GNNconv(self.MLP1)\n",
    "            self.conv2 = GNNconv(self.MLP2)                \n",
    "        else:        \n",
    "            self.conv1 = GNNconv(num_features, hidden_channels)\n",
    "            self.conv2 = GNNconv(hidden_channels,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_channels, heads, edge_dim=1)  # TODO\n",
    "        self.conv2 = GATConv(hidden_channels*heads, num_classes, heads=1, concat=True, edge_dim=1)  # TODO\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889ec36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, mask, name='Train'):\n",
    "    \n",
    "    if args.log_info:\n",
    "        pbar = tqdm(total=sum(mask).item())\n",
    "        pbar.set_description(f'Evaluating {name}')\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct=0\n",
    "    total_examples=0\n",
    "    \n",
    "    with torch.no_grad():                  \n",
    "    \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(batch_data.x, batch_data.edge_index,batch_data.edge_weight)\n",
    "            out=out[:batch_data.batch_size,:]\n",
    "            pred = out.argmax(dim=-1)            \n",
    "            correct = pred.eq(batch_data.y[:batch_data.batch_size].to(device))\n",
    "\n",
    "            total_correct+=correct.sum()\n",
    "            total_examples+=batch_data.batch_size\n",
    "            \n",
    "            if args.log_info:\n",
    "                pbar.update(batch_data.batch_size)\n",
    "    \n",
    "    if args.log_info:\n",
    "        pbar.close()\n",
    "\n",
    "    return total_correct.item()/total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43f91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs=100, train_neighbors=[-1,10], test_neighbors=[-1,-1]):\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(\"Train neighbors: \", train_neighbors)\n",
    "        print(\"Test neighbors: \", test_neighbors)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    batch_size=1024\n",
    "    loader = NeighborLoader(data, input_nodes=data.train_mask,num_neighbors=train_neighbors, \n",
    "                            batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = NeighborLoader(data,input_nodes=data.val_mask, num_neighbors=test_neighbors, \n",
    "                                batch_size=batch_size,shuffle=False, num_workers=0)\n",
    "    test_loader = NeighborLoader(data, input_nodes=data.test_mask,num_neighbors=test_neighbors, \n",
    "                                 batch_size=batch_size,shuffle=False, num_workers=0)\n",
    "        \n",
    "        \n",
    "    best_acc=0\n",
    "    num_iteration = epochs\n",
    "    train_losses = []\n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar = tqdm(total=int(sum(data.train_mask)))\n",
    "            pbar.set_description(f'Epoch {epoch:02d}')\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = total_examples = 0\n",
    "        \n",
    "        for i,batch_data in enumerate(loader):                \n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch_data.x, batch_data.edge_index, data.edge_weight)\n",
    "            \n",
    "            #loss = F.nll_loss(out[batch_data.train_mask], batch_data.y[batch_data.train_mask])\n",
    "            loss = criterion(out[batch_data.train_mask], batch_data.y[batch_data.train_mask])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             total_loss += loss.item() * batch_data.num_nodes\n",
    "#             total_examples += batch_data.num_nodes\n",
    "            \n",
    "            total_loss += loss.item() * sum(batch_data.train_mask).item()\n",
    "            total_examples += sum(batch_data.train_mask).item()\n",
    "        \n",
    "            if args.log_info:\n",
    "                pbar.update(batch_size)\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar.close()\n",
    "        \n",
    "        loss=total_loss / total_examples\n",
    "        train_losses.append(loss)        \n",
    "        \n",
    "        #train_acc=test(model, train_loader,data.train_mask,'Train')\n",
    "        train_acc=0\n",
    "        val_acc = test(model, val_loader,data.val_mask,'Validation')\n",
    "        test_acc = test(model, test_loader,data.test_mask,'Test')\n",
    "                \n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "        \n",
    "        std_dev = np.std(train_losses[-5:])\n",
    "        \n",
    "        if args.log_info:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}, Std dev: {std_dev:.4f}')\n",
    "                \n",
    "        if epoch>=5 and std_dev<=1e-3:\n",
    "            num_iteration = epoch\n",
    "            \n",
    "            if args.log_info:                \n",
    "                print(\"Iteration for convergence: \", epoch)\n",
    "            break\n",
    "                \n",
    "    return best_acc, num_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "513d616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCNperformanceSampler(data, dataset, num_classes, epochs=1, train_neighbors=[-1,-1], test_neighbors=[-1,-1]):        \n",
    "    model = GCN(dataset.num_features, num_classes, hidden_channels=256).to(device)\n",
    "    if args.log_info:\n",
    "        print(model)    \n",
    "    \n",
    "    best_acc, num_iteration = train(model, data, epochs, train_neighbors=train_neighbors, test_neighbors=test_neighbors)    \n",
    "    return best_acc, num_iteration, model\n",
    "\n",
    "def GATperformanceSampler(data, dataset, num_classes, epochs=1, train_neighbors=[-1,1], test_neighbors=[-1,-1]):        \n",
    "    model = GAT(dataset.num_features, num_classes, hidden_channels=64, heads=4).to(device)    \n",
    "    if args.log_info:\n",
    "        print(model)    \n",
    "    \n",
    "    best_acc, num_iteration =train(model, data, epochs, train_neighbors=train_neighbors, test_neighbors=test_neighbors)    \n",
    "    return best_acc, num_iteration, model\n",
    "\n",
    "def GINperformanceSampler(data, dataset, num_classes, epochs=1, train_neighbors=[-1,1], test_neighbors=[-1,-1]):        \n",
    "    model = GCN(dataset.num_features, num_classes, hidden_channels=256, GNNconv = GINConv).to(device)\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(model)    \n",
    "    \n",
    "    best_acc, num_iteration = train(model, data, epochs, train_neighbors=train_neighbors, test_neighbors=test_neighbors)    \n",
    "    return best_acc, num_iteration, model\n",
    "\n",
    "def GSAGEperformanceSampler(data, dataset, num_classes, epochs=1, train_neighbors=[-1,1], test_neighbors=[-1,-1]):        \n",
    "    model = GCN(dataset.num_features, num_classes, hidden_channels=256, GNNconv = SAGEConv).to(device)\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(model)    \n",
    "    \n",
    "    best_acc, num_iteration = train(model, data, epochs, train_neighbors=train_neighbors, test_neighbors=test_neighbors)    \n",
    "    return best_acc, num_iteration, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4406b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N  34  E  156  d  4.588235294117647 0.8020520210266113 0.7564102411270142 0.6170591711997986 -0.4756128787994385 \n",
      "Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34], val_mask=[34], test_mask=[34])\n",
      "GCN(\n",
      "  (conv1): GCNConv(34, 256)\n",
      "  (conv2): GCNConv(256, 4)\n",
      ")\n",
      "Train neighbors:  [25, 10]\n",
      "Test neighbors:  [-1, -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: : 1024it [00:00, 50476.18it/s]       \n",
      "Evaluating Validation: 100%|██████████| 30/30 [00:00<00:00, 13641.49it/s]\n",
      "Evaluating Test: 100%|██████████| 30/30 [00:00<00:00, 15925.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 1.3774, Train: 0.0000, Val: 0.3667, Test: 0.3667, Std dev: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: : 1024it [00:00, 280588.44it/s]      \n",
      "Evaluating Validation: 100%|██████████| 30/30 [00:00<00:00, 15773.99it/s]\n",
      "Evaluating Test: 100%|██████████| 30/30 [00:00<00:00, 15927.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 1.2987, Train: 0.0000, Val: 0.3667, Test: 0.3667, Std dev: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: : 1024it [00:00, 301084.28it/s]      \n",
      "Evaluating Validation: 100%|██████████| 30/30 [00:00<00:00, 14768.68it/s]\n",
      "Evaluating Test: 100%|██████████| 30/30 [00:00<00:00, 15465.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 1.2437, Train: 0.0000, Val: 0.4333, Test: 0.4333, Std dev: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: : 1024it [00:00, 265514.79it/s]      \n",
      "Evaluating Validation: 100%|██████████| 30/30 [00:00<00:00, 15006.45it/s]\n",
      "Evaluating Test: 100%|██████████| 30/30 [00:00<00:00, 15263.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 1.1519, Train: 0.0000, Val: 0.4333, Test: 0.4333, Std dev: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: : 1024it [00:00, 279893.60it/s]      \n",
      "Evaluating Validation: 100%|██████████| 30/30 [00:00<00:00, 14910.43it/s]\n",
      "Evaluating Test: 100%|██████████| 30/30 [00:00<00:00, 1479.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 1.0792, Train: 0.0000, Val: 0.5333, Test: 0.5333, Std dev: 0.1053\n",
      "0.5333333333333333 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args.log_info = True\n",
    "DATASET_NAME = 'karate'\n",
    "data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=True, split_no=0); print(\"\")\n",
    "print(data)\n",
    "best_acc, num_iteration, _ = GCNperformanceSampler(data, dataset, dataset.num_classes, epochs=5, train_neighbors=[25,10])\n",
    "#best_acc, num_iteration, _ = GATperformanceSampler(data, dataset, dataset.num_classes, epochs=5, train_neighbors=[25,10])\n",
    "#best_acc, num_iteration, _ = GINperformanceSampler(data, dataset, dataset.num_classes, epochs=5, train_neighbors=[25,10])\n",
    "#best_acc, num_iteration, _ = GSAGEperformanceSampler(data, dataset, dataset.num_classes, epochs=5, train_neighbors=[25,10])\n",
    "print(best_acc, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e334f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_experiments(method_name = 'GCN', num_run=1):\n",
    "    \n",
    "    ALL_DATASETs= [\n",
    "        \"Roman-empire\",\"Texas\",\"Squirrel\",\"Chameleon\",\n",
    "        \"Cornell\",\"Actor\",\"Wisconsin\",\"Flickr\",\"Amazon-ratings\",\"reed98\",\"amherst41\",\"genius\",\n",
    "        #\"AmazonProducts\",\n",
    "        \"cornell5\",\"penn94\",\"johnshopkins55\",\n",
    "#         \"Yelp\",\n",
    "#         \"cora\",\"Tolokers\",\"Minesweeper\",\n",
    "#         \"CiteSeer\",\"Computers\",\"PubMed\",\"pubmed\",\n",
    "#         #\"Reddit\",\n",
    "#         \"cora_ml\",\"dblp\",\n",
    "#         #\"Reddit2\",\n",
    "#         \"Cora\",\"CS\",\"Photo\",\"Questions\",\"Physics\",\"citeseer\",\n",
    "#         \"Reddit\", #remove this later\n",
    "#         \"Reddit2\",#remove this later\n",
    "#         \"Yelp\", #remove this later\n",
    "#         \"AmazonProducts\",#remove this later\n",
    "    ]\n",
    "    \n",
    "    #ALL_DATASETs= [\"karate\"]\n",
    "    \n",
    "    args.log_info = False\n",
    "    \n",
    "    for DATASET_NAME in ALL_DATASETs:  \n",
    "        print(DATASET_NAME, end=' ')\n",
    "        \n",
    "        result_file = open(\"Results/\"+method_name+\".txt\",'a+')        \n",
    "        result_file.write(f'{DATASET_NAME} ')\n",
    "        \n",
    "        \n",
    "        accs = []\n",
    "        itrs = []\n",
    "        \n",
    "        for i in range(num_run):\n",
    "            data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=False, split_no=i)   \n",
    "            \n",
    "            if data.num_nodes>100000:\n",
    "                accs.append(-1)\n",
    "                itrs.append(-1)\n",
    "                break\n",
    "            \n",
    "            if len(data.y.shape) > 1:\n",
    "                data.y = data.y.argmax(dim=1)        \n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            else:\n",
    "                num_classes = dataset.num_classes\n",
    "            \n",
    "            if num_classes!= torch.max(data.y)+1:\n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "                \n",
    "            if data.num_nodes<100000:\n",
    "                max_epochs = 150\n",
    "            else:\n",
    "                max_epochs = 50\n",
    "             \n",
    "            if method_name == 'GCN':\n",
    "                accuracy, itr, _ =  GCNperformanceSampler(data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "            elif method_name == 'GAT':\n",
    "                accuracy, itr, _ =  GATperformanceSampler(data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "            elif method_name == 'GIN':\n",
    "                accuracy, itr, _ =  GINperformanceSampler(data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "            elif method_name == 'GSAGE':\n",
    "                accuracy, itr, _ =  GSAGEperformanceSampler(data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "            \n",
    "            accs.append(accuracy)\n",
    "            itrs.append(itr)\n",
    "            #print(itr, accuracy)\n",
    "                        \n",
    "        #print(accs, itrs)\n",
    "        print(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f}, itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}')\n",
    "        result_file.write(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}\\n')\n",
    "        result_file.close()\n",
    "                \n",
    "# batch_experiments(method_name = 'GCN', num_run=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c2fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for method_name in ['GAT','GIN']:\n",
    "#     batch_experiments(method_name = method_name, num_run=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab4793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
