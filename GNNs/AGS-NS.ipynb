{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44415f5a",
   "metadata": {},
   "source": [
    "## Get Cuda and Processor information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac319c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Submodular')\n",
    "\n",
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()\n",
    "\n",
    "NUM_PROCESSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413bed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu count:  32\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "NUM_PROCESSORS=multiprocessing.cpu_count()\n",
    "print(\"Cpu count: \",NUM_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "782d8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import get_data,generate_synthetic\n",
    "from ipynb.fs.full.Dataset import datasets as available_datasets\n",
    "from ipynb.fs.full.Utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d11e7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "#set default arguments here\n",
    "def get_configuration():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--log_info', type=bool, default=True)\n",
    "    parser.add_argument('--pbar', type=bool, default=False)\n",
    "    parser.add_argument('--batch_size', type=int, default=2048)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--recompute', type=bool, default=False)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    parser.add_argument('--dataset', type=str, default=\"Cora\", choices=available_datasets)\n",
    "    parser.add_argument('--use_normalization', action='store_false', default=True)\n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    return args, dict_args\n",
    "\n",
    "args, dict_args = get_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d0c7f",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38ae0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SYNTHETIC = True\n",
    "seed = 123\n",
    "\n",
    "data_filename_extension = \"\"\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2deccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141f832",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd4df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv, ChebConv\n",
    "from torch_geometric.nn import GraphConv, TransformerConv\n",
    "from torch_geometric.utils import degree\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from ipynb.fs.full.SpatialConv import SpatialConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007e8b8",
   "metadata": {},
   "source": [
    "### GNN option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5744498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNNconv = SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ac584ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import GCNConv, GATConv, GINConv, SAGEConv\n",
    "GNNconv2 = GATConv\n",
    "\n",
    "class GNNother(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=256):\n",
    "        super().__init__()        \n",
    "        ##GNN layer\n",
    "        global GNNconv2\n",
    "        \n",
    "        if(GNNconv2==GINConv):\n",
    "            self.MLP1 = nn.Linear(num_features,hidden_channels)\n",
    "            self.MLP2 = nn.Linear(hidden_channels,num_classes)\n",
    "            self.conv1 = GNNconv2(self.MLP1)\n",
    "            self.conv2 = GNNconv2(self.MLP2)                \n",
    "        else:        \n",
    "            self.conv1 = GNNconv2(num_features, hidden_channels)\n",
    "            self.conv2 = GNNconv2(hidden_channels,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        \n",
    "        #x = x.log_softmax(dim=-1)\n",
    "        #x = x.relu()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class GNNGAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_channels, heads, edge_dim=1)  # TODO\n",
    "        self.conv2 = GATConv(hidden_channels*heads, num_classes, heads=1, concat=True, edge_dim=1)  # TODO\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd0e048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNHomophily(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=16):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "             \n",
    "        self.conv1 = GNNconv(num_features, hidden_channels)\n",
    "        #self.conv2 = GNNconv(hidden_channels,hidden_channels)\n",
    "        self.conv3 = GNNconv(hidden_channels,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.conv2(x, edge_index, edge_weight)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class GNNHeterophily(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=16):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "             \n",
    "        self.conv1 = ChebConv(num_features, hidden_channels, K=2, normalization='sym')\n",
    "        #self.conv2 = GNNconv(hidden_channels,hidden_channels)\n",
    "        self.conv3 = ChebConv(hidden_channels,num_classes, K=2, normalization='sym')\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.conv2(x, edge_index, edge_weight)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class AGSGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=16, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        hidden = int(hidden_channels/2)        \n",
    "        \n",
    "        ####################\n",
    "        self.gnn1 = GNNHomophily(num_features, hidden, hidden_channels)\n",
    "#         self.gnn2 = GNNHomophily(num_features, hidden, hidden_channels)\n",
    "        \n",
    "# #         self.gnn1 = GNNHeterophily(num_features, hidden, hidden_channels)\n",
    "        self.gnn2 = GNNHeterophily(num_features, hidden, hidden_channels)\n",
    "        \n",
    "#         ####################\n",
    "#         self.gnn1 = GNNother(num_features, hidden, hidden_channels)\n",
    "#         self.gnn2 = GNNother(num_features, hidden, hidden_channels)        \n",
    "\n",
    "#         ####################\n",
    "#         self.gnn1 = GNNHomophily(num_features, num_classes, hidden_channels)\n",
    "#         self.gnn1 = GNNHeterophily(num_features, num_classes, hidden_channels)\n",
    "        #################\n",
    "    \n",
    "        self.p = dropout\n",
    "        self.com_lin = nn.Linear(hidden*2, num_classes)\n",
    "        \n",
    "        \n",
    "#         self.T = 2        \n",
    "#         self.layer_norm_a1 =  nn.LayerNorm(num_classes)\n",
    "#         self.layer_norm_s1 =  nn.LayerNorm(num_classes)\n",
    "        \n",
    "#         self.alpha_a1 = nn.Linear(num_classes, 1)\n",
    "#         self.alpha_s1 = nn.Linear(num_classes, 1)\n",
    "#         self.w1 = nn.Linear(self.T, self.T)\n",
    "        \n",
    "        #self.reset_parameters()\n",
    "            \n",
    "#     def reset_parameters(self):\n",
    "#         std_att = 1. / math.sqrt(self.w1.weight.size(1))\n",
    "#         std_att_vec = 1. / math.sqrt( self.alpha_a1.weight.size(1))\n",
    "        \n",
    "#         self.alpha_s1.weight.data.uniform_(-std_att, std_att)\n",
    "#         self.alpha_i1.weight.data.uniform_(-std_att, std_att)\n",
    "        \n",
    "#         self.layer_norm_a1.reset_parameters()\n",
    "#         self.layer_norm_s1.reset_parameters()        \n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        \n",
    "        #out = model(batch_data.x, batch_data.edge_index, batch_data.weight)\n",
    "        #out = model(batch_data.x, batch_data.edge_index, batch_data.edge_weight)\n",
    "        #out = model(batch_data.x, batch_data.edge_index)\n",
    "        \n",
    "        x1 = self.gnn1(batch_data[0].x, batch_data[0].edge_index)\n",
    "#         return x1        \n",
    "        \n",
    "        x2 = self.gnn2(batch_data[1].x, batch_data[1].edge_index)\n",
    "        #return x2\n",
    "        \n",
    "        a1 = F.relu(x1)\n",
    "        #a1 = self.layer_norm_a1(a1)\n",
    "        a1 = F.dropout(a1, p=self.p, training=self.training)\n",
    "        \n",
    "        s1 = F.relu(x2)\n",
    "        #s1 = self.layer_norm_s1(s1)\n",
    "        s1 = F.dropout(s1, p=self.p, training=self.training)\n",
    "        \n",
    "        used = batch_data[0].batch_size\n",
    "        \n",
    "        x = torch.cat([a1[:used,:], s1[:used,:]], dim=-1)\n",
    "        x = self.com_lin(x)\n",
    "        \n",
    "        \n",
    "#         ala1 = torch.sigmoid(self.alpha_a1(a1))\n",
    "#         als1 = torch.sigmoid(self.alpha_s1(s1))        \n",
    "        \n",
    "#         alpha1 = F.softmax(self.w1(torch.cat([ala1, als1],dim=-1)/self.T), dim=1)                \n",
    "#         x = torch.mm(torch.diag(alpha1[:,0]),a1) + torch.mm(torch.diag(alpha1[:,1]),s1)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b17b8e",
   "metadata": {},
   "source": [
    "## GNN Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e11e841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from ipynb.fs.full.AGSNodeSampler import WeightedNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ac415e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, mask, name='Train'):    \n",
    "    if args.log_info:    \n",
    "        pbar = tqdm(total=sum(mask).item())\n",
    "        pbar.set_description(f'Evaluating {name}')\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct=0\n",
    "    total_examples=0\n",
    "    \n",
    "    sigmoid = nn.Sigmoid()    \n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():                  \n",
    "    \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            \n",
    "            batch_data = [b.to(device) for b in batch_data]\n",
    "            used = batch_data[0].batch_size\n",
    "            \n",
    "            out = model(batch_data)\n",
    "                   \n",
    "            out=out[:used,:]\n",
    "            pred = out.argmax(dim=1)            \n",
    "\n",
    "            y_true.append(batch_data[0].y[:used].detach().cpu().numpy())\n",
    "            y_pred.append(pred.detach().cpu().numpy())\n",
    "            \n",
    "            if args.log_info:\n",
    "                pbar.update(used)\n",
    "              \n",
    "    if args.log_info:\n",
    "        pbar.close()\n",
    "    \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    #acc = f1_score(y_true, y_pred, average='micro')\n",
    "                    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85fa0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DATASET_NAME, model, data, epochs=100, train_neighbors=[-1,10], test_neighbors=[-1,10]):\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(\"Train neighbors: \", train_neighbors)\n",
    "        print(\"Test neighbors: \", test_neighbors)\n",
    "        \n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    if data.y.ndim == 1:\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    batch_size=1024         \n",
    "#     batch_size=512         \n",
    "    worker = 8\n",
    "    \n",
    "    if data.num_nodes>=50000:\n",
    "        worker = 8\n",
    "    else:\n",
    "        worker = min(8,int(sum(data.train_mask)/batch_size))\n",
    "        \n",
    "    if args.log_info:\n",
    "        print(\"Worker: \", worker)\n",
    "        \n",
    "    weight_func=['knn','submodular']; \n",
    "#     weight_func=['knn','submodular']; \n",
    "#     weight_func=['random', 'random'];  worker = 0;\n",
    "#     weight_func=['link-nn', 'link-sub'];  worker = 2;\n",
    "    params={\n",
    "        'knn':{'metric':'cosine'},\n",
    "        'submodular':{'metric':'cosine'},\n",
    "        'link-nn':{'value':'min'},\n",
    "        'link-sub':{'value':'max'},\n",
    "        'apricot':{'sub_func':'coverage','metric':'cosine'}\n",
    "    }    \n",
    "    \n",
    "    global data_filename_extension        \n",
    "#     sampler_dir = DIR+'AGSGNNstruc/'+DATASET_NAME+data_filename_extension\n",
    "    sampler_dir = DIR+'AGSGNNstrucCorrect/'+DATASET_NAME+data_filename_extension\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(sampler_dir)\n",
    "    \n",
    "    \n",
    "#     if not os.path.exists(sampler_dir):\n",
    "#         os.makedirs(sampler_dir)\n",
    "    \n",
    "    start = time.time()    \n",
    "#     loader = WeightedNeighborLoader(data, input_nodes=data.train_mask,num_neighbors=train_neighbors, \n",
    "#                               batch_size=batch_size, shuffle=True, num_workers=worker, drop_last=False, \n",
    "#                               weight_func=weight_func, params=params, log=args.log_info,\n",
    "#                                     directed=True, replace = False,\n",
    "#                                     save_dir = sampler_dir,recompute = args.recompute)\n",
    "    \n",
    "    loader = WeightedNeighborLoader(data, input_nodes=data.train_mask,num_neighbors=train_neighbors, \n",
    "                              batch_size=batch_size, shuffle=True, num_workers=worker, drop_last=False, \n",
    "                              weight_func=weight_func, params=params, log=True,\n",
    "                                    directed=True, replace = False,\n",
    "                                    save_dir = sampler_dir,recompute = args.recompute)\n",
    "\n",
    "    train_loader = WeightedNeighborLoader(data, input_nodes=data.train_mask,num_neighbors=train_neighbors, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=worker, drop_last=False, \n",
    "                              weight_func=weight_func, params=params, log=args.log_info,\n",
    "                                          directed=True, replace = False,\n",
    "                                          save_dir = sampler_dir,recompute = False)\n",
    "    \n",
    "    val_loader = WeightedNeighborLoader(data, input_nodes=data.val_mask,num_neighbors=test_neighbors, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=min(8,int(sum(data.val_mask)/batch_size)), drop_last=False, \n",
    "                              weight_func=weight_func, params=params,log=args.log_info, directed=True, replace = False,\n",
    "                                        save_dir = sampler_dir,recompute = False)\n",
    "    \n",
    "    test_loader = WeightedNeighborLoader(data, input_nodes=data.test_mask,num_neighbors=test_neighbors, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=min(8,int(sum(data.test_mask)/batch_size)), drop_last=False, \n",
    "                              weight_func=weight_func, params=params, log=args.log_info, directed=True, replace = False,\n",
    "                                         save_dir = sampler_dir,recompute = False)\n",
    "    \n",
    "    top_k_accs = []    \n",
    "    best_acc=0  \n",
    "    \n",
    "    train_losses=[]\n",
    "    val_accuracies=[]\n",
    "    train_accuracies=[]\n",
    "    test_accuracies=[]\n",
    "    \n",
    "    num_iteration = epochs\n",
    "    \n",
    "    end = time.time()\n",
    "    if args.log_info:\n",
    "        print(\"Total initialization time: \", end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar = tqdm(total=int(sum(data.train_mask)))\n",
    "            pbar.set_description(f'Epoch {epoch:02d}')\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = total_examples = 0\n",
    "        \n",
    "        for i,batch_data in enumerate(loader):            \n",
    "            #print(batch_data)\n",
    "            \n",
    "            batch_data = [b.to(device) for b in batch_data]\n",
    "            used = batch_data[0].batch_size #int(sum(batch_data.train_mask))       \n",
    "            \n",
    "            optimizer.zero_grad()            \n",
    "            out = model(batch_data)\n",
    "            #out = F.log_softmax(out, dim=1)                 \n",
    "            #loss = F.nll_loss(out[batch_data[0].train_mask], batch_data[0].y[batch_data[0].train_mask])\n",
    "            #loss = F.cross_entropy(out[:used], batch_data[0].y[:used])\n",
    "            loss = criterion(out[:used], batch_data[0].y[:used])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            total_loss += loss.item() * used\n",
    "            total_examples += used\n",
    "            \n",
    "            if args.log_info:\n",
    "                pbar.update(used)\n",
    "        if args.log_info:\n",
    "            pbar.close()\n",
    "        \n",
    "        loss=total_loss / total_examples\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        #print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}', end = ', ')                \n",
    "        \n",
    "        if args.log_info:\n",
    "            train_acc=test(model, train_loader,data.train_mask,'Train')            \n",
    "            train_accuracies.append(train_acc.item())        \n",
    "        else:\n",
    "            train_acc = 0 ; train_accuracies.append(train_acc)\n",
    "        \n",
    "        if args.log_info:\n",
    "            val_acc = test(model, val_loader,data.val_mask,'Validation')\n",
    "            val_accuracies.append(val_acc.item())\n",
    "        else:\n",
    "            val_acc = 0 ; val_accuracies.append(val_acc)\n",
    "    \n",
    "        if epoch%10==0:\n",
    "            test_acc = test(model, test_loader,data.test_mask,'Test')\n",
    "            test_accuracies.append(test_acc.item())\n",
    "        else:\n",
    "            test_acc = 0\n",
    "            test_accuracies.append(test_acc)\n",
    "            \n",
    "        \n",
    "        #print(f'Epoch: {epoch:03d}, Test: {test_acc:.4f}')\n",
    "        \n",
    "        std_dev = np.std(train_losses[-5:])\n",
    "        #print(f'Epoch: {epoch:03d}, Std dev: {std_dev:.4f}')\n",
    "        \n",
    "        if args.log_info:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}, Std dev: {std_dev:.4f}')\n",
    "\n",
    "        if epoch>=5 and std_dev<=1e-3:\n",
    "            num_iteration = epoch\n",
    "            \n",
    "            if args.log_info:                \n",
    "                print(\"Iteration for convergence: \", epoch)\n",
    "            break\n",
    "        \n",
    "    if args.log_info:\n",
    "        #save_plot([val_accuracies], labels=['Validation'], name='Plots/Validation', yname='Accuracy', xname='Epoch')    \n",
    "        save_plot([train_losses, train_accuracies, val_accuracies, test_accuracies], labels=['Loss','Train','Validation','Test'], name='Results/AGSNSVal', yname='Accuracy', xname='Epoch')\n",
    "        \n",
    "        print (\"Best Validation Accuracy, \",max(val_accuracies))\n",
    "        print (\"Best Test Accuracy, \",max(test_accuracies))\n",
    "        \n",
    "    best_acc = max(test_accuracies)\n",
    "    \n",
    "    end = time.time()\n",
    "    if args.log_info:\n",
    "        print(\"Total epoch time: \", end-start)    \n",
    "    \n",
    "    return best_acc, num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34bee9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=1, train_neighbors=[-1,-1], test_neighbors=[-1,-1]):        \n",
    "    \n",
    "    model = AGSGNN(data.x.shape[1], num_classes, hidden_channels=256).to(device)\n",
    "    \n",
    "    if args.log_info: print(model)    \n",
    "    \n",
    "    best_acc, num_iteration = train(DATASET_NAME, model, data, epochs, train_neighbors=train_neighbors, test_neighbors=test_neighbors)    \n",
    "    \n",
    "    return best_acc, num_iteration, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9140fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_feature(data):    \n",
    "    adj_mat = torch.zeros((data.num_nodes,data.num_nodes))\n",
    "    edges = data.edge_index.t()\n",
    "    adj_mat[edges[:,0], edges[:,1]] = 1\n",
    "    return adj_mat\n",
    "\n",
    "# adj_feature(data)\n",
    "# data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e76eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_self_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16779f1",
   "metadata": {},
   "source": [
    "# AGS-GNN Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "586728b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N  183  E  325  d  1.7759562841530054 0.06539812684059143 0.10769230872392654 0.0 -0.34627223014831543 \n",
      "Data(x=[183, 1703], edge_index=[2, 325], y=[183], train_mask=[183], val_mask=[183], test_mask=[183])\n",
      "AGSGNN(\n",
      "  (gnn1): GNNHomophily(\n",
      "    (conv1): SAGEConv(1703, 256)\n",
      "    (conv3): SAGEConv(256, 128)\n",
      "  )\n",
      "  (gnn2): GNNHeterophily(\n",
      "    (conv1): ChebConv(1703, 256, K=2, normalization=sym)\n",
      "    (conv3): ChebConv(256, 128, K=2, normalization=sym)\n",
      "  )\n",
      "  (com_lin): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "Train neighbors:  [8, 4]\n",
      "Test neighbors:  [8, 4]\n",
      "Worker:  0\n",
      "/scratch/gilbreth/das90/Dataset/AGSGNNstrucCorrect/Texas\n",
      "Loading weights  knncosine\n",
      "Metric:  cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 183/183 [00:00<00:00, 2362.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weights  submodularcosine\n",
      "Total initialization time:  0.08454251289367676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 87/87 [00:00<00:00, 3234.88it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20699.10it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14618.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 1.6125, Train: 0.6552, Val: 0.5593, Test: 0.0000, Std dev: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 87/87 [00:00<00:00, 14499.32it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21082.99it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14814.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 1.4426, Train: 0.6897, Val: 0.5254, Test: 0.0000, Std dev: 0.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 87/87 [00:00<00:00, 14579.27it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21303.31it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14947.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 1.2799, Train: 0.6897, Val: 0.5424, Test: 0.0000, Std dev: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 87/87 [00:00<00:00, 14733.49it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20278.10it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14963.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 1.1413, Train: 0.6552, Val: 0.5593, Test: 0.0000, Std dev: 0.1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 87/87 [00:00<00:00, 14814.24it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 19553.34it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14900.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 1.0396, Train: 0.6667, Val: 0.5593, Test: 0.0000, Std dev: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 87/87 [00:00<00:00, 14533.97it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21242.55it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14781.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.9234, Train: 0.7126, Val: 0.5932, Test: 0.0000, Std dev: 0.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 87/87 [00:00<00:00, 14622.50it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21274.75it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14808.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.8050, Train: 0.7701, Val: 0.5932, Test: 0.0000, Std dev: 0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 87/87 [00:00<00:00, 14655.39it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21336.95it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14814.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.7426, Train: 0.8276, Val: 0.6441, Test: 0.0000, Std dev: 0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 87/87 [00:00<00:00, 14694.34it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21236.36it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14846.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.7120, Train: 0.8506, Val: 0.6102, Test: 0.0000, Std dev: 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 87/87 [00:00<00:00, 14396.36it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21131.83it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 13494.60it/s]\n",
      "Evaluating Test: 100%|██████████| 37/37 [00:00<00:00, 10177.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.5665, Train: 0.8506, Val: 0.5763, Test: 0.6757, Std dev: 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 87/87 [00:00<00:00, 14517.78it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21040.45it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14723.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.5135, Train: 0.8391, Val: 0.6102, Test: 0.0000, Std dev: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 87/87 [00:00<00:00, 14563.56it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21173.52it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14705.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.4418, Train: 0.8391, Val: 0.5763, Test: 0.0000, Std dev: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 87/87 [00:00<00:00, 14543.24it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21047.73it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14715.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.4082, Train: 0.8506, Val: 0.6102, Test: 0.0000, Std dev: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 87/87 [00:00<00:00, 14345.42it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21108.60it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14752.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.4071, Train: 0.8851, Val: 0.6271, Test: 0.0000, Std dev: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 87/87 [00:00<00:00, 14529.34it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21196.89it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14014.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.3689, Train: 0.9080, Val: 0.6610, Test: 0.0000, Std dev: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 87/87 [00:00<00:00, 14421.39it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 19963.04it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14685.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.2939, Train: 0.9425, Val: 0.6610, Test: 0.0000, Std dev: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 87/87 [00:00<00:00, 14603.19it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21047.73it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14750.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.2712, Train: 0.9425, Val: 0.6610, Test: 0.0000, Std dev: 0.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 87/87 [00:00<00:00, 14541.50it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21063.52it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14680.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.2623, Train: 0.9425, Val: 0.7119, Test: 0.0000, Std dev: 0.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 87/87 [00:00<00:00, 14863.72it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21012.58it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14763.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.2307, Train: 0.9425, Val: 0.7458, Test: 0.0000, Std dev: 0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 87/87 [00:00<00:00, 14497.02it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21021.05it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14660.19it/s]\n",
      "Evaluating Test: 100%|██████████| 37/37 [00:00<00:00, 10089.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 0.1943, Train: 0.9540, Val: 0.7458, Test: 0.7838, Std dev: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 87/87 [00:00<00:00, 14571.12it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 18962.97it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14688.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Train Loss: 0.1619, Train: 0.9540, Val: 0.7627, Test: 0.0000, Std dev: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 87/87 [00:00<00:00, 14276.39it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21104.94it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14797.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Train Loss: 0.1569, Train: 0.9540, Val: 0.7966, Test: 0.0000, Std dev: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 87/87 [00:00<00:00, 14321.21it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21039.23it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14805.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Train Loss: 0.1477, Train: 0.9540, Val: 0.7966, Test: 0.0000, Std dev: 0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 87/87 [00:00<00:00, 14298.76it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21134.28it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14732.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Train Loss: 0.1279, Train: 0.9540, Val: 0.8136, Test: 0.0000, Std dev: 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 87/87 [00:00<00:00, 14347.68it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21195.66it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14763.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Train Loss: 0.1248, Train: 0.9655, Val: 0.8305, Test: 0.0000, Std dev: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 87/87 [00:00<00:00, 14887.98it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21183.35it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14028.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Train Loss: 0.1149, Train: 0.9655, Val: 0.8475, Test: 0.0000, Std dev: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 87/87 [00:00<00:00, 14734.68it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20088.33it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14745.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Train Loss: 0.0955, Train: 0.9655, Val: 0.8305, Test: 0.0000, Std dev: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 87/87 [00:00<00:00, 14293.16it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21164.92it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14701.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Train Loss: 0.1004, Train: 0.9770, Val: 0.8305, Test: 0.0000, Std dev: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 87/87 [00:00<00:00, 14499.90it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21067.17it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14739.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Train Loss: 0.0858, Train: 0.9770, Val: 0.8305, Test: 0.0000, Std dev: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 87/87 [00:00<00:00, 14587.43it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21120.82it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14853.78it/s]\n",
      "Evaluating Test: 100%|██████████| 37/37 [00:00<00:00, 10110.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Train Loss: 0.1072, Train: 0.9885, Val: 0.8475, Test: 0.7838, Std dev: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 87/87 [00:00<00:00, 14207.46it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21254.92it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14820.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Train Loss: 0.0793, Train: 0.9885, Val: 0.8475, Test: 0.0000, Std dev: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 87/87 [00:00<00:00, 14533.39it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 19436.69it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14752.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Train Loss: 0.0636, Train: 0.9885, Val: 0.8136, Test: 0.0000, Std dev: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 87/87 [00:00<00:00, 15161.39it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21134.28it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14769.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Train Loss: 0.0622, Train: 0.9885, Val: 0.8305, Test: 0.0000, Std dev: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 87/87 [00:00<00:00, 14550.20it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21128.16it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14772.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Train Loss: 0.0532, Train: 0.9885, Val: 0.8644, Test: 0.0000, Std dev: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 87/87 [00:00<00:00, 14574.61it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21184.58it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14734.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Train Loss: 0.0602, Train: 0.9885, Val: 0.8305, Test: 0.0000, Std dev: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 87/87 [00:00<00:00, 14864.33it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21120.82it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14715.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Train Loss: 0.0515, Train: 0.9885, Val: 0.7966, Test: 0.0000, Std dev: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 87/87 [00:00<00:00, 14514.32it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21085.43it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 13983.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Train Loss: 0.0473, Train: 0.9885, Val: 0.7966, Test: 0.0000, Std dev: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 87/87 [00:00<00:00, 14274.71it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21120.82it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14733.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Train Loss: 0.0402, Train: 0.9885, Val: 0.7797, Test: 0.0000, Std dev: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 87/87 [00:00<00:00, 14592.09it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21177.21it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14705.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Train Loss: 0.0480, Train: 0.9885, Val: 0.7797, Test: 0.0000, Std dev: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 87/87 [00:00<00:00, 14555.42it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21124.49it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14816.43it/s]\n",
      "Evaluating Test: 100%|██████████| 37/37 [00:00<00:00, 10173.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Train Loss: 0.0480, Train: 0.9885, Val: 0.7797, Test: 0.8378, Std dev: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 87/87 [00:00<00:00, 14501.05it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21292.13it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14458.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Train Loss: 0.0327, Train: 1.0000, Val: 0.7797, Test: 0.0000, Std dev: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 87/87 [00:00<00:00, 14689.60it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21028.32it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14769.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 042, Train Loss: 0.0325, Train: 1.0000, Val: 0.7797, Test: 0.0000, Std dev: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 87/87 [00:00<00:00, 13679.13it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21214.14it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14760.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 043, Train Loss: 0.0392, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 87/87 [00:00<00:00, 14604.36it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21238.84it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14802.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 044, Train Loss: 0.0306, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 87/87 [00:00<00:00, 14337.53it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21171.06it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14886.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 045, Train Loss: 0.0265, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 87/87 [00:00<00:00, 14316.72it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21102.50it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14734.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046, Train Loss: 0.0418, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 87/87 [00:00<00:00, 14286.45it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20728.50it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14588.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 047, Train Loss: 0.0280, Train: 1.0000, Val: 0.8136, Test: 0.0000, Std dev: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 87/87 [00:00<00:00, 14481.48it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 18971.84it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14469.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Train Loss: 0.0219, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 87/87 [00:00<00:00, 14199.17it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20737.92it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14564.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 049, Train Loss: 0.0265, Train: 1.0000, Val: 0.8136, Test: 0.0000, Std dev: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 87/87 [00:00<00:00, 14650.68it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20977.55it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14674.09it/s]\n",
      "Evaluating Test: 100%|██████████| 37/37 [00:00<00:00, 10042.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Train Loss: 0.0250, Train: 1.0000, Val: 0.8136, Test: 0.7838, Std dev: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 87/87 [00:00<00:00, 14140.29it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 19504.22it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14621.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 051, Train Loss: 0.0270, Train: 1.0000, Val: 0.8305, Test: 0.0000, Std dev: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 87/87 [00:00<00:00, 14417.40it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20933.02it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14971.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 052, Train Loss: 0.0226, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 87/87 [00:00<00:00, 14891.63it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 19048.10it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14860.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 053, Train Loss: 0.0172, Train: 1.0000, Val: 0.8136, Test: 0.0000, Std dev: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 87/87 [00:00<00:00, 14947.14it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20965.50it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14813.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 054, Train Loss: 0.0181, Train: 1.0000, Val: 0.7966, Test: 0.0000, Std dev: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 87/87 [00:00<00:00, 14716.26it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20838.58it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14561.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 055, Train Loss: 0.0163, Train: 1.0000, Val: 0.8305, Test: 0.0000, Std dev: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 87/87 [00:00<00:00, 14663.63it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 20877.93it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14753.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 056, Train Loss: 0.0171, Train: 1.0000, Val: 0.8305, Test: 0.0000, Std dev: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 87/87 [00:00<00:00, 14527.61it/s]\n",
      "Evaluating Train: 100%|██████████| 87/87 [00:00<00:00, 21152.65it/s]\n",
      "Evaluating Validation: 100%|██████████| 59/59 [00:00<00:00, 14858.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 057, Train Loss: 0.0164, Train: 1.0000, Val: 0.8305, Test: 0.0000, Std dev: 0.0006\n",
      "Iteration for convergence:  57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy,  0.864406779661017\n",
      "Best Test Accuracy,  0.8378378378378378\n",
      "Total epoch time:  1.2838773727416992\n",
      "0.8378378378378378 57\n"
     ]
    }
   ],
   "source": [
    "args.log_info = True\n",
    "DATASET_NAME = 'Texas'\n",
    "data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=True, split_no=1); print(\"\")\n",
    "print(data)\n",
    "\n",
    "# (row, col) = data.edge_index\n",
    "# data.edge_index = torch.stack((torch.cat((row, col),dim=0),torch.cat((col, row),dim=0)),dim=0)\n",
    "# data.edge_index = torch_geometric.utils.coalesce(data.edge_index)\n",
    "# print(data)\n",
    "\n",
    "args.recompute = False\n",
    "\n",
    "\n",
    "if len(data.y.shape) > 1:\n",
    "    data.y = data.y.argmax(dim=1)        \n",
    "    num_classes = torch.max(data.y).item()+1\n",
    "else:\n",
    "    num_classes = dataset.num_classes\n",
    "\n",
    "if num_classes!= torch.max(data.y)+1:\n",
    "    num_classes = torch.max(data.y).item()+1\n",
    "    \n",
    "# data.edge_index, _ = add_self_loops(data.edge_index)            \n",
    "# data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "# if args.log_info == True:\n",
    "#     print(data.x.shape)\n",
    "\n",
    "    \n",
    "# if DATASET_NAME in ['Cornell', 'cornell5']:\n",
    "#     data.edge_index, _ = add_self_loops(data.edge_index)            \n",
    "    \n",
    "# if DATASET_NAME in ['Squirrel', 'Chameleon', 'amherst41',\n",
    "#                     'Cornell','cornell5', 'johnshopkins55']:\n",
    "#     data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "#     if args.log_info == True:\n",
    "#         print(data.x.shape)\n",
    "\n",
    "\n",
    "best_acc, num_iteration, _ =  AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=150, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "print(best_acc, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759650ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb2f89d3",
   "metadata": {},
   "source": [
    "# Batch Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7a2677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_experiments(num_run=1):\n",
    "    \n",
    "    ALL_DATASETs= [\n",
    "        \"Cornell\",\"Texas\",\"Wisconsin\",\n",
    "        \"reed98\",\"amherst41\",\n",
    "        \"penn94\",\"Roman-empire\",\"cornell5\",\"Squirrel\",\"johnshopkins55\",\n",
    "        \"AmazonProducts\",\n",
    "        \"Actor\",\"Minesweeper\",\"Questions\",\"Chameleon\",\n",
    "        \"Tolokers\",\"Flickr\",\n",
    "        \"Yelp\",\"Amazon-ratings\",\"genius\",\"cora\",\"CiteSeer\",\n",
    "        \"dblp\",\"Computers\",\"PubMed\",\"pubmed\",\"Reddit\",\n",
    "        \"cora_ml\",\"Cora\",\"Reddit2\",\"CS\",\"Photo\",\"Physics\",\"citeseer\"\n",
    "    ]     \n",
    "    \n",
    "    ALL_DATASETs= [\n",
    "        'karate',\n",
    "    ]\n",
    "\n",
    "    args.log_info = False\n",
    "    \n",
    "    filename = \"Results/AGSGNN-NS-2.txt\"\n",
    "    \n",
    "    for DATASET_NAME in ALL_DATASETs:  \n",
    "        print(DATASET_NAME, end=' ')\n",
    "        \n",
    "        \n",
    "        result_file = open(filename,'a+')        \n",
    "        result_file.write(f'{DATASET_NAME} ')\n",
    "        result_file.close()\n",
    "                \n",
    "        accs = []\n",
    "        itrs = []\n",
    "                \n",
    "        for i in range(num_run):\n",
    "            data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=False, split_no=i)   \n",
    "            \n",
    "            #optional for making undirected graph\n",
    "            (row, col) = data.edge_index\n",
    "            data.edge_index = torch.stack((torch.cat((row, col),dim=0),torch.cat((col, row),dim=0)),dim=0)\n",
    "            data.edge_index = torch_geometric.utils.coalesce(data.edge_index)\n",
    "            \n",
    "#             if data.num_nodes>100000:\n",
    "#                 accs.append(-1)\n",
    "#                 itrs.append(-1)\n",
    "#                 break\n",
    "            \n",
    "            if len(data.y.shape) > 1:\n",
    "                data.y = data.y.argmax(dim=1)        \n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            else:\n",
    "                num_classes = dataset.num_classes\n",
    "            \n",
    "            if num_classes!= torch.max(data.y)+1:\n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "                \n",
    "            if data.num_nodes<100000:\n",
    "                max_epochs = 150\n",
    "            else:\n",
    "                max_epochs = 20\n",
    "                \n",
    "            if DATASET_NAME in ['Squirrel', 'Chameleon','cornell5','penn94','johnshopkins55'\n",
    "                               \"amherst41\"]:\n",
    "                data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "                if args.log_info == True:\n",
    "                    print(data.x.shape)\n",
    "                              \n",
    "            accuracy, itr, _ = AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])\n",
    "            \n",
    "            accs.append(accuracy)\n",
    "            itrs.append(itr)\n",
    "            #print(itr, accuracy)\n",
    "                        \n",
    "        #print(accs, itrs)\n",
    "        print(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}')\n",
    "        result_file = open(filename,'a+')\n",
    "        result_file.write(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}\\n')\n",
    "        result_file.close()\n",
    "                \n",
    "# batch_experiments(num_run=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4cab8c",
   "metadata": {},
   "source": [
    "## View Learned Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "361d4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':    \n",
    "    \n",
    "#     n=7\n",
    "#     x = torch.Tensor([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "#     y = torch.LongTensor([0,0,0, 1, 1, 1, 1])\n",
    "#     edge_index = torch.LongTensor([[1,2],[1,4],[1,5],[2,1],[3,6],[3,7],[4,5],[4,1],[4,6],[4,7],[5,1],[5,4],[5,6],[6,3],[6,4],[6,5],[6,7],[7,3],[7,4],[7,6]]).T\n",
    "#     edge_index = edge_index-1\n",
    "    \n",
    "#     mask = torch.zeros(n, dtype=torch.bool)\n",
    "#     mask[[1,3]] = True\n",
    "    \n",
    "#     test_data = Data(x = x, y = y, edge_index = edge_index, train_mask = mask, test_mask = mask, val_mask = mask)    \n",
    "#     print(test_data)\n",
    "    \n",
    "    \n",
    "#     None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83ca9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48f76e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# #X = model(data.x.to(device),data.edge_index.to(device), data.weight.to(device))\n",
    "# X = model(data.x.to(device),data.edge_index.to(device))\n",
    "# X = X.detach().to('cpu')\n",
    "# y = data.y.to('cpu')\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1e750fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "\n",
    "# # Create a t-SNE model with 2 components and a perplexity of 30\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42, learning_rate='auto', init='random')\n",
    "\n",
    "# # Fit and transform the data to the 2D t-SNE space\n",
    "# X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# # Plot the data in the 2D t-SNE space, colored by class\n",
    "# plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6a5b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sparsify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc7c75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.SubmodularWeights import SubModularWeightFacilityFaster\n",
    "from ipynb.fs.full.KNNWeights import KNNWeight\n",
    "# from ipynb.fs.full.PretrainedLink import LinkPred, LinkNN, LinkSub\n",
    "from ipynb.fs.full.PretrainedLinkFast import get_link_weight, LinkNN, LinkSub\n",
    "from ipynb.fs.full.RandomSparse import RandomSparse\n",
    "import torch_geometric.utils.homophily as homophily\n",
    "import copy\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a64131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify(data, log = True, method = 'NN', metric= None):\n",
    "    data.to('cpu')    \n",
    "    \n",
    "    if metric is None:\n",
    "        metric = 'cosine'\n",
    "    \n",
    "    if method == 'nn':\n",
    "        submodular_weight = KNNWeight(data, metric=metric, log=log)                \n",
    "        data.weight = submodular_weight.compute_weights()        \n",
    "\n",
    "    elif method == 'submodular':\n",
    "        submodular_weight = SubModularWeightFacilityFaster(data, metric=metric, log=log)\n",
    "        data.weight = submodular_weight.compute_weights()        \n",
    "    \n",
    "    elif method == 'link-nn':    \n",
    "        submodular_weight = LinkPred(data, selfloop = True, log=log)\n",
    "        data.weight = submodular_weight.compute_weights()        \n",
    "        nn_weight = LinkNN(data, value='min', log=log) #min favor similar ones, max disimilar\n",
    "        data.weight = nn_weight.compute_weights()\n",
    "    elif method == 'link-sub':    \n",
    "        nn_weight = LinkSub(data, value='max', selfloop = True, log=log) #min favor similar ones, max disimilar    \n",
    "        data.weight = nn_weight.compute_weights()\n",
    "    else:\n",
    "        raise 'Not implemented error'\n",
    "    \n",
    "    cp_data= copy.deepcopy(data)\n",
    "    G = to_networkx(cp_data, to_undirected=False, edge_attrs=['weight'])\n",
    "    to_remove = [(a,b) for a, b, attrs in G.edges(data=True) if attrs[\"weight\"] < 0.7 ]\n",
    "    G.remove_edges_from(to_remove)\n",
    "    updated_data = from_networkx(G)\n",
    "    \n",
    "    updated_data = from_networkx(G, group_edge_attrs=['weight'])\n",
    "    updated_data.weight = updated_data.edge_attr.view(-1)\n",
    "\n",
    "    row, col = updated_data.edge_index\n",
    "    updated_data.edge_index = torch.stack((torch.cat((row, col),dim=0), torch.cat((col, row),dim=0)),dim=0)\n",
    "    updated_data.weight = torch.cat((updated_data.weight, updated_data.weight),dim=0)\n",
    "\n",
    "    \n",
    "    #if args.log_info:\n",
    "    if True:\n",
    "        print(updated_data)\n",
    "        print(\"Node Homophily:\", homophily(updated_data.edge_index, data.y, method='node'))\n",
    "        print(\"Edge Homophily:\", homophily(updated_data.edge_index, data.y, method='edge'))\n",
    "        print(\"Edge_insensitive Homophily:\", homophily(updated_data.edge_index, data.y, method='edge_insensitive'))    \n",
    "        print(\"Degree: \", updated_data.num_edges / updated_data.num_nodes)\n",
    "\n",
    "    data.edge_index = updated_data.edge_index\n",
    "    data.edge_weight = updated_data.weight\n",
    "    data.weight = None\n",
    "\n",
    "    return data\n",
    "\n",
    "# LOG_INFO = True\n",
    "# data = sparsify(data, log = False)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "295e15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sparsify(data, K, log = False):    \n",
    "    rand_sparse = RandomSparse(data, K = K, log = log)\n",
    "    edge_index = rand_sparse.sparse()\n",
    "    row, col = edge_index\n",
    "    data.edge_index = torch.stack((torch.cat((row, col),dim=0), torch.cat((col, row),dim=0)),dim=0)\n",
    "    \n",
    "    if log:\n",
    "        print(\"Node Homophily:\", homophily(data.edge_index, data.y, method='node'))\n",
    "        print(\"Edge Homophily:\", homophily(data.edge_index, data.y, method='edge'))\n",
    "        print(\"Edge_insensitive Homophily:\", homophily(data.edge_index, data.y, method='edge_insensitive'))    \n",
    "        print(\"Degree: \", data.num_edges / data.num_nodes)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfb29939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_homophily(data, h = 0.1, d = 11, log = False):\n",
    "    data.to('cpu')\n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "    adj = SparseTensor(\n",
    "        row=data.edge_index[0], col=data.edge_index[1],\n",
    "        value=torch.arange(E, device=data.edge_index.device),\n",
    "        sparse_sizes=(N, N))\n",
    "    \n",
    "    edge_index=[]\n",
    "    \n",
    "#     h = 0.1\n",
    "#     d = 11\n",
    "\n",
    "    match = int(round(d*h))\n",
    "    unmatch = int(round(d*(1-h)))\n",
    "    #print(match,unmatch)\n",
    "    \n",
    "    for u in range(N):                \n",
    "        row, col, e_index = adj[u,:].coo()   \n",
    "        \n",
    "        cur_y = data.y[u]\n",
    "        neighbors = data.y[col]\n",
    "        #print(cur_y, neighbors)\n",
    "        \n",
    "        match_indexs = torch.nonzero(neighbors == cur_y).squeeze()\n",
    "        other_indexs = torch.nonzero(neighbors != cur_y).squeeze()\n",
    "        \n",
    "        #print(match_indexs, other_indexs)\n",
    "        \n",
    "        if match_indexs.dim()>0:\n",
    "            m_sel = match_indexs[np.random.choice(len(match_indexs), size=min(match,len(match_indexs)), replace = False)]\n",
    "        else:\n",
    "            m_sel = torch.LongTensor([])\n",
    "        if other_indexs.dim()>0:\n",
    "            um_sel = other_indexs[np.random.choice(len(other_indexs), size=min(unmatch, len(other_indexs)), replace = False)]\n",
    "        else:\n",
    "            um_sel = torch.LongTensor([])\n",
    "            \n",
    "        \n",
    "        #print(m_sel, um_sel)\n",
    "        \n",
    "        indexs = torch.cat((m_sel,um_sel),dim=0)\n",
    "    \n",
    "        e_index = e_index[indexs]            \n",
    "        edge_index.extend(e_index)\n",
    "        \n",
    "        #break        \n",
    "            \n",
    "    edge_index = data.edge_index[:,edge_index]\n",
    "    row, col = edge_index\n",
    "    data.edge_index = torch.stack((torch.cat((row, col),dim=0), torch.cat((col, row),dim=0)),dim=0)\n",
    "    \n",
    "    if log:\n",
    "        print(\"Node Homophily:\", homophily(data.edge_index, data.y, method='node'))\n",
    "        print(\"Edge Homophily:\", homophily(data.edge_index, data.y, method='edge'))\n",
    "        print(\"Edge_insensitive Homophily:\", homophily(data.edge_index, data.y, method='edge_insensitive'))    \n",
    "        print(\"Degree: \", data.num_edges / data.num_nodes)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# data = modify_homophily(data, h=0.15, d=11, log = True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df9032d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hetero():\n",
    "    d = 42\n",
    "    for h in np.array(range(0,21))/20:\n",
    "        DATASET_NAME = 'squirrel'\n",
    "        data, dataset = get_data(DATASET_NAME, log=False)\n",
    "        data = generate_synthetic(data, d=d, h = h, train=0.6, random_state=1, log=False, balance = False)\n",
    "        num_classes = dataset.num_classes\n",
    "        \n",
    "        print('d ', d, ' h', h, end=' ')\n",
    "        count, score = test_uniformity(data, num_classes, log=False)\n",
    "        print(count, score, end = ' ')\n",
    "        total_en, en_score = total_entropy(data, num_classes, log=False)\n",
    "        print(total_en, en_score, end = ' ')\n",
    "        \n",
    "        print('sparse', end = ' ')\n",
    "        data = sparsify(data, log=False)\n",
    "        \n",
    "        count, score = test_uniformity(data, num_classes, log=False)\n",
    "        print(count, score, end = ' ')\n",
    "        total_en, en_score = total_entropy(data, num_classes, log=False)\n",
    "        print(total_en, en_score, end = ' ')\n",
    "        \n",
    "        print(\"Nh \", homophily(data.edge_index, data.y, method='node'), end = ' ')\n",
    "        print(\"Eh \", homophily(data.edge_index, data.y, method='edge'), end = ' ')\n",
    "        print(\"EiH \", homophily(data.edge_index, data.y, method='edge_insensitive'), end = ' ')    \n",
    "        \n",
    "#         print(\"Ha \", agg_homophily(data, 'affinity'), end = ' ')\n",
    "#         print(\"Hl \", agg_homophily(data, 'laplacian'), end =' ')\n",
    "        \n",
    "        print(\"D \", data.num_edges / data.num_nodes, end = '\\n')\n",
    "\n",
    "\n",
    "# LOG_INFO = False\n",
    "# test_hetero()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd1712",
   "metadata": {},
   "source": [
    "# Ablation studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "505da1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import generate_synthetic2homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f746ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reed98 - 10 Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.6528497409326425, 0.6528497409326425, 0.6424870466321243] [107, 117, 195]\n",
      "reed98 - 10 acc 64.9396 sd 0.4885 itr 139 sd 39\n",
      "amherst41 - 10 Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.7762863534675615, 0.7785234899328859, 0.785234899328859] [61, 59, 50]\n",
      "amherst41 - 10 acc 78.0015 sd 0.3802 itr 56 sd 4\n",
      "cornell5 - 10 Metric:  cosine\n",
      "Pool Size:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 18660/18660 [00:22<00:00, 843.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.7722400857449089, 0.7805466237942122, 0.7751875669882101] [28, 48, 40]\n",
      "cornell5 - 10 acc 77.5991 sd 0.3438 itr 38 sd 8\n",
      "Squirrel - 10 Metric:  cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 5201/5201 [00:07<00:00, 716.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.6839577329490875, 0.6791546589817483, 0.654178674351585] [76, 82, 87]\n",
      "Squirrel - 10 acc 67.2430 sd 1.3054 itr 81 sd 4\n",
      "johnshopkins55 - 10 Metric:  cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 5180/5180 [00:07<00:00, 663.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.7847490347490348, 0.7722007722007722, 0.7673745173745173] [59, 50, 56]\n",
      "johnshopkins55 - 10 acc 77.4775 sd 0.7323 itr 55 sd 3\n",
      "Chameleon - 10 Metric:  cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 2277/2277 [00:01<00:00, 1696.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weights  knncosine\n",
      "Loading weights  knncosine\n",
      "Loading weights  knncosine\n",
      "[0.7192982456140351, 0.7456140350877193, 0.7039473684210527] [134, 130, 141]\n",
      "Chameleon - 10 acc 72.2953 sd 1.7206 itr 135 sd 4\n",
      "Runtime:  2593.0342602729797\n"
     ]
    }
   ],
   "source": [
    "def ablation(num_run = 1):\n",
    "    \n",
    "    #SYN_NAME = random.randint(0,1000)\n",
    "\n",
    "#     ALL_DATASETs= [\n",
    "#         'Wisconsin',\n",
    "#         'reed98',        \n",
    "#         'Roman-empire',\n",
    "#         'Actor',\n",
    "#         'Minesweeper',        \n",
    "#         'Tolokers'\n",
    "#     ]\n",
    "\n",
    "    ALL_DATASETs= [\n",
    "        \"reed98\",\n",
    "        \"amherst41\",\n",
    "#         \"penn94\",\n",
    "        \"cornell5\",\n",
    "        \"Squirrel\",\n",
    "        \"johnshopkins55\",\n",
    "        \"Chameleon\",\n",
    "#         \"Tolokers\",\n",
    "#         \"Flickr\",\n",
    "        \n",
    "#         \"Computers\",\n",
    "#         \"Photo\",\n",
    "#         \"Physics\",\n",
    "        \n",
    "#         \"AmazonProducts\",\n",
    "#         \"Yelp\",\n",
    "#         'pokec',\n",
    "#         'twitch-gamer',\n",
    "#         'wiki',        \n",
    "        \n",
    "#         \"Reddit\",\n",
    "#         \"Reddit2\",\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \n",
    "#     ALL_DATASETs= [\"Cora\"]\n",
    "    \n",
    "    args.log_info = False    \n",
    "    \n",
    "    filename = \"Results/AGSGNN-NS-2Ablation.txt\"\n",
    "    \n",
    "    for DATASET_NAME in ALL_DATASETs:  \n",
    "        \n",
    "        random_state = 10\n",
    "        #args.recompute = True\n",
    "        \n",
    "        print(DATASET_NAME,\"-\",random_state, end=' ')\n",
    "        \n",
    "        \n",
    "        result_file = open(filename,'a+')        \n",
    "        result_file.write(f'{DATASET_NAME} ')\n",
    "        result_file.close()\n",
    "                \n",
    "        accs = []\n",
    "        itrs = []\n",
    "                \n",
    "        for i in range(num_run):\n",
    "            data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=False, split_no=i)   \n",
    "            \n",
    "            d = 100\n",
    "            h =0.50\n",
    "            train=0.1\n",
    "            balance=True\n",
    "            h2 = 0.25\n",
    "            ratio = 0.50\n",
    "                                    \n",
    "#             global data_filename_extension\n",
    "#             data_filename_extension = str(d)+str(h)+str(train)+str(random_state)+str(balance)+'.weight'            \n",
    "#             data_filename = DIR+'AGSGNNstruc/'+DATASET_NAME+str(d)+str(h)+str(train)+str(random_state)+str(balance)\n",
    "            \n",
    "#             if os.path.exists(data_filename):\n",
    "#                 data = torch.load(data_filename)                \n",
    "#                 print(\"loaded \"+data_filename)\n",
    "#             else:\n",
    "#                 data = generate_synthetic(data, d=d, h=h, train=train, random_state=random_state, log=False, balance=balance)\n",
    "# #                 data = generate_synthetic(data, d=d, h=h, train=train, random_state=random_state, log=False)\n",
    "#                 torch.save(data,data_filename)\n",
    "#                 print(\"saved \"+data_filename)\n",
    "        \n",
    "#             global data_filename_extension\n",
    "#             data_filename_extension = str(d)+str(h)+str(h2)+str(ratio)+str(train)+str(random_state)+str(balance)+'.weight'            \n",
    "#             data_filename = DIR+'AGSGNNstruc/'+DATASET_NAME+str(d)+str(h)+str(h2)+str(ratio)+str(train)+str(random_state)+str(balance)\n",
    "            \n",
    "#             if os.path.exists(data_filename):\n",
    "#                 data = torch.load(data_filename)                \n",
    "#                 print(\"loaded \"+data_filename)\n",
    "#             else:\n",
    "#                 data = generate_synthetic2homophily(data, d=d, h1=h, h2=h2, ratio=ratio, train=train, random_state=random_state, log=False, balance=balance)                 \n",
    "#                 torch.save(data,data_filename)\n",
    "#                 print(\"saved \"+data_filename)\n",
    "    \n",
    "            ##Sparsifiy\n",
    "            #data = random_sparsify(data, 13, log = True)\n",
    "#             data = sparsify(data, log = True, method = 'submodular', metric= 'cosine')\n",
    "                        \n",
    "#             data1 = sparsify(copy.deepcopy(data), log = True, method = 'submodular', metric= 'cosine')\n",
    "#             data = sparsify(data, log = True, method = 'nn', metric= 'cosine')                         \n",
    "#             data.edge_index = torch.cat((data.edge_index, data1.edge_index), dim=1)\n",
    "            \n",
    "            #optional for making undirected graph\n",
    "            (row, col) = data.edge_index\n",
    "            data.edge_index = torch.stack((torch.cat((row, col),dim=0),torch.cat((col, row),dim=0)),dim=0)\n",
    "            data.edge_index = torch_geometric.utils.coalesce(data.edge_index)\n",
    "            \n",
    "            if args.log_info:\n",
    "                print(\"Node Homophily:\", homophily(data.edge_index, data.y, method='node'))\n",
    "                print(\"Edge Homophily:\", homophily(data.edge_index, data.y, method='edge'))\n",
    "                print(\"Edge_insensitive Homophily:\", homophily(data.edge_index, data.y, method='edge_insensitive'))    \n",
    "                print(\"Degree: \", data.num_edges / data.num_nodes)\n",
    "\n",
    "            \n",
    "#             if data.num_nodes>100000:\n",
    "#                 accs.append(-1)\n",
    "#                 itrs.append(-1)\n",
    "#                 break\n",
    "            \n",
    "            if len(data.y.shape) > 1:\n",
    "                data.y = data.y.argmax(dim=1)        \n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            else:\n",
    "                num_classes = dataset.num_classes\n",
    "            \n",
    "            if num_classes!= torch.max(data.y)+1:\n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "                \n",
    "            if data.num_nodes<100000:\n",
    "                max_epochs = 500\n",
    "            else:\n",
    "                max_epochs = 20\n",
    "                \n",
    "            if DATASET_NAME in ['Squirrel', 'Chameleon','cornell5','penn94','johnshopkins55','amherst41']:\n",
    "                data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "                if args.log_info == True:\n",
    "                    print(data.x.shape)\n",
    "\n",
    "#             accuracy, itr = 0,0\n",
    "            \n",
    "#             accuracy, itr, mdl = AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs, train_neighbors=[25,25], test_neighbors=[25,25])        \n",
    "            accuracy, itr, mdl = AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs, train_neighbors=[8,4], test_neighbors=[8,4])            \n",
    "#             accuracy, itr, mdl = AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs, train_neighbors=[4,4], test_neighbors=[4,4])            \n",
    "#             accuracy, itr, mdl = AGSNSperformanceSampler(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs, train_neighbors=[-1,-1], test_neighbors=[-1,-1])\n",
    "            \n",
    "            #print(mdl)\n",
    "            #args.recompute = False\n",
    "    \n",
    "            accs.append(accuracy)\n",
    "            itrs.append(itr)\n",
    "            #print(itr, accuracy)\n",
    "                        \n",
    "        print(accs, itrs)\n",
    "        print(DATASET_NAME,\"-\",random_state, end=' ')\n",
    "        print(f'acc {np.mean(accs)*100:0.4f} sd {np.std(accs)*100:0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}')\n",
    "        result_file = open(filename,'a+')\n",
    "        result_file.write(f'acc {np.mean(accs)*100:0.4f} sd {np.std(accs)*10:0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}\\n')\n",
    "        result_file.close()\n",
    "                \n",
    "    return \n",
    "\n",
    "# st_time = time.time()\n",
    "# ablation(num_run=3)\n",
    "# en_time = time.time()\n",
    "\n",
    "# print(\"Runtime: \", en_time-st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ca0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef0592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776ba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
