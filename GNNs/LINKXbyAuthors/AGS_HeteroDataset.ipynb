{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62baaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not os.getcwd().endswith(\"Submodular\"):\n",
    "    sys.path.append('../../Submodular')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283c5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1adb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import get_data\n",
    "from ipynb.fs.full.Dataset import datasets as available_datasets\n",
    "from ipynb.fs.full.Utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f88a3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_undirected, sort_edge_index\n",
    "from torch_geometric.data import NeighborSampler, ClusterData, ClusterLoader, Data, GraphSAINTNodeSampler, GraphSAINTEdgeSampler, GraphSAINTRandomWalkSampler, RandomNodeSampler\n",
    "from torch_scatter import scatter\n",
    "\n",
    "from logger import Logger, SimpleLogger\n",
    "from dataset import load_nc_dataset, NCDataset\n",
    "from data_utils import normalize, gen_normalized_adjs, evaluate, eval_acc, eval_rocauc, to_sparse_tensor\n",
    "from parse import parse_method, parser_add_main_args\n",
    "from batch_utils import nc_dataset_to_torch_geo, torch_geo_to_nc_dataset, AdjRowLoader, make_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cdfdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "#set default arguments here\n",
    "def get_configuration():\n",
    "    \n",
    "    parser = ArgumentParser()\n",
    "    \n",
    "    ### Parse args ###\n",
    "    parser = argparse.ArgumentParser(description='General Training Pipeline')\n",
    "    parser_add_main_args(parser)\n",
    "    parser.add_argument('--train_batch', type=str, default='cluster', help='type of mini batch loading scheme for training GNN')\n",
    "    parser.add_argument('--no_mini_batch_test', action='store_true', help='whether to test on mini batches as well')\n",
    "    parser.add_argument('--batch_size', type=int, default=10000)\n",
    "    parser.add_argument('--num_parts', type=int, default=100, help='number of partitions for partition batching')\n",
    "    parser.add_argument('--cluster_batch_size', type=int, default=1, help='number of clusters to use per cluster-gcn step')\n",
    "    parser.add_argument('--saint_num_steps', type=int, default=5, help='number of steps for graphsaint')\n",
    "    parser.add_argument('--test_num_parts', type=int, default=10, help='number of partitions for testing')\n",
    "    \n",
    "    #parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--log_info', type=bool, default=True)\n",
    "    parser.add_argument('--pbar', type=bool, default=False)\n",
    "    #parser.add_argument('--batch_size', type=int, default=2048)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    #parser.add_argument('--dataset', type=str, default=\"Cora\", choices=available_datasets)\n",
    "    #parser.add_argument('--use_normalization', action='store_false', default=True)\n",
    "    parser.add_argument('--use_normalization', action='store_true')    \n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    return args, dict_args\n",
    "\n",
    "args, dict_args = get_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3b96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.datasets import LINKXDataset\n",
    "# from torch_geometric.nn import LINKX\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn import GCNConv, SGConv, GATConv, JumpingKnowledge, APPNP, GCN2Conv, MessagePassing\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "import scipy.sparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032af89",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b7b287c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args.log_info = True\n",
    "\n",
    "DATASET_NAME = 'Cora'\n",
    "args.dataset = DATASET_NAME\n",
    "gnn_name = 'linkx'\n",
    "\n",
    "args.method = gnn_name\n",
    "args.train_batch = 'random'\n",
    "args.num_parts = 100\n",
    "\n",
    "# data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=True, split_no=0); print(\"\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d026fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1ySNspxbK-snNoAZM7oxiWGvOnTRdSyEK\n",
      "From (redirected): https://drive.google.com/uc?id=1ySNspxbK-snNoAZM7oxiWGvOnTRdSyEK&confirm=t&uuid=122487d5-be2a-44da-b97c-f978dcaeed8e\n",
      "To: /scratch/gilbreth/das90/Dataset/LINKX/data/wiki_features2M.pt\n",
      "100%|██████████| 4.62G/4.62G [00:39<00:00, 118MB/s] \n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=14X7FlkjrlUgmnsYtPwdh-gGuFla4yb5u\n",
      "From (redirected): https://drive.google.com/uc?id=14X7FlkjrlUgmnsYtPwdh-gGuFla4yb5u&confirm=t&uuid=265be899-a60c-4443-9f74-36520d73f3f3\n",
      "To: /scratch/gilbreth/das90/Dataset/LINKX/data/wiki_edges2M.pt\n",
      "100%|██████████| 4.85G/4.85G [00:34<00:00, 140MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1p5DlVHrnFgYm3VsNIzahSsvCD424AyvP\n",
      "To: /scratch/gilbreth/das90/Dataset/LINKX/data/wiki_views2M.pt\n",
      "100%|██████████| 15.4M/15.4M [00:00<00:00, 83.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges shape: torch.Size([2, 303434860])\n",
      "features shape: 1925342\n",
      "Label shape: 1925342\n"
     ]
    }
   ],
   "source": [
    "# args.dataset = 'fb100'\n",
    "# args.sub_dataset = 'Penn94'\n",
    "\n",
    "#pokec, arxiv-year\n",
    "\n",
    "args.dataset = 'wiki'\n",
    "args.sub_dataset = ''\n",
    "\n",
    "dataset = load_nc_dataset(args.dataset, args.sub_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76a2fa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'edge_index': tensor([[      0,       0,       0,  ..., 1924550, 1924550, 1924550],\n",
       "          [      1,       2,       3,  ...,  557978,   61041, 1920560]]),\n",
       "  'edge_feat': None,\n",
       "  'node_feat': tensor([[ 1.2721e-01, -1.1162e-01,  6.0405e-03,  ..., -1.0686e-01,\n",
       "           -5.9631e-02, -7.6529e-03],\n",
       "          [-1.7307e-01, -4.5984e-02,  2.5106e-01,  ..., -8.6675e-02,\n",
       "           -7.4201e-02,  4.2817e-02],\n",
       "          [-1.6128e-01,  2.4741e-01, -2.0739e-02,  ..., -1.2163e-01,\n",
       "           -2.8721e-02, -1.8481e-02],\n",
       "          ...,\n",
       "          [ 2.2221e-01,  1.4399e-01,  8.5297e-02,  ..., -1.5650e-01,\n",
       "           -1.5056e-01,  1.0138e-02],\n",
       "          [-8.9892e-02,  9.6628e-02,  1.5188e-02,  ..., -1.2053e-01,\n",
       "           -8.2116e-02, -4.7099e-02],\n",
       "          [-1.6750e-04,  8.1035e-02,  1.0128e-01,  ..., -1.0855e-01,\n",
       "           -1.6818e-01,  5.5043e-03]]),\n",
       "  'num_nodes': 1925342},\n",
       " tensor([ 4,  4,  4,  ..., -1, -1, -1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1fce03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data = nc_dataset_to_torch_geo(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc719314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1925342, 600], edge_index=[2, 303434860], y=[1925342], node_ids=[1925342], mask=[1925342])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55e56511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FileName = DIR + 'LINKXdataset/'+ args.dataset+'.pt'\n",
    "\n",
    "# # print(FileName)\n",
    "# # if not os.path.exists(FileName):\n",
    "# #         os.makedirs(FileName)\n",
    "\n",
    "# torch.save(geo_data,FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3debc489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/gilbreth/das90/Dataset/LINKXdataset/wiki/\n"
     ]
    }
   ],
   "source": [
    "FolderName = DIR + 'LINKXdataset/'+ args.dataset+'/'\n",
    "\n",
    "print(FolderName)\n",
    "if not os.path.exists(FolderName):\n",
    "        os.makedirs(FolderName)\n",
    "        \n",
    "    \n",
    "torch.save(geo_data.x, FolderName+'x.pt')\n",
    "torch.save(geo_data.edge_index, FolderName+'edge_index.pt')\n",
    "torch.save(geo_data.y, FolderName+'y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa53c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import AttributedGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a37486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blogcatalog()\n",
      "Data(x=[5196, 8189], edge_index=[2, 343486], y=[5196])\n",
      "Ppi()\n",
      "Data(x=[56944, 50], edge_index=[2, 1612348], y=[56944, 121])\n",
      "Facebook()\n",
      "Data(x=[4039, 1283], edge_index=[2, 88234], y=[4039, 193])\n",
      "Twitter()\n",
      "Data(x=[81306, 216839, nnz=94616433], edge_index=[2, 2420766], y=[81306, 4065])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://docs.google.com/uc?export=download&id=1ggraUMrQgdUyA3DjSRzzqMv0jFkU65V5&confirm=t\n",
      "Extracting /scratch/gilbreth/das90/Dataset/AttributedGraphDatasetPYG2/mag/raw/uc\n",
      "Processing...\n"
     ]
    }
   ],
   "source": [
    "# datasets = [\"BlogCatalog\", \"PPI\", \"Facebook\", \"Twitter\", \"MAG\"]\n",
    "\n",
    "# #DATASET_NAME in [\"BlogCatalog\", \"PPI\", \"Facebook\", \"Twitter\", \"TWeibo\", \"MAG\"]:\n",
    "\n",
    "# for DATASET_NAME in datasets:\n",
    "\n",
    "# #DATASET_NAME = \"BlogCatalog\"        \n",
    "#     dataset = AttributedGraphDataset(root=DIR+'/AttributedGraphDatasetPYG2', name=DATASET_NAME)\n",
    "        \n",
    "#     print(dataset)\n",
    "#     print(dataset[0])        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cu117pyg200",
   "language": "python",
   "name": "py311cu117pyg200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
