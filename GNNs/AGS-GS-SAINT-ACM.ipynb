{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44415f5a",
   "metadata": {},
   "source": [
    "# AGS-GNN Graph Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac319c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Submodular')\n",
    "\n",
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782d8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import get_data\n",
    "from ipynb.fs.full.Dataset import datasets as available_datasets\n",
    "from ipynb.fs.full.Utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11e7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "#set default arguments here\n",
    "def get_configuration():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--log_info', type=bool, default=True)\n",
    "    parser.add_argument('--pbar', type=bool, default=False)\n",
    "    parser.add_argument('--batch_size', type=int, default=2048)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    parser.add_argument('--dataset', type=str, default=\"Cora\", choices=available_datasets)\n",
    "    parser.add_argument('--use_normalization', action='store_false', default=True)\n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    return args, dict_args\n",
    "\n",
    "args, dict_args = get_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ae0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141f832",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd4df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv, ChebConv\n",
    "from torch_geometric.nn import GraphConv, TransformerConv\n",
    "from torch_geometric.utils import degree\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ipynb.fs.full.SpatialConv import SpatialConv\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb2011",
   "metadata": {},
   "source": [
    "## Homophilic GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2402dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomophilicNet(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels, end_hidden):\n",
    "        super().__init__()\n",
    "        in_channels = num_features\n",
    "        out_channels = num_classes\n",
    "        self.conv1 = GraphConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "#         self.lin = torch.nn.Linear(3 * hidden_channels, end_hidden)\n",
    "#         self.lin2 = torch.nn.Linear(3 * hidden_channels, out_channels)\n",
    "        self.lin = torch.nn.Linear(2 * hidden_channels, end_hidden)\n",
    "        self.lin2 = torch.nn.Linear(2 * hidden_channels, out_channels)\n",
    "\n",
    "\n",
    "    def set_aggr(self, aggr):\n",
    "        self.conv1.aggr = aggr\n",
    "        self.conv2.aggr = aggr\n",
    "#         self.conv3.aggr = aggr\n",
    "\n",
    "    def forward(self, x0, edge_index, edge_weight=None):\n",
    "        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))\n",
    "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
    "        x2 = F.relu(self.conv2(x1, edge_index, edge_weight))\n",
    "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
    "#         x3 = F.relu(self.conv3(x2, edge_index, edge_weight))\n",
    "#         x3 = F.dropout(x3, p=0.2, training=self.training)\n",
    "#         x = torch.cat([x1, x2, x3], dim=-1)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=-1)\n",
    "        \n",
    "        c1 = self.lin(x)\n",
    "        c2 = self.lin2(x)\n",
    "        \n",
    "        return F.relu(c1), c2.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525b2fa",
   "metadata": {},
   "source": [
    "## Heterophilic GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3777acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace this part with ACMGCN\n",
    "#import ACM.modelgeom.layers as layers\n",
    "from ACM.modelgeom.models import GCN\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils.convert import to_scipy_sparse_matrix\n",
    "from ipynb.fs.full.ACM.models.Test import normalize_tensor, sparse_mx_to_torch_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad18eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeterophilicNet(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels, end_hidden, N):\n",
    "        super().__init__()\n",
    "        in_channels = num_features\n",
    "        out_channels = num_classes\n",
    "                \n",
    "        self.hetero_gnn  = GCN(\n",
    "            nfeat=num_features,\n",
    "            nhid=hidden_channels,\n",
    "            nclass=hidden_channels,\n",
    "            nlayers=2,\n",
    "            nnodes=N,\n",
    "            dropout=0.2,\n",
    "            model_type='acmgcnp',\n",
    "            structure_info=1,\n",
    "            variant=True,)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_channels, end_hidden)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "                \n",
    "        n = batch_data.num_nodes\n",
    "        x = batch_data.x\n",
    "        \n",
    "        #print(batch_data)\n",
    "        \n",
    "        edge_index, _ = torch_geometric.utils.add_self_loops(batch_data.edge_index, num_nodes=n)\n",
    "        \n",
    "        adj_low_unnormalized = to_scipy_sparse_matrix(edge_index)\n",
    "        \n",
    "#         print(sp.identity(n).shape)\n",
    "#         print(adj_low_unnormalized.shape)\n",
    "        \n",
    "        \n",
    "        adj_low = normalize_tensor(sp.identity(n) + adj_low_unnormalized)\n",
    "        adj_high = sp.identity(n) - adj_low\n",
    "        adj_low = sparse_mx_to_torch_sparse_tensor(adj_low).to(device)\n",
    "        adj_high = sparse_mx_to_torch_sparse_tensor(adj_high).to(device)\n",
    "        adj_low_unnormalized = sparse_mx_to_torch_sparse_tensor(adj_low_unnormalized).to(device)\n",
    "\n",
    "#         print(x.device, adj_low.device, adj_high.device, adj_low_unnormalized.device)\n",
    "        \n",
    "        x = self.hetero_gnn(x, adj_low, adj_high, adj_low_unnormalized)\n",
    "        \n",
    "        c1 = self.lin(x)\n",
    "        c2 = self.lin2(x)\n",
    "        \n",
    "        return F.relu(c1), c2.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ef962",
   "metadata": {},
   "source": [
    "## Combination Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24c3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGSGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features,num_classes, hidden_channels=256, dropout=0.5, N = 0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        hidden = int(hidden_channels/2)        \n",
    "        self.gnn1 = HomophilicNet(num_features, num_classes, hidden_channels, hidden)\n",
    "        self.gnn2 = HeterophilicNet(num_features, num_classes, hidden_channels, hidden, N = N)\n",
    "        self.p = dropout\n",
    "        self.com_lin = nn.Linear(hidden*2, num_classes)      \n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        \n",
    "        #out = model(batch_data.x, batch_data.edge_index, batch_data.edge_weight)\n",
    "        #out = model(batch_data.x, batch_data.edge_index)\n",
    "        \n",
    "        x1, x1c1 = self.gnn1(batch_data[0].x, batch_data[0].edge_index, batch_data[0].weight)\n",
    "        x2, x2c2 = self.gnn2(batch_data[1])\n",
    "\n",
    "#         x1 = self.gnn1(batch_data[0].x, batch_data[0].edge_index)\n",
    "#         x2 = self.gnn2(batch_data[1].x, batch_data[1].edge_index)\n",
    "\n",
    "        a1 = F.relu(x1)\n",
    "        a1 = F.dropout(a1, p=self.p, training=self.training)\n",
    "        \n",
    "        s1 = F.relu(x2)        \n",
    "        s1 = F.dropout(s1, p=self.p, training=self.training)\n",
    "        \n",
    "        batch_size = batch_data[0].batch_size        \n",
    "        x = torch.cat([a1[:batch_size,:], s1[:batch_size,:]], dim=-1)\n",
    "        x = self.com_lin(x)\n",
    "        \n",
    "        #return x\n",
    "    \n",
    "        return x.log_softmax(dim=-1), x1c1, x2c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b17b8e",
   "metadata": {},
   "source": [
    "## GNN Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11e841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.a2AGS_Graph_Sampler import AGSGraphSampler\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83409b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def prediction(y_pred_seed, y_pred_hm, y_pred_ht):\n",
    "    \n",
    "    all_tensors = [y_pred_seed, y_pred_hm, y_pred_ht]\n",
    "    final_predictions = []\n",
    "\n",
    "    for i in range(len(y_pred_seed)):\n",
    "        values_at_index = [tensor[i].item() for tensor in all_tensors]\n",
    "        counter = Counter(values_at_index)\n",
    "        most_common_values = counter.most_common()\n",
    "\n",
    "        # Check if there's a tie\n",
    "        if len(most_common_values) > 1 and most_common_values[0][1] == most_common_values[1][1]:\n",
    "            #selected_value = random.choice([value for value, count in most_common_values[:2]])\n",
    "            selected_value = y_pred_seed[i].item()\n",
    "        else:\n",
    "            selected_value = most_common_values[0][0]\n",
    "\n",
    "        final_predictions.append(selected_value)\n",
    "            \n",
    "    return torch.LongTensor(final_predictions)\n",
    "\n",
    "y_pred_seed = torch.tensor([0, 1, 2, 2, 1])\n",
    "y_pred_hm = torch.tensor([2, 1, 1, 0, 2])\n",
    "y_pred_ht = torch.tensor([0, 2, 1, 1, 0])\n",
    "\n",
    "\n",
    "# prediction(y_pred_seed,y_pred_hm,y_pred_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac415e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, mask, name='Train', channel='all'):\n",
    "    if args.log_info:\n",
    "        pbar = tqdm(total=sum(mask).item())\n",
    "        pbar.set_description(f'Evaluating {name}')\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct=0\n",
    "    total_examples=0\n",
    "    \n",
    "    with torch.no_grad():                  \n",
    "    \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            \n",
    "            batch_data = [b_data.to(device) for b_data in batch_data]\n",
    "            batch_size = batch_data[0].batch_size\n",
    "            batch_data[0].weight = batch_data[0].edge_norm * batch_data[0].edge_weight\n",
    "            \n",
    "            out, out1, out2 = model(batch_data)\n",
    "                \n",
    "            #print(out.shape, out1.shape, out2.shape)\n",
    "            \n",
    "            y_pred_seed = out[:batch_size].argmax(dim=-1).cpu()\n",
    "            y_pred_hm = out1[:batch_size].argmax(dim=-1).cpu()\n",
    "            y_pred_ht = out2[:batch_size].argmax(dim=-1).cpu()\n",
    "            \n",
    "            #print(y_pred_seed.shape,y_pred_hm.shape, y_pred_ht.shape)\n",
    "            \n",
    "            \n",
    "            y_true = batch_data[0].y[:batch_size]\n",
    "            \n",
    "            if name == 'Train':\n",
    "                t_mask = batch_data[0].train_mask[:batch_size]\n",
    "            elif name == 'Validation':\n",
    "                t_mask = batch_data[0].val_mask[:batch_size]\n",
    "            else:\n",
    "                t_mask = batch_data[0].test_mask[:batch_size]\n",
    "\n",
    "            if channel=='sd':\n",
    "                y_pred = y_pred_seed\n",
    "            elif channel=='hm':\n",
    "                y_pred = y_pred_hm\n",
    "            elif channel=='ht':\n",
    "                y_pred = y_pred_ht\n",
    "            else:\n",
    "                y_pred = prediction(y_pred_seed, y_pred_hm, y_pred_ht)\n",
    "\n",
    "            #print(y_pred)                \n",
    "            correct = y_pred.eq(y_true.cpu())\n",
    "            total_correct+= correct[t_mask].sum().item()\n",
    "            items = t_mask.sum().item()\n",
    "            total_examples+= items           \n",
    "            if args.log_info:\n",
    "                pbar.update(items)\n",
    "    \n",
    "    if args.log_info:\n",
    "        pbar.close()\n",
    "\n",
    "    return total_correct/total_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85fa0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/GraphSAINT/GraphSAINT/issues/11\n",
    "    \n",
    "def train(DATASET_NAME,model, data, dataset, epochs=1, channel='all', BATCH_SIZE=1024): #'all', 'hm', 'ht', 'sd'\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)    \n",
    "    if data.y.ndim == 1:\n",
    "        criterion = torch.nn.CrossEntropyLoss() #regular logits as output\n",
    "#         criterion = torch.nn.NLLLoss() ## if log softmax used as activation\n",
    "    else:\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()     #multillabel\n",
    "    \n",
    "    row, col = data.edge_index\n",
    "    data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.\n",
    "    \n",
    "    #minibatch_size= 2048\n",
    "    minibatch_size = BATCH_SIZE\n",
    "    \n",
    "    sampler_dir = DIR+'AGSGSAINTACM/'+DATASET_NAME\n",
    "    if not os.path.exists(sampler_dir):\n",
    "        os.makedirs(sampler_dir)\n",
    "        \n",
    "    #batch_size= min(1024, data.num_nodes)\n",
    "    #num_steps=math.ceil(sum (data.train_mask)/batch_size)    \n",
    "    num_steps=math.ceil(data.num_nodes/minibatch_size)\n",
    "    num_workers = 8  if data.num_nodes>50000 else 0\n",
    "    \n",
    "    \n",
    "    sample_func =['rw', 'rw']\n",
    "    weight_func =[\n",
    "        {'exact':False,'weight':'random'}, #exact for exact size to the batch\n",
    "        {'exact':True,'weight':'random'}\n",
    "    ]\n",
    "\n",
    "    params={'knn':{'metric':'cosine'},\n",
    "            'submodular':{'metric':'cosine'},\n",
    "            'link-nn':{'value':'min'},\n",
    "            'link-sub':{'value':'max'},\n",
    "            'disjoint':{'value':'mst'},\n",
    "           }\n",
    "    \n",
    "    loader = AGSGraphSampler(\n",
    "        data, batch_size=minibatch_size, walk_length=2, num_steps=num_steps, sample_coverage=100,\n",
    "        num_workers=num_workers,log=args.log_info,save_dir=sampler_dir,recompute = False, shuffle = False,\n",
    "        sample_func = sample_func, weight_func=weight_func, params=params)\n",
    "        \n",
    "    \n",
    "    #for evaluation\n",
    "    train_num_steps = int(torch.ceil(sum(data.train_mask)/minibatch_size))\n",
    "    val_num_steps = int(torch.ceil(sum(data.val_mask)/minibatch_size))\n",
    "    test_num_steps = int(torch.ceil(sum(data.test_mask)/minibatch_size))\n",
    "    \n",
    "    train_loader = AGSGraphSampler(\n",
    "        data, input_nodes = data.train_mask, batch_size=minibatch_size, walk_length=2, num_steps=train_num_steps, \n",
    "        sample_coverage=100,num_workers=num_workers,log=args.log_info,save_dir=sampler_dir,\n",
    "        recompute = False, shuffle = False,sample_func = sample_func, weight_func=weight_func, params=params)\n",
    "    \n",
    "    \n",
    "    val_loader = AGSGraphSampler(\n",
    "        data, input_nodes = data.val_mask, batch_size=minibatch_size, walk_length=2, num_steps=val_num_steps, \n",
    "        sample_coverage=100,num_workers=num_workers,log=args.log_info,save_dir=sampler_dir,\n",
    "        recompute = False, shuffle = False,sample_func = sample_func, weight_func=weight_func, params=params)\n",
    "        \n",
    "    test_loader = AGSGraphSampler(\n",
    "        data, input_nodes = data.test_mask, batch_size=minibatch_size, walk_length=2, num_steps=test_num_steps, \n",
    "        sample_coverage=100,num_workers=num_workers,log=args.log_info,save_dir=sampler_dir,\n",
    "        recompute = False, shuffle = False,sample_func = sample_func, weight_func=weight_func, params=params)\n",
    "            \n",
    "            \n",
    "    best_acc=0    \n",
    "    train_losses = []; val_accuracies = []; train_accuracies = []; test_accuracies = []    \n",
    "    max_iteration = epochs    \n",
    "    \n",
    "    \n",
    "    th_node = 10000\n",
    "    \n",
    "    if (minibatch_size == data.num_nodes) and data.num_nodes<th_node:\n",
    "        test_data = data.clone()\n",
    "        test_data.weight = loader.edge_norm * test_data.edge_weight\n",
    "        test_data.seed_node=torch.arange(test_data.num_nodes)  \n",
    "        test_data.batch_size=test_data.seed_node.shape[0]\n",
    "        all_data = [test_data.to(device), test_data.to(device)]    \n",
    "        \n",
    "        if args.log_info:\n",
    "            print(all_data)\n",
    "            \n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar = tqdm(total=num_steps)\n",
    "            pbar.set_description(f'Epoch {epoch:02d}')\n",
    "        \n",
    "        model.train()\n",
    "        #if model.__class__.__name__ == 'Net':\n",
    "            #model.set_aggr('add' if args.use_normalization else 'mean')\n",
    "        model.gnn1.set_aggr('add' if args.use_normalization else 'mean')\n",
    "        #model.gnn2.set_aggr('add' if args.use_normalization else 'mean')\n",
    "\n",
    "        total_loss = total_examples = 0\n",
    "        total_loss_seed = total_loss_hm = total_loss_ht = 0\n",
    "        total_seed_example = total_hm_example = total_ht_example = 0\n",
    "                    \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            \n",
    "#             print(batch_data);\n",
    "#             print(\"*\"*50)            \n",
    "            \n",
    "            batch_data = [b_data.to(device) for b_data in batch_data]\n",
    "            batch_size = batch_data[0].batch_size\n",
    "            mask = batch_data[0].train_mask[:batch_size]\n",
    "            y_true = batch_data[0].y[:batch_size]\n",
    "            \n",
    "            if torch.sum(mask) == 0:\n",
    "                print(\"no training mask in seed node\")\n",
    "#                 continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if args.use_normalization:                 \n",
    "                \n",
    "                batch_data[0].weight = batch_data[0].edge_norm * batch_data[0].edge_weight\n",
    "                batch_data[1].weight = batch_data[1].edge_norm * batch_data[1].edge_weight\n",
    "                \n",
    "                out, out1, out2 = model(batch_data)                            \n",
    "                #print(out.shape, out1.shape, out2.shape)\n",
    "                \n",
    "                                \n",
    "#                 print(out[:batch_size][mask].shape, y_true[mask].shape)                \n",
    "#                 print(loss.shape)\n",
    "#                 print(batch_data[0].node_norm.shape)\n",
    "#                 print(batch_data[0].node_norm[:batch_size].shape)\n",
    "#                 loss = criterion(out, batch_data.y, reduction='none')\n",
    "\n",
    "                #--------- loss computation seed nodes --------- #                \n",
    "                loss_seed = F.nll_loss(out[:batch_size][mask], y_true[mask], reduction='none')\n",
    "                loss_seed = (loss_seed * batch_data[0].node_norm[:batch_size][mask]).sum()\n",
    "        \n",
    "                #--------- loss computation homophily nodes --------- #\n",
    "            \n",
    "                loss_hm = F.nll_loss(out1[batch_data[0].train_mask], batch_data[0].y[batch_data[0].train_mask], reduction='none')\n",
    "                loss_hm = (loss_hm * batch_data[0].node_norm[batch_data[0].train_mask]).sum()\n",
    "                \n",
    "                #--------- loss computation homophily nodes --------- #\n",
    "                loss_ht = F.nll_loss(out2[batch_data[1].train_mask], batch_data[1].y[batch_data[1].train_mask], reduction='none')\n",
    "                loss_ht = (loss_ht * batch_data[1].node_norm[batch_data[1].train_mask]).sum()\n",
    "                \n",
    "                if channel=='sd':loss = loss_seed\n",
    "                elif channel=='hm':loss = loss_hm\n",
    "                elif channel=='ht':loss = loss_ht\n",
    "                else:loss = loss_seed + loss_hm + loss_ht                \n",
    "\n",
    "            else:\n",
    "                batch_data[0].weight = None\n",
    "                batch_data[1].weight = None\n",
    "                    \n",
    "                out, out1, out2 = model(batch_data)                            \n",
    "                #print(out.shape, out1.shape, out2.shape)\n",
    "                \n",
    "                mask = batch_data[0].train_mask[:batch_size]\n",
    "                y_true = batch_data[0].y[:batch_size]\n",
    "                \n",
    "                #--------- loss computation seed nodes --------- #                \n",
    "                loss_seed = F.nll_loss(out[:batch_size][mask], y_true[mask])\n",
    "                \n",
    "                #--------- loss computation homophily nodes --------- #\n",
    "                loss_hm = F.nll_loss(out1[batch_data[0].train_mask], batch_data[0].y[batch_data[0].train_mask])\n",
    "                \n",
    "                #--------- loss computation homophily nodes --------- #\n",
    "                loss_ht = F.nll_loss(out2[batch_data[1].train_mask], batch_data[1].y[batch_data[1].train_mask])\n",
    "                #loss = criterion(out[batch_data.train_mask], batch_data.y[batch_data.train_mask])\n",
    "                \n",
    "                if channel=='sd':loss = loss_seed\n",
    "                elif channel=='hm':loss = loss_hm\n",
    "                elif channel=='ht':loss = loss_ht\n",
    "                else:loss = loss_seed + loss_hm + loss_ht\n",
    "                                                        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss_seed+= loss_seed.item()*batch_size\n",
    "            total_loss_hm+= loss_hm.item()*sum(batch_data[0].train_mask).item()\n",
    "            total_loss_ht+= loss_ht.item()*sum(batch_data[1].train_mask).item()\n",
    "            \n",
    "            total_seed_example+= sum(mask).item()\n",
    "            total_hm_example+=sum(batch_data[0].train_mask).item()\n",
    "            total_ht_example+=sum(batch_data[1].train_mask).item()\n",
    "            \n",
    "            if args.log_info:\n",
    "                pbar.update(1)\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar.close()\n",
    "            \n",
    "        total_loss_seed /= max(total_seed_example,1)\n",
    "        total_loss_hm /= max(total_hm_example,1)\n",
    "        total_loss_ht /= max(total_ht_example,1)\n",
    "        \n",
    "        total_loss=total_loss_seed+total_loss_hm+total_loss_ht\n",
    "        total_examples = total_seed_example + total_hm_example + total_ht_example\n",
    "        \n",
    "        if args.log_info:\n",
    "            print(f'Loss:{total_loss:0.4f} seed:{total_loss_seed:0.4f} hm:{total_loss_hm:0.4f} ht:{total_loss_ht:0.4f}')\n",
    "            print(f'Example:{total_examples:1d} seed:{total_seed_example:1d} hm:{total_hm_example:1d} ht:{total_ht_example:1d}')\n",
    "        \n",
    "        if channel=='sd':train_losses.append(total_loss_seed)\n",
    "        elif channel=='hm':train_losses.append(total_loss_hm)\n",
    "        elif channel=='ht':train_losses.append(total_loss_ht)\n",
    "        else:train_losses.append(total_loss)\n",
    "                        \n",
    "\n",
    "        model.eval()       \n",
    "        model.gnn1.set_aggr('add' if args.use_normalization else 'mean')\n",
    "#         model.gnn2.set_aggr('add' if args.use_normalization else 'mean')\n",
    "        accs = [0,0,0]\n",
    "        \n",
    "        if (minibatch_size == data.num_nodes) and data.num_nodes<th_node:\n",
    "                        \n",
    "            with torch.no_grad():\n",
    "                out, out1, out2 = model(all_data)\n",
    "                \n",
    "                #print(out.shape, out1.shape, out2.shape)\n",
    "                y_pred_seed = out.argmax(dim=-1).cpu()\n",
    "                y_pred_hm = out1.argmax(dim=-1).cpu()\n",
    "                y_pred_ht = out2.argmax(dim=-1).cpu()\n",
    "                \n",
    "                if channel=='sd':\n",
    "                    y_pred = y_pred_seed\n",
    "                elif channel=='hm':\n",
    "                    y_pred = y_pred_hm\n",
    "                elif channel=='ht':\n",
    "                    y_pred = y_pred_ht\n",
    "                else:\n",
    "                    y_pred = prediction(y_pred_seed, y_pred_hm, y_pred_ht)\n",
    "                \n",
    "                #print(y_pred)                \n",
    "                correct = y_pred.eq(data.y.cpu())\n",
    "                accs = []\n",
    "                for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "                    accs.append(correct[mask].sum().item() / mask.sum().item()) \n",
    "                                                    \n",
    "        else:\n",
    "            accs[0] = test(model, train_loader, data.train_mask, name='Train',channel=channel)\n",
    "            accs[1] = test(model, val_loader, data.val_mask, name='Validation',channel=channel)\n",
    "            accs[2] = test(model, test_loader, data.test_mask, name='Test',channel=channel)\n",
    "            \n",
    "        train_accuracies.append(accs[0])\n",
    "        val_accuracies.append(accs[1])\n",
    "        test_accuracies.append(accs[2])\n",
    "        std_dev = np.std(train_losses[-5:])\n",
    "        \n",
    "        if args.log_info:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Train: {accs[0]:.4f}, Val: {accs[1]:.4f}, Test: {accs[2]:.4f}, Std dev: {std_dev:.4f}')\n",
    "        \n",
    "        if epoch>=5 and std_dev<=1e-3:\n",
    "            if args.log_info:\n",
    "                print(\"Iteration for convergence: \", epoch)\n",
    "            max_iteration = epoch\n",
    "            break\n",
    "    \n",
    "    if args.log_info:\n",
    "        save_plot([train_losses, train_accuracies, val_accuracies, test_accuracies], labels=['Loss','Train','Validation','Test'], name='Results/AGSGSValidation', yname='Accuracy', xname='Epoch')\n",
    "        print (\"Best Validation Accuracy, \",max(val_accuracies))\n",
    "        print (\"Best Test Accuracy, \",max(test_accuracies))\n",
    "    \n",
    "    if (minibatch_size == data.num_nodes) and data.num_nodes<th_node:\n",
    "        del all_data\n",
    "    \n",
    "    return max(test_accuracies), max_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34bee9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGSGSperformanceSampler(DATASET_NAME,data, dataset, num_classes, epochs=1,channel='all'):\n",
    "    \n",
    "    ###\n",
    "    BATCH_SIZE = min(data.num_nodes, 1024)\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(\"BATCH SIZE: \", BATCH_SIZE)\n",
    "        \n",
    "    model = AGSGNN(data.x.shape[1], num_classes, hidden_channels=256, N = BATCH_SIZE).to(device)            \n",
    "    \n",
    "    if args.log_info:\n",
    "        print(model)\n",
    "    \n",
    "    itr, accuracy = train(DATASET_NAME, model, data, dataset, epochs, channel, BATCH_SIZE)\n",
    "    \n",
    "    return itr, accuracy, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ce2248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "def adj_feature(data):    \n",
    "    adj_mat = torch.zeros((data.num_nodes,data.num_nodes))\n",
    "    edges = data.edge_index.t()\n",
    "    adj_mat[edges[:,0], edges[:,1]] = 1\n",
    "    adj_mat[edges[:,1], edges[:,0]] = 1\n",
    "    \n",
    "#     n_components = data.x.shape[1]\n",
    "    n_components = min(256, data.x.shape[1], data.num_nodes)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    x = svd.fit_transform(adj_mat)\n",
    "    \n",
    "    x = torch.Tensor(x)\n",
    "    x.shape    \n",
    "    \n",
    "    return x\n",
    "\n",
    "# x = adj_feature(data)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "586728b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N  5201  E  217073  d  41.73678138819458 0.08891735225915909 0.2239430993795395 0.042996399104595184 0.3737970292568207 Data(x=[5201, 2089], edge_index=[2, 217073], y=[5201], train_mask=[5201], val_mask=[5201], test_mask=[5201])\n",
      "BATCH SIZE:  1024\n",
      "AGSGNN(\n",
      "  (gnn1): HomophilicNet(\n",
      "    (conv1): GraphConv(2089, 256)\n",
      "    (conv2): GraphConv(256, 256)\n",
      "    (lin): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      "  (gnn2): HeterophilicNet(\n",
      "    (hetero_gnn): GCN(\n",
      "      (gcns): ModuleList(\n",
      "        (0): GraphConvolution (2089 -> 256)\n",
      "        (1): GraphConvolution (256 -> 256)\n",
      "      )\n",
      "      (mlps): ModuleList()\n",
      "    )\n",
      "    (lin): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (lin2): Linear(in_features=256, out_features=5, bias=True)\n",
      "  )\n",
      "  (com_lin): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "loading saved norm\n",
      "loading saved norm\n",
      "loading saved norm\n",
      "loading saved norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 6/6 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.7367 seed:1.2648 hm:0.8366 ht:0.6353\n",
      "Example:10240 seed:2654 hm:4649 ht:2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 33748.92it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 47483.87it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 34080.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.6006, Train: 0.2003, Val: 0.2019, Test: 0.1979, Std dev: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 6/6 [00:00<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.7119 seed:1.2470 hm:0.8387 ht:0.6262\n",
      "Example:10386 seed:2697 hm:4717 ht:2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 33822.63it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 46938.11it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31881.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.6279, Train: 0.2007, Val: 0.2007, Test: 0.1979, Std dev: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 6/6 [00:00<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.7038 seed:1.2671 hm:0.8372 ht:0.5995\n",
      "Example:10263 seed:2654 hm:4698 ht:2911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 32600.15it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42181.07it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32325.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.6054, Train: 0.2035, Val: 0.2043, Test: 0.1988, Std dev: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 6/6 [00:00<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.6693 seed:1.2404 hm:0.8311 ht:0.5978\n",
      "Example:10314 seed:2681 hm:4678 ht:2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41987.11it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40056.95it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 17073.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.6278, Train: 0.2151, Val: 0.2145, Test: 0.2200, Std dev: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 6/6 [00:00<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.6551 seed:1.2559 hm:0.8254 ht:0.5739\n",
      "Example:10226 seed:2669 hm:4620 ht:2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 34876.85it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 21520.86it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 26963.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.5654, Train: 0.2841, Val: 0.2620, Test: 0.2469, Std dev: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 6/6 [00:00<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.6403 seed:1.2642 hm:0.8277 ht:0.5485\n",
      "Example:10204 seed:2638 hm:4670 ht:2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 29296.00it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39087.58it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29787.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.5421, Train: 0.3081, Val: 0.2861, Test: 0.2747, Std dev: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 6/6 [00:00<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.5962 seed:1.2470 hm:0.8229 ht:0.5263\n",
      "Example:10198 seed:2634 hm:4673 ht:2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 28415.20it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29906.42it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 33678.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.5358, Train: 0.3321, Val: 0.2957, Test: 0.2997, Std dev: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 6/6 [00:00<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.6319 seed:1.2692 hm:0.8395 ht:0.5232\n",
      "Example:10218 seed:2646 hm:4642 ht:2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 39516.48it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39537.30it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 16811.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.5290, Train: 0.3646, Val: 0.2975, Test: 0.3180, Std dev: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 6/6 [00:00<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.6066 seed:1.2592 hm:0.8379 ht:0.5095\n",
      "Example:10275 seed:2663 hm:4661 ht:2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 27100.72it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42447.87it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29621.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.4946, Train: 0.4103, Val: 0.3071, Test: 0.3208, Std dev: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 6/6 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.5690 seed:1.2362 hm:0.8442 ht:0.4886\n",
      "Example:10519 seed:2740 hm:4753 ht:3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 31333.94it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 26358.35it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 28451.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.5162, Train: 0.4635, Val: 0.3143, Test: 0.3401, Std dev: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 6/6 [00:00<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.5577 seed:1.2502 hm:0.8402 ht:0.4673\n",
      "Example:10245 seed:2638 hm:4669 ht:2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 23526.97it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 37165.57it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29706.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.4490, Train: 0.5048, Val: 0.3269, Test: 0.3391, Std dev: 0.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 6/6 [00:00<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.5285 seed:1.2659 hm:0.8343 ht:0.4284\n",
      "Example:10160 seed:2603 hm:4660 ht:2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42483.44it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 21437.24it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29387.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.4815, Train: 0.5329, Val: 0.3275, Test: 0.3449, Std dev: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 6/6 [00:00<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4820 seed:1.2506 hm:0.8201 ht:0.4114\n",
      "Example:10174 seed:2645 hm:4597 ht:2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 28147.80it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 43944.02it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 27264.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.3818, Train: 0.5593, Val: 0.3329, Test: 0.3497, Std dev: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 6/6 [00:00<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4874 seed:1.2590 hm:0.8363 ht:0.3920\n",
      "Example:10348 seed:2690 hm:4699 ht:2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 32732.14it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 38194.31it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 28808.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.3599, Train: 0.5805, Val: 0.3305, Test: 0.3535, Std dev: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 6/6 [00:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4493 seed:1.2557 hm:0.8348 ht:0.3588\n",
      "Example:10205 seed:2635 hm:4663 ht:2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 33064.51it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 26030.49it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29591.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.3411, Train: 0.6122, Val: 0.3389, Test: 0.3487, Std dev: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 6/6 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4000 seed:1.2391 hm:0.8288 ht:0.3320\n",
      "Example:10338 seed:2701 hm:4641 ht:2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41795.68it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39164.79it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 17226.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.3400, Train: 0.6302, Val: 0.3413, Test: 0.3631, Std dev: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 6/6 [00:00<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4659 seed:1.2730 hm:0.8536 ht:0.3393\n",
      "Example:10329 seed:2662 hm:4711 ht:2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 25342.74it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 41669.83it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36862.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.3616, Train: 0.6518, Val: 0.3377, Test: 0.3641, Std dev: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 6/6 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4124 seed:1.2600 hm:0.8493 ht:0.3032\n",
      "Example:10409 seed:2710 hm:4727 ht:2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41863.87it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 22111.44it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 25736.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.3145, Train: 0.6771, Val: 0.3377, Test: 0.3641, Std dev: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 6/6 [00:00<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4041 seed:1.2629 hm:0.8392 ht:0.3019\n",
      "Example:10322 seed:2686 hm:4680 ht:2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 46025.40it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 41752.84it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 22006.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.3055, Train: 0.6903, Val: 0.3353, Test: 0.3564, Std dev: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 6/6 [00:00<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.4181 seed:1.2776 hm:0.8635 ht:0.2770\n",
      "Example:10476 seed:2722 hm:4767 ht:2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 44554.74it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29030.19it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 35516.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 0.2620, Train: 0.7083, Val: 0.3480, Test: 0.3449, Std dev: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 6/6 [00:00<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.3263 seed:1.2379 hm:0.8299 ht:0.2585\n",
      "Example:10370 seed:2694 hm:4705 ht:2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41406.06it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29689.51it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36949.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Train Loss: 0.2497, Train: 0.7192, Val: 0.3456, Test: 0.3602, Std dev: 0.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 6/6 [00:00<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.3278 seed:1.2520 hm:0.8342 ht:0.2416\n",
      "Example:10346 seed:2688 hm:4692 ht:2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41268.95it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 28865.82it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36727.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Train Loss: 0.2344, Train: 0.7528, Val: 0.3480, Test: 0.3564, Std dev: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 6/6 [00:00<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.3453 seed:1.2625 hm:0.8555 ht:0.2273\n",
      "Example:10541 seed:2762 hm:4745 ht:3034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41078.35it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 31965.24it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 20205.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Train Loss: 0.2352, Train: 0.7732, Val: 0.3594, Test: 0.3602, Std dev: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 6/6 [00:00<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.3416 seed:1.2701 hm:0.8576 ht:0.2140\n",
      "Example:10499 seed:2728 hm:4771 ht:3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 46923.39it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 38072.00it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 20910.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Train Loss: 0.2081, Train: 0.7861, Val: 0.3552, Test: 0.3622, Std dev: 0.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 6/6 [00:00<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2853 seed:1.2541 hm:0.8317 ht:0.1995\n",
      "Example:10302 seed:2674 hm:4679 ht:2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 44952.48it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 32049.05it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36183.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Train Loss: 0.1970, Train: 0.8033, Val: 0.3540, Test: 0.3622, Std dev: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 6/6 [00:00<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2955 seed:1.2623 hm:0.8419 ht:0.1913\n",
      "Example:10325 seed:2687 hm:4689 ht:2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42065.73it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 31810.80it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 30935.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Train Loss: 0.2065, Train: 0.8277, Val: 0.3684, Test: 0.3622, Std dev: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 6/6 [00:00<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2543 seed:1.2570 hm:0.8225 ht:0.1747\n",
      "Example:10150 seed:2623 hm:4630 ht:2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41896.21it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 27495.18it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36731.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Train Loss: 0.1681, Train: 0.8381, Val: 0.3558, Test: 0.3631, Std dev: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 6/6 [00:00<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2827 seed:1.2709 hm:0.8411 ht:0.1708\n",
      "Example:10241 seed:2642 hm:4686 ht:2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 34173.83it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 45293.80it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31158.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Train Loss: 0.1779, Train: 0.8510, Val: 0.3630, Test: 0.3622, Std dev: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 6/6 [00:00<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2817 seed:1.2625 hm:0.8551 ht:0.1640\n",
      "Example:10492 seed:2720 hm:4784 ht:2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 46955.17it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 45817.72it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 25329.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Train Loss: 0.1625, Train: 0.8654, Val: 0.3624, Test: 0.3622, Std dev: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 6/6 [00:00<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.3038 seed:1.2795 hm:0.8659 ht:0.1584\n",
      "Example:10532 seed:2726 hm:4800 ht:3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 47788.30it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 43985.84it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 26813.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Train Loss: 0.1499, Train: 0.8650, Val: 0.3582, Test: 0.3535, Std dev: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 6/6 [00:00<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2642 seed:1.2576 hm:0.8514 ht:0.1552\n",
      "Example:10459 seed:2704 hm:4750 ht:3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 38317.18it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 23979.89it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32478.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Train Loss: 0.1619, Train: 0.8834, Val: 0.3570, Test: 0.3573, Std dev: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 6/6 [00:00<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2433 seed:1.2611 hm:0.8418 ht:0.1404\n",
      "Example:10430 seed:2717 hm:4727 ht:2986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 38980.32it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29469.01it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31972.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Train Loss: 0.1173, Train: 0.8830, Val: 0.3546, Test: 0.3564, Std dev: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 6/6 [00:00<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2374 seed:1.2646 hm:0.8384 ht:0.1344\n",
      "Example:10277 seed:2668 hm:4656 ht:2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 23340.55it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39087.58it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31291.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Train Loss: 0.1288, Train: 0.8998, Val: 0.3600, Test: 0.3641, Std dev: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 6/6 [00:00<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2169 seed:1.2605 hm:0.8279 ht:0.1286\n",
      "Example:10106 seed:2584 hm:4655 ht:2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42093.13it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 27007.56it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 21526.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Train Loss: 0.1163, Train: 0.9042, Val: 0.3618, Test: 0.3612, Std dev: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 6/6 [00:00<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2213 seed:1.2573 hm:0.8359 ht:0.1281\n",
      "Example:10250 seed:2660 hm:4654 ht:2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 29396.44it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39227.08it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 30835.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Train Loss: 0.1274, Train: 0.9127, Val: 0.3684, Test: 0.3650, Std dev: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 6/6 [00:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1981 seed:1.2542 hm:0.8300 ht:0.1139\n",
      "Example:10262 seed:2655 hm:4689 ht:2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 41436.54it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 22623.41it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 29010.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Train Loss: 0.0972, Train: 0.9147, Val: 0.3546, Test: 0.3679, Std dev: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 6/6 [00:00<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2143 seed:1.2680 hm:0.8371 ht:0.1092\n",
      "Example:10275 seed:2668 hm:4671 ht:2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 30726.87it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40135.03it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 33688.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Train Loss: 0.1030, Train: 0.9235, Val: 0.3582, Test: 0.3660, Std dev: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 6/6 [00:00<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2061 seed:1.2682 hm:0.8295 ht:0.1084\n",
      "Example:10164 seed:2621 hm:4650 ht:2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 40752.78it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 22534.73it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 28913.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Train Loss: 0.1232, Train: 0.9247, Val: 0.3618, Test: 0.3698, Std dev: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 6/6 [00:00<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2239 seed:1.2663 hm:0.8483 ht:0.1093\n",
      "Example:10403 seed:2694 hm:4721 ht:2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 31417.63it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40222.93it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 38424.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Train Loss: 0.1184, Train: 0.9295, Val: 0.3582, Test: 0.3689, Std dev: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 6/6 [00:00<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2256 seed:1.2727 hm:0.8453 ht:0.1076\n",
      "Example:10358 seed:2700 hm:4695 ht:2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 45048.03it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 27216.41it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 21152.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Train Loss: 0.0957, Train: 0.9335, Val: 0.3606, Test: 0.3631, Std dev: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 6/6 [00:00<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2209 seed:1.2810 hm:0.8433 ht:0.0966\n",
      "Example:10330 seed:2680 hm:4708 ht:2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 30063.76it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42048.67it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 37091.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Train Loss: 0.1031, Train: 0.9335, Val: 0.3552, Test: 0.3593, Std dev: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 6/6 [00:00<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2147 seed:1.2781 hm:0.8411 ht:0.0955\n",
      "Example:10285 seed:2669 hm:4673 ht:2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 27123.68it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 37412.81it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32326.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 042, Train Loss: 0.0942, Train: 0.9323, Val: 0.3594, Test: 0.3698, Std dev: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 6/6 [00:00<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1949 seed:1.2623 hm:0.8441 ht:0.0885\n",
      "Example:10345 seed:2685 hm:4692 ht:2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 27725.87it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40408.30it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32233.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 043, Train Loss: 0.0838, Train: 0.9367, Val: 0.3570, Test: 0.3698, Std dev: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 6/6 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2038 seed:1.2702 hm:0.8468 ht:0.0867\n",
      "Example:10335 seed:2667 hm:4724 ht:2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 39927.17it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 22039.04it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 34275.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 044, Train Loss: 0.0903, Train: 0.9427, Val: 0.3546, Test: 0.3670, Std dev: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 6/6 [00:00<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2051 seed:1.2697 hm:0.8510 ht:0.0844\n",
      "Example:10443 seed:2727 hm:4730 ht:2986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 30234.46it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40175.93it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32986.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 045, Train Loss: 0.0818, Train: 0.9443, Val: 0.3516, Test: 0.3670, Std dev: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 6/6 [00:00<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2372 seed:1.2807 hm:0.8720 ht:0.0845\n",
      "Example:10559 seed:2741 hm:4803 ht:3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 40377.91it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 24079.91it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 34106.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046, Train Loss: 0.0915, Train: 0.9423, Val: 0.3504, Test: 0.3660, Std dev: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 6/6 [00:00<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1775 seed:1.2617 hm:0.8388 ht:0.0770\n",
      "Example:10320 seed:2675 hm:4702 ht:2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 28462.17it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40671.33it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32117.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 047, Train Loss: 0.0775, Train: 0.9515, Val: 0.3498, Test: 0.3746, Std dev: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 6/6 [00:00<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1633 seed:1.2530 hm:0.8306 ht:0.0797\n",
      "Example:10300 seed:2691 hm:4649 ht:2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 47297.34it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 43601.96it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 26607.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Train Loss: 0.0899, Train: 0.9551, Val: 0.3558, Test: 0.3785, Std dev: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 6/6 [00:00<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.2046 seed:1.2697 hm:0.8538 ht:0.0810\n",
      "Example:10496 seed:2734 hm:4757 ht:3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 47281.75it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42983.00it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 23031.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 049, Train Loss: 0.0864, Train: 0.9535, Val: 0.3546, Test: 0.3785, Std dev: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 6/6 [00:00<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1629 seed:1.2605 hm:0.8344 ht:0.0680\n",
      "Example:10301 seed:2680 hm:4694 ht:2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 47430.20it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42217.56it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 22160.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Train Loss: 0.0745, Train: 0.9531, Val: 0.3564, Test: 0.3814, Std dev: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 6/6 [00:00<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1593 seed:1.2701 hm:0.8221 ht:0.0672\n",
      "Example:10065 seed:2581 hm:4603 ht:2881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 31913.84it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 46019.23it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 34962.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 051, Train Loss: 0.0652, Train: 0.9583, Val: 0.3570, Test: 0.3823, Std dev: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 6/6 [00:00<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1963 seed:1.2799 hm:0.8472 ht:0.0692\n",
      "Example:10336 seed:2680 hm:4686 ht:2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 33284.11it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 47230.66it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 34566.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 052, Train Loss: 0.0627, Train: 0.9607, Val: 0.3528, Test: 0.3775, Std dev: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 6/6 [00:00<00:00, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1701 seed:1.2652 hm:0.8315 ht:0.0734\n",
      "Example:10218 seed:2643 hm:4652 ht:2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 32422.85it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 48224.71it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32025.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 053, Train Loss: 0.0851, Train: 0.9619, Val: 0.3642, Test: 0.3766, Std dev: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 6/6 [00:00<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1949 seed:1.2654 hm:0.8564 ht:0.0730\n",
      "Example:10429 seed:2697 hm:4774 ht:2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 34370.96it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 45500.20it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32603.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 054, Train Loss: 0.0809, Train: 0.9619, Val: 0.3594, Test: 0.3737, Std dev: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 6/6 [00:00<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1439 seed:1.2569 hm:0.8205 ht:0.0664\n",
      "Example:10152 seed:2633 hm:4588 ht:2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 32738.90it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 46349.59it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31545.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 055, Train Loss: 0.0736, Train: 0.9643, Val: 0.3534, Test: 0.3679, Std dev: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 6/6 [00:00<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1598 seed:1.2499 hm:0.8456 ht:0.0644\n",
      "Example:10503 seed:2747 hm:4746 ht:3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 32706.88it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 47263.28it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31247.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 056, Train Loss: 0.0573, Train: 0.9643, Val: 0.3588, Test: 0.3766, Std dev: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 6/6 [00:00<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1876 seed:1.2747 hm:0.8458 ht:0.0671\n",
      "Example:10346 seed:2687 hm:4707 ht:2952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42040.73it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 32720.38it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 37944.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 057, Train Loss: 0.0691, Train: 0.9651, Val: 0.3558, Test: 0.3650, Std dev: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 6/6 [00:00<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1515 seed:1.2631 hm:0.8201 ht:0.0683\n",
      "Example:10133 seed:2612 hm:4611 ht:2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42028.41it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29765.87it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 36829.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 058, Train Loss: 0.0701, Train: 0.9671, Val: 0.3456, Test: 0.3670, Std dev: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 6/6 [00:00<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1718 seed:1.2688 hm:0.8434 ht:0.0596\n",
      "Example:10268 seed:2634 hm:4707 ht:2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42507.94it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 29796.75it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 37860.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 059, Train Loss: 0.0664, Train: 0.9700, Val: 0.3492, Test: 0.3622, Std dev: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 6/6 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1520 seed:1.2480 hm:0.8419 ht:0.0622\n",
      "Example:10457 seed:2709 hm:4760 ht:2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 40205.47it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 41095.45it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 17075.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 060, Train Loss: 0.0606, Train: 0.9688, Val: 0.3558, Test: 0.3746, Std dev: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 6/6 [00:00<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1491 seed:1.2538 hm:0.8362 ht:0.0592\n",
      "Example:10325 seed:2681 hm:4671 ht:2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 25642.05it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42124.30it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32417.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 061, Train Loss: 0.0584, Train: 0.9700, Val: 0.3444, Test: 0.3775, Std dev: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 6/6 [00:00<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1201 seed:1.2372 hm:0.8278 ht:0.0551\n",
      "Example:10270 seed:2655 hm:4655 ht:2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 40613.97it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 38015.60it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 17014.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 062, Train Loss: 0.0556, Train: 0.9696, Val: 0.3528, Test: 0.3766, Std dev: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 6/6 [00:00<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1641 seed:1.2641 hm:0.8409 ht:0.0592\n",
      "Example:10332 seed:2673 hm:4720 ht:2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 24267.57it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 42866.84it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 37027.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 063, Train Loss: 0.0507, Train: 0.9720, Val: 0.3498, Test: 0.3794, Std dev: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 6/6 [00:00<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1759 seed:1.2665 hm:0.8542 ht:0.0552\n",
      "Example:10466 seed:2728 hm:4750 ht:2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 44849.83it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 21944.65it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 26953.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Train Loss: 0.0568, Train: 0.9712, Val: 0.3474, Test: 0.3766, Std dev: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 6/6 [00:00<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1218 seed:1.2464 hm:0.8194 ht:0.0560\n",
      "Example:10166 seed:2637 hm:4622 ht:2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 45258.75it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 28837.31it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31995.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 065, Train Loss: 0.0524, Train: 0.9704, Val: 0.3510, Test: 0.3756, Std dev: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 6/6 [00:00<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1459 seed:1.2522 hm:0.8402 ht:0.0535\n",
      "Example:10431 seed:2732 hm:4706 ht:2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 30168.41it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 39633.17it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32265.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 066, Train Loss: 0.0528, Train: 0.9704, Val: 0.3462, Test: 0.3775, Std dev: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 6/6 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1421 seed:1.2525 hm:0.8363 ht:0.0533\n",
      "Example:10408 seed:2708 hm:4725 ht:2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 36926.33it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 26698.96it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 31608.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 067, Train Loss: 0.0496, Train: 0.9724, Val: 0.3534, Test: 0.3660, Std dev: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 6/6 [00:00<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1802 seed:1.2781 hm:0.8483 ht:0.0538\n",
      "Example:10376 seed:2687 hm:4721 ht:2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 42457.26it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40552.46it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 18700.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 068, Train Loss: 0.0531, Train: 0.9728, Val: 0.3474, Test: 0.3708, Std dev: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 6/6 [00:00<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.1573 seed:1.2708 hm:0.8331 ht:0.0534\n",
      "Example:10246 seed:2650 hm:4672 ht:2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Train: 100%|██████████| 2496/2496 [00:00<00:00, 30268.72it/s]\n",
      "Evaluating Validation: 100%|██████████| 1664/1664 [00:00<00:00, 40604.36it/s]\n",
      "Evaluating Test: 100%|██████████| 1041/1041 [00:00<00:00, 32335.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 069, Train Loss: 0.0468, Train: 0.9659, Val: 0.3486, Test: 0.3804, Std dev: 0.0010\n",
      "Iteration for convergence:  69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy,  0.3683894230769231\n",
      "Best Test Accuracy,  0.38232468780019213\n",
      "0.38232468780019213 69\n"
     ]
    }
   ],
   "source": [
    "args.log_info = True\n",
    "\n",
    "DATASET_NAME = 'Cora'\n",
    "data, dataset = get_data(DATASET_NAME,DIR=None, log=False, h_score=True, split_no=0)\n",
    "print(data)\n",
    "\n",
    "channel = 'ht' #'all', 'hm', 'ht', 'sd'\n",
    "\n",
    "# if DATASET_NAME in ['Squirrel', 'Chameleon']:\n",
    "#     data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "#     if args.log_info == True:\n",
    "#         print(data.x.shape)\n",
    "    \n",
    "best_acc, num_iteration, _ =  AGSGSperformanceSampler(DATASET_NAME, data, dataset, dataset.num_classes,\n",
    "                                                      epochs=150, channel=channel)\n",
    "print(best_acc, num_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72e3b1",
   "metadata": {},
   "source": [
    "# Batch Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5dd76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_experiments(num_run=1, channel='all'):\n",
    "    \n",
    "    ALL_DATASETs= [\n",
    "        \"Roman-empire\",\"Texas\",\"Squirrel\",\"Chameleon\",\n",
    "        \"Cornell\",\"Actor\",\"Wisconsin\",\"Flickr\",\"Amazon-ratings\",\"reed98\",\"amherst41\",\"genius\",\n",
    "        \"AmazonProducts\",\n",
    "        \"cornell5\",\"penn94\",\n",
    "        \"johnshopkins55\",\n",
    "        \"Yelp\",\n",
    "        \"cora\",\"Tolokers\",\"Minesweeper\",\n",
    "        \"CiteSeer\",\"Computers\",\"PubMed\",\"pubmed\",\n",
    "        \"Reddit\",\n",
    "        \"cora_ml\",\"dblp\",\n",
    "        \"Reddit2\",\n",
    "        \"Cora\",\"CS\",\"Photo\",\"Questions\",\"Physics\",\"citeseer\",\n",
    "    ]\n",
    "    \n",
    "    #ALL_DATASETs= [\"Cora\"]\n",
    "    ALL_DATASETs= [\"Squirrel\"]\n",
    "#     ALL_DATASETs= [\"Texas\", \"Cornell\", \"Wisconsin\"]\n",
    "#     ALL_DATASETs= [\"cornell5\", \"penn94\", \"johnshopkins55\"]\n",
    "\n",
    "    args.log_info = False\n",
    "    \n",
    "    filename = \"Results/AGSGNN-SAINT-ACM-GS-\"+channel+\".txt\"\n",
    "    \n",
    "    for DATASET_NAME in ALL_DATASETs:  \n",
    "        print(DATASET_NAME, end=' ')\n",
    "                \n",
    "        result_file = open(filename,'a+')        \n",
    "        result_file.write(f'{DATASET_NAME} ')\n",
    "        result_file.close()\n",
    "                \n",
    "        accs = []\n",
    "        itrs = []\n",
    "                \n",
    "        for i in range(num_run):\n",
    "            data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=False, split_no=i)   \n",
    "            \n",
    "            if data.num_nodes>10000:\n",
    "                accs.append(-1)\n",
    "                itrs.append(-1)\n",
    "                break\n",
    "            \n",
    "            if len(data.y.shape) > 1:\n",
    "                data.y = data.y.argmax(dim=1)        \n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            else:\n",
    "                num_classes = dataset.num_classes\n",
    "            \n",
    "            if num_classes!= torch.max(data.y)+1:\n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "                \n",
    "            if data.num_nodes<100000:\n",
    "                max_epochs = 150\n",
    "            else:\n",
    "                max_epochs = 50\n",
    "                \n",
    "#             if DATASET_NAME in ['Squirrel', 'Chameleon', \n",
    "#                                 #'cornell5','penn94','johnshopkins55'\n",
    "#                                ]:\n",
    "#                 data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "#                 if args.log_info == True:\n",
    "#                     print(data.x.shape)\n",
    "                              \n",
    "            accuracy, itr, _ = AGSGSperformanceSampler(DATASET_NAME, data, dataset, num_classes,epochs=max_epochs, channel=channel)\n",
    "            \n",
    "            accs.append(accuracy)\n",
    "            itrs.append(itr)\n",
    "            #print(itr, accuracy)\n",
    "                        \n",
    "        #print(accs, itrs)\n",
    "        print(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}')\n",
    "        result_file = open(filename,'a+')\n",
    "        result_file.write(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}\\n')\n",
    "        result_file.close()\n",
    "                \n",
    "# start = time.time()\n",
    "# batch_experiments(num_run=5, channel='ht')\n",
    "# end = time.time()\n",
    "# print(\"Time spent:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4cab8c",
   "metadata": {},
   "source": [
    "## Visualize representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361d4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    \n",
    "#     n=7\n",
    "#     x = torch.Tensor([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1],[0,1]])\n",
    "#     y = torch.LongTensor([0,0,0, 1, 1, 1, 1])\n",
    "#     edge_index = torch.LongTensor([[1,2],[1,4],[1,5],[2,1],[3,6],[3,7],[4,5],[4,1],[4,6],[4,7],[5,1],[5,4],[5,6],[6,3],[6,4],[6,5],[6,7],[7,3],[7,4],[7,6]]).T\n",
    "#     edge_index = edge_index-1\n",
    "    \n",
    "#     mask = torch.zeros(n, dtype=torch.bool)\n",
    "#     mask[[1,3]] = True\n",
    "    \n",
    "#     test_data = Data(x = x, y = y, edge_index = edge_index, train_mask = mask, test_mask = mask, val_mask = mask)    \n",
    "#     print(test_data)\n",
    "    \n",
    "    \n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f76e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AGS_layer(torch.nn.Module):\n",
    "#     def __init__(self, input_channels, output_channels, dropout=0.2):\n",
    "#         super().__init__()\n",
    "#         self.T = 3\n",
    "#         self.p = dropout\n",
    "#         #self.Aconv1 = GCNConv(input_channels, output_channels)        \n",
    "#         #self.Sconv1 = SpatialConv(input_channels, output_channels)\n",
    "        \n",
    "#         self.Aconv1 = GCNConv(input_channels, output_channels)\n",
    "#         self.Sconv1 = SpatialConv(input_channels, output_channels)\n",
    "        \n",
    "#         self.I1 = nn.Linear(input_channels, output_channels)\n",
    "        \n",
    "#         self.layer_norm_a1 =  nn.LayerNorm(output_channels)\n",
    "#         self.layer_norm_s1 =  nn.LayerNorm(output_channels)\n",
    "#         self.layer_norm_i1 =  nn.LayerNorm(output_channels)\n",
    "        \n",
    "#         self.alpha_a1 = nn.Linear(output_channels, 1)\n",
    "#         self.alpha_s1 = nn.Linear(output_channels, 1)\n",
    "#         self.alpha_i1 = nn.Linear(output_channels, 1)\n",
    "#         self.w1 = nn.Linear(3, 3)\n",
    "        \n",
    "#         #self.reset_parameters()\n",
    "            \n",
    "#     def reset_parameters(self):\n",
    "        \n",
    "#         stdv = 1. / math.sqrt(self.I1.weight.size(1))\n",
    "#         std_att = 1. / math.sqrt(self.w1.weight.size(1))\n",
    "#         std_att_vec = 1. / math.sqrt( self.alpha_a1.weight.size(1))\n",
    "        \n",
    "#         self.I1.weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "#         self.alpha_a1.weight.data.uniform_(-std_att, std_att)\n",
    "#         self.alpha_s1.weight.data.uniform_(-std_att, std_att)\n",
    "#         self.alpha_i1.weight.data.uniform_(-std_att, std_att)\n",
    "        \n",
    "#         self.w1.weight.data.uniform_(-std_att_vec, std_att_vec)\n",
    "        \n",
    "#         self.layer_norm_a1.reset_parameters()\n",
    "#         self.layer_norm_s1.reset_parameters()\n",
    "#         self.layer_norm_i1.reset_parameters()\n",
    "        \n",
    "\n",
    "#     def forward(self, x0, edge_index, edge_weight=None):\n",
    "#         a1 = F.relu(self.Aconv1(x0, edge_index, edge_weight))\n",
    "#         a1 = self.layer_norm_a1(a1)\n",
    "#         a1 = F.dropout(a1, p=self.p, training=self.training)\n",
    "        \n",
    "#         s1 = F.relu(self.Sconv1(x0, edge_index, edge_weight))\n",
    "#         s1 = self.layer_norm_s1(s1)\n",
    "#         s1 = F.dropout(s1, p=self.p, training=self.training)\n",
    "\n",
    "#         i1 = F.relu(self.I1(x0))\n",
    "#         i1 = self.layer_norm_i1(i1)\n",
    "#         i1 = F.dropout(i1, p=self.p, training=self.training)\n",
    "        \n",
    "#         ala1 = torch.sigmoid(self.alpha_a1(a1))\n",
    "#         als1 = torch.sigmoid(self.alpha_s1(s1))\n",
    "#         ali1 = torch.sigmoid(self.alpha_i1(i1))        \n",
    "#         alpha1 = F.softmax(self.w1(torch.cat([ala1, als1, ali1],dim=-1)/self.T), dim=1)        \n",
    "        \n",
    "#         x1 = torch.mm(torch.diag(alpha1[:,0]),a1) + torch.mm(torch.diag(alpha1[:,1]),s1) + torch.mm(torch.diag(alpha1[:,2]),i1)                \n",
    "        \n",
    "#         return x1\n",
    "        \n",
    "# class AGS_GCN(torch.nn.Module):\n",
    "#     def __init__(self, num_features, num_classes, hidden_channels=16, dropout=0.2):\n",
    "#         super().__init__()        \n",
    "#         self.num_classes = num_classes\n",
    "#         self.p = dropout\n",
    "        \n",
    "#         self.ags_layer1 = AGS_layer(num_features, hidden_channels)\n",
    "#         self.ags_layer2 = AGS_layer(hidden_channels, hidden_channels)\n",
    "#         #self.ags_layer2 = AGS_layer(hidden_channels, num_classes)\n",
    "                \n",
    "#         self.CombineW = nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "#         self.PredW = nn.Linear(1*hidden_channels, num_classes)\n",
    "        \n",
    "    \n",
    "#     def forward(self, x0, edge_index, edge_weight=None):\n",
    "        \n",
    "#         #x0 = F.dropout(x0, p=self.p, training=self.training)\n",
    "#         x1 = self.ags_layer1(x0, edge_index, edge_weight)\n",
    "#         x1 = F.dropout(x1, p=self.p, training=self.training)\n",
    "        \n",
    "#         x2 = self.ags_layer2(x1, edge_index, edge_weight)\n",
    "#         x2 = F.dropout(x2, p=self.p, training=self.training)        \n",
    "        \n",
    "#         #x = self.PredW(torch.cat([x1, x2], dim=-1))\n",
    "#         x = self.PredW(x2)\n",
    "         \n",
    "#         #return x\n",
    "#         return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0c3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
