{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not os.getcwd().endswith(\"Submodular\"):\n",
    "    sys.path.append('../Submodular')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Dataset import get_data\n",
    "from ipynb.fs.full.Dataset import datasets as available_datasets\n",
    "from ipynb.fs.full.Utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "#set default arguments here\n",
    "def get_configuration():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--log_info', type=bool, default=True)\n",
    "    parser.add_argument('--pbar', type=bool, default=False)\n",
    "    parser.add_argument('--batch_size', type=int, default=2048)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    parser.add_argument('--dataset', type=str, default=\"Cora\", choices=available_datasets)\n",
    "    #parser.add_argument('--use_normalization', action='store_false', default=True)\n",
    "    parser.add_argument('--use_normalization', action='store_true')    \n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    return args, dict_args\n",
    "\n",
    "args, dict_args = get_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import init\n",
    "from random import shuffle, randint\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSAINT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler, GraphSAINTNodeSampler, GraphSAINTEdgeSampler, GraphSAINTSampler\n",
    "from ipynb.fs.full.a2AGS_Graph_Sampler import AGSGraphSampler\n",
    "\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "# from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\" adapted from https://github.com/CUAI/CorrectAndSmooth/blob/master/gen_models.py \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout=.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        if num_layers == 1:\n",
    "            # just linear layer i.e. logistic regression\n",
    "            self.lins.append(nn.Linear(in_channels, out_channels))\n",
    "        else:\n",
    "            self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
    "            for _ in range(num_layers - 2):\n",
    "                self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "                self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
    "            self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, b_data, input_tensor=False):\n",
    "        if not input_tensor:\n",
    "            x = b_data.x.shape[1]\n",
    "        else:\n",
    "            x = b_data\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = F.relu(x, inplace=True)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LINKX(nn.Module):\t\n",
    "    \"\"\" our LINKX method with skip connections \n",
    "        a = MLP_1(A), x = MLP_2(X), MLP_3(sigma(W_1[a, x] + a + x))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, num_nodes, dropout=.5, cache=False, inner_activation=False, inner_dropout=False, init_layers_A=1, init_layers_X=1):\n",
    "        super(LINKX, self).__init__()\t\n",
    "        self.mlpA = MLP(num_nodes, hidden_channels, hidden_channels, init_layers_A, dropout=0)\n",
    "        self.mlpX = MLP(in_channels, hidden_channels, hidden_channels, init_layers_X, dropout=0)\n",
    "        self.W = nn.Linear(2*hidden_channels, hidden_channels)\n",
    "        self.mlp_final = MLP(hidden_channels, hidden_channels, out_channels, num_layers, dropout=dropout)\n",
    "        self.in_channels = in_channels\n",
    "        self.num_nodes = num_nodes\n",
    "        self.A = None\n",
    "        self.inner_activation = inner_activation\n",
    "        self.inner_dropout = inner_dropout\n",
    "\n",
    "    def reset_parameters(self):\t\n",
    "        self.mlpA.reset_parameters()\t\n",
    "        self.mlpX.reset_parameters()\n",
    "        self.W.reset_parameters()\n",
    "        self.mlp_final.reset_parameters()\t\n",
    "\n",
    "    def forward(self, b_data):\t\n",
    "        \n",
    "        m = b_data.num_nodes\n",
    "        feat_dim = b_data.x.shape[1]\n",
    "        row, col = b_data.edge_index\n",
    "        \n",
    "        row = row-row.min()\n",
    "        A = SparseTensor(row=row, col=col,\t\n",
    "                 sparse_sizes=(m, self.num_nodes)\n",
    "                        ).to_torch_sparse_coo_tensor()\n",
    "\n",
    "        xA = self.mlpA(A, input_tensor=True)\n",
    "        xX = self.mlpX(b_data.x, input_tensor=True)\n",
    "        x = torch.cat((xA, xX), axis=-1)\n",
    "        x = self.W(x)\n",
    "        if self.inner_dropout:\n",
    "            x = F.dropout(x)\n",
    "        if self.inner_activation:\n",
    "            x = F.relu(x)\n",
    "        x = F.relu(x + xA + xX)\n",
    "        x = self.mlp_final(x, input_tensor=True)\n",
    "        \n",
    "        x.log_softmax(dim=-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, mask, name='Train'):\n",
    "    if args.log_info:\n",
    "        pbar = tqdm(total=sum(mask).item())\n",
    "        pbar.set_description(f'Evaluating {name}')\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct=0\n",
    "    total_examples=0\n",
    "    \n",
    "    with torch.no_grad():                  \n",
    "    \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            out = model(batch_data.to(device))\n",
    "            out=out[:batch_data.batch_size,:]\n",
    "            pred = out.argmax(dim=-1)            \n",
    "            correct = pred.eq(batch_data.y[:batch_data.batch_size].to(device))\n",
    "\n",
    "            total_correct+=correct.sum()\n",
    "            total_examples+=batch_data.batch_size\n",
    "\n",
    "            if args.log_info:                \n",
    "                pbar.update(batch_data.batch_size)\n",
    "    if args.log_info:\n",
    "        pbar.close()\n",
    "\n",
    "    return total_correct.item()/total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(DATASET_NAME, model, data, dataset, epochs=10,train_neighbors=[8,4],test_neighbors=[8,4]):\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    row, col = data.edge_index\n",
    "    data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.\n",
    "\n",
    "    \n",
    "    sampler_dir = DIR+'AGSLINKX/'+DATASET_NAME\n",
    "    if not os.path.exists(sampler_dir):\n",
    "        os.makedirs(sampler_dir)\n",
    "        \n",
    "    batch_size=min(data.num_nodes,4096)\n",
    "    #batch_size= 6000\n",
    "    \n",
    "    num_steps=math.ceil(data.num_nodes/batch_size) #num_steps=5    \n",
    "    num_workers = 0 if data.num_nodes <100000 else 8\n",
    "    \n",
    "    worker = num_workers\n",
    "    \n",
    "    sample_func =['rw']\n",
    "    weight_func =[\n",
    "        {'exact':True,'weight':'knn'}, #exact for exact size to the batch\n",
    "       #{'exact':False,'weight':'knn'}\n",
    "    ]\n",
    "\n",
    "    params={'knn':{'metric':'cosine'},\n",
    "            'submodular':{'metric':'cosine'},\n",
    "            'link-nn':{'value':'min'},\n",
    "            'link-sub':{'value':'max'},\n",
    "            'disjoint':{'value':'mst'},\n",
    "           }\n",
    "    \n",
    "    loader = AGSGraphSampler(\n",
    "        data, batch_size=batch_size, walk_length=2, num_steps=num_steps, sample_coverage=100,\n",
    "        num_workers=num_workers,log=args.log_info,save_dir=sampler_dir,recompute = False, shuffle = False,\n",
    "        sample_func = sample_func, weight_func=weight_func, params=params)\n",
    "        \n",
    "#     #### original loader\n",
    "#     loader = GraphSAINTRandomWalkSampler(data, batch_size=batch_size, walk_length=2,\n",
    "#                                      num_steps=num_steps, sample_coverage=100,\n",
    "#                                      save_dir=sampler_dir,num_workers=num_workers)\n",
    "    \n",
    "#     #----\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(\"Train neighbors: \", train_neighbors)\n",
    "        print(\"Test neighbors: \", test_neighbors)\n",
    "\n",
    "    sample_batch_size=512\n",
    "    train_loader = NeighborLoader(data, input_nodes=data.train_mask,num_neighbors=train_neighbors, \n",
    "                            batch_size=sample_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    val_loader = NeighborLoader(data,input_nodes=data.val_mask,num_neighbors=test_neighbors, \n",
    "                                batch_size=sample_batch_size,shuffle=False, num_workers=num_workers)\n",
    "    test_loader = NeighborLoader(data, input_nodes=data.test_mask,num_neighbors=test_neighbors, \n",
    "                                 batch_size=sample_batch_size,shuffle=False, num_workers=num_workers)\n",
    "\n",
    "#         subgraph_loader = NeighborSampler(data.edge_index, node_idx=None,\n",
    "#                                       sizes=[-1], batch_size=2048,\n",
    "#                                       shuffle=False, num_workers=4)\n",
    "\n",
    "    \n",
    "    best_acc=0    \n",
    "    num_iteration = epochs\n",
    "    train_losses = []; val_accuracies = []; train_accuracies = []; test_accuracies = [];\n",
    "    training_times = []\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        if args.log_info:\n",
    "            #pbar = tqdm(total=int(sum(data.train_mask)))\n",
    "            pbar = tqdm(total=batch_size*num_steps)\n",
    "            pbar.set_description(f'Epoch {epoch:02d}')\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        total_loss = total_examples = 0\n",
    "        \n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        for i,batch_data in enumerate(loader):\n",
    "            \n",
    "            #print(batch_data);print(\"*\"*50)            \n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if args.use_normalization:\n",
    "#                 edge_weight = batch_data.edge_norm * batch_data.edge_weight\n",
    "                out = model(batch_data)\n",
    "                loss = F.nll_loss(out, batch_data.y, reduction='none')\n",
    "                #loss = criterion(out, batch_data.y, reduction='none')\n",
    "                loss = (loss * batch_data.node_norm)[batch_data.train_mask].sum()\n",
    "            else:\n",
    "                out = model(batch_data)\n",
    "                loss = F.nll_loss(out[batch_data.train_mask], batch_data.y[batch_data.train_mask])\n",
    "                #loss = criterion(out[batch_data.train_mask], batch_data.y[batch_data.train_mask])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * batch_data.num_nodes\n",
    "            total_examples += batch_data.num_nodes\n",
    "            \n",
    "            if args.log_info:\n",
    "                pbar.update(batch_size)\n",
    "        \n",
    "        if args.log_info:\n",
    "            pbar.close()\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "        training_times.append(epoch_end-epoch_start)\n",
    "        \n",
    "        loss=total_loss / total_examples\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        if args.log_info:\n",
    "            print(\"Training Loss: \",loss)                             \n",
    "        \n",
    "        if data.num_nodes<10000:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out = model(batch_data.to(device))\n",
    "                pred = out.argmax(dim=-1)\n",
    "                correct = pred.eq(data.y.to(device))\n",
    "\n",
    "            accs = []\n",
    "            for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "                accs.append(correct[mask].sum().item() / mask.sum().item())\n",
    "            \n",
    "            if args.log_info:                \n",
    "                print(accs)\n",
    "\n",
    "            if accs[2]>best_acc:\n",
    "                best_acc=accs[2]\n",
    "                \n",
    "            train_acc=accs[0]\n",
    "            val_acc=accs[1]\n",
    "            test_acc=accs[2]\n",
    "\n",
    "        else:\n",
    "            if args.log_info==True:\n",
    "                train_acc=test(model, train_loader,data.train_mask,'Train')\n",
    "                val_acc = test(model, val_loader,data.val_mask,'Validation')\n",
    "            else:\n",
    "                train_acc=0\n",
    "                val_acc = 0            \n",
    "            test_acc = test(model, test_loader,data.test_mask,'Test')\n",
    "            \n",
    "            accs=[train_acc,val_acc,test_acc]\n",
    "            \n",
    "            if args.log_info:\n",
    "                print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "            if test_acc>best_acc:\n",
    "                best_acc=test_acc\n",
    "                \n",
    "        train_accuracies.append(accs[0])\n",
    "        val_accuracies.append(accs[1])\n",
    "        test_accuracies.append(accs[2])\n",
    "        std_dev = np.std(train_losses[-5:])\n",
    "        \n",
    "                \n",
    "        std_dev = np.std(train_losses[-5:])\n",
    "        if args.log_info:\n",
    "            print('std_dev: ', std_dev)\n",
    "        \n",
    "        if epoch>=5 and std_dev<=1e-3:\n",
    "            num_iteration = epoch            \n",
    "            if args.log_info:                \n",
    "                print(\"Iteration for convergence: \", epoch)\n",
    "            break\n",
    "            \n",
    "    if args.log_info:\n",
    "        save_plot([train_losses, train_accuracies, val_accuracies, test_accuracies], labels=['Loss','Train','Validation','Test'], name='Results/AGSGSValidation', yname='Accuracy', xname='Epoch')\n",
    "        print (\"Best Validation Accuracy, \",max(val_accuracies))\n",
    "        print (\"Best Test Accuracy, \",max(test_accuracies))\n",
    "    \n",
    "    acc_file = open(\"Runtime/AGSLINKX.txt\",'a+') \n",
    "    acc_file.write(str(train_losses))\n",
    "    acc_file.write(str(train_accuracies))\n",
    "    acc_file.write(str(val_accuracies))\n",
    "    acc_file.write(str(test_accuracies))\n",
    "    acc_file.write(str(training_times))\n",
    "    acc_file.write(str(np.mean(training_times)))\n",
    "    acc_file.write(f'\\nworker {worker:1d} avg epoch runtime {np.mean(training_times):0.8f}')\n",
    "    acc_file.close()     \n",
    " \n",
    "                \n",
    "    return best_acc, num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def LINKXperformance(DATASET_NAME, data, dataset, num_classes, epochs=20, train_neighbors=[8,4],test_neighbors=[8,4]):\n",
    "    \n",
    "    model  = LINKX(in_channels=data.x.shape[1], hidden_channels=32, out_channels=num_classes, num_layers=2, num_nodes = data.num_nodes).to(device)\n",
    "    \n",
    "    if args.log_info:\n",
    "        print(model)\n",
    "    \n",
    "    best_acc, num_iteration = train(DATASET_NAME, model, data, dataset, epochs, train_neighbors, test_neighbors)\n",
    "    \n",
    "    return best_acc, num_iteration, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "def adj_feature(data):    \n",
    "    adj_mat = torch.zeros((data.num_nodes,data.num_nodes))\n",
    "    edges = data.edge_index.t()\n",
    "    adj_mat[edges[:,0], edges[:,1]] = 1\n",
    "    adj_mat[edges[:,1], edges[:,0]] = 1\n",
    "    \n",
    "#     n_components = data.x.shape[1]\n",
    "    n_components = min(256, data.x.shape[1], data.num_nodes)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    x = svd.fit_transform(adj_mat)\n",
    "    \n",
    "    x = torch.Tensor(x)\n",
    "    x.shape    \n",
    "    \n",
    "    return x\n",
    "\n",
    "# x = adj_feature(data)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your adjacency matrix (replace this with your actual adjacency matrix)\n",
    "# adj = np.array([[0, 1, 0, 1],\n",
    "#                 [1, 0, 1, 0],\n",
    "#                 [0, 1, 0, 1],\n",
    "#                 [1, 0, 1, 0]], dtype=np.float32)\n",
    "\n",
    "# n_components = 2\n",
    "\n",
    "# # Perform SVD dimensionality reduction\n",
    "# svd = TruncatedSVD(n_components=n_components)\n",
    "# low_dimensional_matrix = svd.fit_transform(adj_feature(data))\n",
    "\n",
    "# low_dimensional_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N  2708  E  10556  d  3.8980797636632203 0.825157880783081 0.8099659085273743 0.7657181620597839 -0.06587088108062744 \n",
      "LINKX(\n",
      "  (mlpA): MLP(\n",
      "    (lins): ModuleList(\n",
      "      (0): Linear(in_features=2708, out_features=32, bias=True)\n",
      "    )\n",
      "    (bns): ModuleList()\n",
      "  )\n",
      "  (mlpX): MLP(\n",
      "    (lins): ModuleList(\n",
      "      (0): Linear(in_features=1433, out_features=32, bias=True)\n",
      "    )\n",
      "    (bns): ModuleList()\n",
      "  )\n",
      "  (W): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (mlp_final): MLP(\n",
      "    (lins): ModuleList(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=32, out_features=7, bias=True)\n",
      "    )\n",
      "    (bns): ModuleList(\n",
      "      (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "loading saved norm\n",
      "Loading weights  knn\n",
      "Train neighbors:  [8, 4]\n",
      "Test neighbors:  [8, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 2708/2708 [00:00<00:00, 92404.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.10447314381599426\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 2708/2708 [00:00<00:00, 265613.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.08582159876823425\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.009325772523880005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 2708/2708 [00:00<00:00, 249526.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.013879459351301193\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.05195673392277562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 2708/2708 [00:00<00:00, 278960.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.0345785915851593\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.04620254099923314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 2708/2708 [00:00<00:00, 268261.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.08721710741519928\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.043564133924128584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 2708/2708 [00:00<00:00, 275824.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.22158314287662506\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.07869088223600282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 2708/2708 [00:00<00:00, 282485.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.18939246237277985\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.08957006964835271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 2708/2708 [00:00<00:00, 292925.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.25322532653808594\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.08286859732244223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 2708/2708 [00:00<00:00, 298962.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.20738746225833893\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.056296439341168285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2708/2708 [00:00<00:00, 283232.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.23224371671676636\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.0216762437579846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 2708/2708 [00:00<00:00, 303743.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.3763292133808136\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.06596839157047424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 2708/2708 [00:00<00:00, 296767.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.4092433452606201\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.08126876693194361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 2708/2708 [00:00<00:00, 287986.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.3378898501396179\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.079457830263338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2708/2708 [00:00<00:00, 285008.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.5236639380455017\n",
      "[0.14285714285714285, 0.116, 0.102]\n",
      "std_dev:  0.09489788209067142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 2708/2708 [00:00<00:00, 286822.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.5417753458023071\n",
      "[0.14285714285714285, 0.114, 0.103]\n",
      "std_dev:  0.08094401107078023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 2708/2708 [00:00<00:00, 290758.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.6456629037857056\n",
      "[0.14285714285714285, 0.114, 0.102]\n",
      "std_dev:  0.10741550860204356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 2708/2708 [00:00<00:00, 293265.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.6843809485435486\n",
      "[0.14285714285714285, 0.116, 0.104]\n",
      "std_dev:  0.12075287801548128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 2708/2708 [00:00<00:00, 292435.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.7171745896339417\n",
      "[0.14285714285714285, 0.114, 0.104]\n",
      "std_dev:  0.07695983600465198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2708/2708 [00:00<00:00, 294428.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.7934120297431946\n",
      "[0.14285714285714285, 0.116, 0.102]\n",
      "std_dev:  0.08305011916675191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2708/2708 [00:00<00:00, 281568.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.8098955750465393\n",
      "[0.14285714285714285, 0.116, 0.104]\n",
      "std_dev:  0.06286917827971836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 2708/2708 [00:00<00:00, 291781.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.8592830896377563\n",
      "[0.14285714285714285, 0.114, 0.102]\n",
      "std_dev:  0.06354899356168596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 2708/2708 [00:00<00:00, 286092.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.0884946584701538\n",
      "[0.14285714285714285, 0.112, 0.102]\n",
      "std_dev:  0.12597805022249806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 2708/2708 [00:00<00:00, 273328.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -0.7686460614204407\n",
      "[0.14285714285714285, 0.116, 0.104]\n",
      "std_dev:  0.11612270272818956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 2708/2708 [00:00<00:00, 294543.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.014623761177063\n",
      "[0.14285714285714285, 0.112, 0.103]\n",
      "std_dev:  0.12277141852022941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 2708/2708 [00:00<00:00, 294604.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.010221004486084\n",
      "[0.14285714285714285, 0.112, 0.102]\n",
      "std_dev:  0.11669372872858266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 2708/2708 [00:00<00:00, 292427.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.1519454717636108\n",
      "[0.14285714285714285, 0.112, 0.104]\n",
      "std_dev:  0.13002418022372905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 2708/2708 [00:00<00:00, 273381.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.3931758403778076\n",
      "[0.15, 0.114, 0.106]\n",
      "std_dev:  0.20424788855706555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 2708/2708 [00:00<00:00, 291138.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.3357208967208862\n",
      "[0.14285714285714285, 0.112, 0.101]\n",
      "std_dev:  0.15915258873169016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2708/2708 [00:00<00:00, 287374.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.4037131071090698\n",
      "[0.15, 0.12, 0.108]\n",
      "std_dev:  0.153741852546553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 2708/2708 [00:00<00:00, 292457.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.5377074480056763\n",
      "[0.1357142857142857, 0.114, 0.104]\n",
      "std_dev:  0.1251946042274328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 2708/2708 [00:00<00:00, 289623.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.690678596496582\n",
      "[0.14285714285714285, 0.11, 0.11]\n",
      "std_dev:  0.12773874964291035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 2708/2708 [00:00<00:00, 292224.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.4449286460876465\n",
      "[0.16428571428571428, 0.11, 0.103]\n",
      "std_dev:  0.12292214143142663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 2708/2708 [00:00<00:00, 293295.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.7489067316055298\n",
      "[0.15, 0.126, 0.11]\n",
      "std_dev:  0.1347531789022387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 2708/2708 [00:00<00:00, 286323.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.7440638542175293\n",
      "[0.15, 0.108, 0.117]\n",
      "std_dev:  0.12128276454622026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 2708/2708 [00:00<00:00, 286641.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -1.8686940670013428\n",
      "[0.1357142857142857, 0.11, 0.114]\n",
      "std_dev:  0.1399556897916729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 2708/2708 [00:00<00:00, 292472.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.0794432163238525\n",
      "[0.1357142857142857, 0.1, 0.111]\n",
      "std_dev:  0.20592469092756605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 2708/2708 [00:00<00:00, 288879.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.208707809448242\n",
      "[0.15714285714285714, 0.126, 0.114]\n",
      "std_dev:  0.18500635164493526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 2708/2708 [00:00<00:00, 270053.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.1826181411743164\n",
      "[0.19285714285714287, 0.156, 0.138]\n",
      "std_dev:  0.18142147816489895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 2708/2708 [00:00<00:00, 295278.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.257180690765381\n",
      "[0.12142857142857143, 0.124, 0.143]\n",
      "std_dev:  0.13813465965811225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 2708/2708 [00:00<00:00, 292502.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.4167251586914062\n",
      "[0.17142857142857143, 0.116, 0.12]\n",
      "std_dev:  0.11042205104409944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 2708/2708 [00:00<00:00, 290944.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.4714324474334717\n",
      "[0.17142857142857143, 0.112, 0.133]\n",
      "std_dev:  0.11549134285812845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 2708/2708 [00:00<00:00, 271648.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.4943418502807617\n",
      "[0.19285714285714287, 0.134, 0.143]\n",
      "std_dev:  0.12297915121332548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 2708/2708 [00:00<00:00, 293061.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.0062615871429443\n",
      "[0.19285714285714287, 0.118, 0.132]\n",
      "std_dev:  0.2525014980167901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 2708/2708 [00:00<00:00, 293470.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -2.897359609603882\n",
      "[0.15714285714285714, 0.096, 0.133]\n",
      "std_dev:  0.24428718206706168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 2708/2708 [00:00<00:00, 291392.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.0824599266052246\n",
      "[0.16428571428571428, 0.124, 0.116]\n",
      "std_dev:  0.25796368234462047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 2708/2708 [00:00<00:00, 291571.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.2470695972442627\n",
      "[0.19285714285714287, 0.11, 0.138]\n",
      "std_dev:  0.2526877073323686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 2708/2708 [00:00<00:00, 273664.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.1462881565093994\n",
      "[0.19285714285714287, 0.106, 0.128]\n",
      "std_dev:  0.11918283016900307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 2708/2708 [00:00<00:00, 287076.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.2759344577789307\n",
      "[0.15, 0.118, 0.135]\n",
      "std_dev:  0.13538752721891562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2708/2708 [00:00<00:00, 292759.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.4522252082824707\n",
      "[0.17857142857142858, 0.118, 0.138]\n",
      "std_dev:  0.1264740479073304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 2708/2708 [00:00<00:00, 273079.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.719203233718872\n",
      "[0.16428571428571428, 0.134, 0.155]\n",
      "std_dev:  0.20134242530358076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 2708/2708 [00:00<00:00, 295032.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.8670105934143066\n",
      "[0.18571428571428572, 0.122, 0.144]\n",
      "std_dev:  0.2683420199485439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 2708/2708 [00:00<00:00, 287119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.9684629440307617\n",
      "[0.2, 0.128, 0.167]\n",
      "std_dev:  0.25773070586410246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 2708/2708 [00:00<00:00, 288835.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -3.953047037124634\n",
      "[0.17142857142857143, 0.13, 0.156]\n",
      "std_dev:  0.1915453918290967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 2708/2708 [00:00<00:00, 288139.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.1629414558410645\n",
      "[0.17142857142857143, 0.148, 0.165]\n",
      "std_dev:  0.1446304374752293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 2708/2708 [00:00<00:00, 292435.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.521286487579346\n",
      "[0.17142857142857143, 0.176, 0.19]\n",
      "std_dev:  0.23429751889341238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 2708/2708 [00:00<00:00, 269393.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.843640327453613\n",
      "[0.17857142857142858, 0.168, 0.163]\n",
      "std_dev:  0.3444062210243213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 2708/2708 [00:00<00:00, 244830.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.580977439880371\n",
      "[0.2, 0.184, 0.176]\n",
      "std_dev:  0.3160625089731322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 2708/2708 [00:00<00:00, 292789.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.783341884613037\n",
      "[0.14285714285714285, 0.188, 0.191]\n",
      "std_dev:  0.24009498068475416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2708/2708 [00:00<00:00, 297911.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -4.759803295135498\n",
      "[0.14285714285714285, 0.182, 0.18]\n",
      "std_dev:  0.12428656715334171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 2708/2708 [00:00<00:00, 289993.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.3753838539123535\n",
      "[0.17142857142857143, 0.192, 0.196]\n",
      "std_dev:  0.26806165777606233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 2708/2708 [00:00<00:00, 297420.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.554967403411865\n",
      "[0.17142857142857143, 0.21, 0.195]\n",
      "std_dev:  0.38171284438796177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 2708/2708 [00:00<00:00, 296055.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.69307279586792\n",
      "[0.17857142857142858, 0.182, 0.184]\n",
      "std_dev:  0.3903101838133387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 2708/2708 [00:00<00:00, 286417.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.20971155166626\n",
      "[0.11428571428571428, 0.186, 0.215]\n",
      "std_dev:  0.3235534827836834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 2708/2708 [00:00<00:00, 295978.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.794029235839844\n",
      "[0.12857142857142856, 0.214, 0.229]\n",
      "std_dev:  0.2113357987802573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 2708/2708 [00:00<00:00, 290430.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -5.718504905700684\n",
      "[0.15714285714285714, 0.214, 0.232]\n",
      "std_dev:  0.20713750234448494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 2708/2708 [00:00<00:00, 294611.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.5621256828308105\n",
      "[0.18571428571428572, 0.232, 0.249]\n",
      "std_dev:  0.4352665351238003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 2708/2708 [00:00<00:00, 273552.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.385224342346191\n",
      "[0.16428571428571428, 0.23, 0.235]\n",
      "std_dev:  0.48760003173606264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 2708/2708 [00:00<00:00, 304084.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.397919178009033\n",
      "[0.17857142857142858, 0.244, 0.223]\n",
      "std_dev:  0.3456069668336938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 2708/2708 [00:00<00:00, 275136.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.759185314178467\n",
      "[0.11428571428571428, 0.234, 0.241]\n",
      "std_dev:  0.3503393689586864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 2708/2708 [00:00<00:00, 296713.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.795901775360107\n",
      "[0.15714285714285714, 0.246, 0.243]\n",
      "std_dev:  0.17328092901275985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 2708/2708 [00:00<00:00, 279585.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.921358108520508\n",
      "[0.08571428571428572, 0.24, 0.235]\n",
      "std_dev:  0.21930639978933217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 2708/2708 [00:00<00:00, 293606.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -6.710286617279053\n",
      "[0.1357142857142857, 0.24, 0.234]\n",
      "std_dev:  0.17414071523584176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 2708/2708 [00:00<00:00, 300107.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -7.6307220458984375\n",
      "[0.10714285714285714, 0.236, 0.219]\n",
      "std_dev:  0.34085535643682924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 2708/2708 [00:00<00:00, 276590.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -7.337201118469238\n",
      "[0.10714285714285714, 0.216, 0.232]\n",
      "std_dev:  0.3498600059260837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 2708/2708 [00:00<00:00, 294253.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -7.139853000640869\n",
      "[0.14285714285714285, 0.23, 0.227]\n",
      "std_dev:  0.3199510886800877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 2708/2708 [00:00<00:00, 304174.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -7.701308727264404\n",
      "[0.12142857142857143, 0.244, 0.234]\n",
      "std_dev:  0.35920567187187835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 2708/2708 [00:00<00:00, 299569.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -7.833904266357422\n",
      "[0.1357142857142857, 0.228, 0.238]\n",
      "std_dev:  0.25346623961634973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 2708/2708 [00:00<00:00, 273592.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.12182903289795\n",
      "[0.10714285714285714, 0.242, 0.254]\n",
      "std_dev:  0.35056593146334664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 2708/2708 [00:00<00:00, 301629.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.776068687438965\n",
      "[0.1357142857142857, 0.252, 0.263]\n",
      "std_dev:  0.536154838217388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 2708/2708 [00:00<00:00, 294215.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.674227714538574\n",
      "[0.07857142857142857, 0.268, 0.269]\n",
      "std_dev:  0.4343437629411276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 2708/2708 [00:00<00:00, 273230.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.714618682861328\n",
      "[0.18571428571428572, 0.252, 0.254]\n",
      "std_dev:  0.6467648235415069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 2708/2708 [00:00<00:00, 298020.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.98974609375\n",
      "[0.11428571428571428, 0.246, 0.249]\n",
      "std_dev:  0.5164394996229442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 2708/2708 [00:00<00:00, 292089.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.672684669494629\n",
      "[0.09285714285714286, 0.25, 0.248]\n",
      "std_dev:  0.3919773599474722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 2708/2708 [00:00<00:00, 280608.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.57900619506836\n",
      "[0.1, 0.264, 0.235]\n",
      "std_dev:  0.44268378426959415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 2708/2708 [00:00<00:00, 292706.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -8.911829948425293\n",
      "[0.17857142857142858, 0.228, 0.226]\n",
      "std_dev:  0.4025661144872918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 2708/2708 [00:00<00:00, 305105.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.172887802124023\n",
      "[0.1, 0.204, 0.198]\n",
      "std_dev:  0.30294468584218937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 2708/2708 [00:00<00:00, 294306.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.486105918884277\n",
      "[0.14285714285714285, 0.166, 0.202]\n",
      "std_dev:  0.3408931158813701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 2708/2708 [00:00<00:00, 300918.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.795394897460938\n",
      "[0.1357142857142857, 0.162, 0.19]\n",
      "std_dev:  0.31147534618842854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2708/2708 [00:00<00:00, 304712.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -10.22164535522461\n",
      "[0.19285714285714287, 0.166, 0.172]\n",
      "std_dev:  0.4603532546772912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 2708/2708 [00:00<00:00, 291056.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -9.74476432800293\n",
      "[0.15, 0.144, 0.163]\n",
      "std_dev:  0.34801185998000256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 2708/2708 [00:00<00:00, 286706.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -11.200347900390625\n",
      "[0.17142857142857143, 0.182, 0.147]\n",
      "std_dev:  0.6034683504025491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 2708/2708 [00:00<00:00, 306927.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -10.594610214233398\n",
      "[0.12142857142857143, 0.16, 0.156]\n",
      "std_dev:  0.5414479717714347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 2708/2708 [00:00<00:00, 303727.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -11.36557674407959\n",
      "[0.14285714285714285, 0.142, 0.167]\n",
      "std_dev:  0.6029778952671014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 2708/2708 [00:00<00:00, 303062.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -11.479792594909668\n",
      "[0.17142857142857143, 0.146, 0.152]\n",
      "std_dev:  0.6431674149680721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 2708/2708 [00:00<00:00, 297817.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -11.792736053466797\n",
      "[0.15714285714285714, 0.118, 0.158]\n",
      "std_dev:  0.39649052874892005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 2708/2708 [00:00<00:00, 281400.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -12.169478416442871\n",
      "[0.12142857142857143, 0.184, 0.154]\n",
      "std_dev:  0.5234866111722789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 2708/2708 [00:00<00:00, 294680.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -12.210323333740234\n",
      "[0.11428571428571428, 0.126, 0.151]\n",
      "std_dev:  0.34528959374870916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 2708/2708 [00:00<00:00, 280428.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -12.65176010131836\n",
      "[0.17142857142857143, 0.126, 0.147]\n",
      "std_dev:  0.39820345288463804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2708/2708 [00:00<00:00, 295309.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -11.687650680541992\n",
      "[0.12142857142857143, 0.126, 0.152]\n",
      "std_dev:  0.3423016909345662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 2708/2708 [00:00<00:00, 268660.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -13.043615341186523\n",
      "[0.06428571428571428, 0.152, 0.141]\n",
      "std_dev:  0.46107108424288423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|██████████| 2708/2708 [00:00<00:00, 296503.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -12.247502326965332\n",
      "[0.14285714285714285, 0.134, 0.149]\n",
      "std_dev:  0.45590186575977365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|██████████| 2708/2708 [00:00<00:00, 293530.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -12.991074562072754\n",
      "[0.16428571428571428, 0.16, 0.167]\n",
      "std_dev:  0.5060458529111032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 100%|██████████| 2708/2708 [00:00<00:00, 292352.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.662474632263184\n",
      "[0.14285714285714285, 0.162, 0.192]\n",
      "std_dev:  1.0027242163944554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 100%|██████████| 2708/2708 [00:00<00:00, 295785.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -13.088491439819336\n",
      "[0.12857142857142856, 0.16, 0.163]\n",
      "std_dev:  0.790747005263539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 2708/2708 [00:00<00:00, 277841.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -13.561440467834473\n",
      "[0.1357142857142857, 0.19, 0.188]\n",
      "std_dev:  0.7965036759172216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106: 100%|██████████| 2708/2708 [00:00<00:00, 294078.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.180228233337402\n",
      "[0.19285714285714287, 0.182, 0.168]\n",
      "std_dev:  0.6407246267097766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 100%|██████████| 2708/2708 [00:00<00:00, 288578.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.229084968566895\n",
      "[0.09285714285714286, 0.18, 0.177]\n",
      "std_dev:  0.5534490248297359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 100%|██████████| 2708/2708 [00:00<00:00, 291407.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.9847993850708\n",
      "[0.1357142857142857, 0.176, 0.177]\n",
      "std_dev:  0.6446062833676839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 100%|██████████| 2708/2708 [00:00<00:00, 271499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -15.275996208190918\n",
      "[0.12142857142857143, 0.152, 0.162]\n",
      "std_dev:  0.6130791680822772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 100%|██████████| 2708/2708 [00:00<00:00, 298091.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.751870155334473\n",
      "[0.1357142857142857, 0.162, 0.152]\n",
      "std_dev:  0.4257414788384245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111: 100%|██████████| 2708/2708 [00:00<00:00, 285668.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.630796432495117\n",
      "[0.20714285714285716, 0.138, 0.127]\n",
      "std_dev:  0.35053235498104857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 100%|██████████| 2708/2708 [00:00<00:00, 288879.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.05681037902832\n",
      "[0.12857142857142856, 0.138, 0.152]\n",
      "std_dev:  0.4064561568521667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|██████████| 2708/2708 [00:00<00:00, 287214.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -14.859305381774902\n",
      "[0.15714285714285714, 0.16, 0.139]\n",
      "std_dev:  0.39425981415715017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114: 100%|██████████| 2708/2708 [00:00<00:00, 285862.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -16.025711059570312\n",
      "[0.15, 0.168, 0.144]\n",
      "std_dev:  0.6431333730091956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115: 100%|██████████| 2708/2708 [00:00<00:00, 294344.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -15.587749481201172\n",
      "[0.12142857142857143, 0.138, 0.131]\n",
      "std_dev:  0.6982981682025283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116: 100%|██████████| 2708/2708 [00:00<00:00, 291833.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -16.09608268737793\n",
      "[0.15, 0.144, 0.157]\n",
      "std_dev:  0.7719816183019423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117: 100%|██████████| 2708/2708 [00:00<00:00, 291721.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -16.61261749267578\n",
      "[0.17142857142857143, 0.164, 0.154]\n",
      "std_dev:  0.5869119674686185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118: 100%|██████████| 2708/2708 [00:00<00:00, 291369.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -15.4801607131958\n",
      "[0.15, 0.17, 0.136]\n",
      "std_dev:  0.4043664538499336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2708/2708 [00:00<00:00, 272914.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -16.81685447692871\n",
      "[0.16428571428571428, 0.148, 0.149]\n",
      "std_dev:  0.5332028844661386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120: 100%|██████████| 2708/2708 [00:00<00:00, 297373.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -16.905176162719727\n",
      "[0.14285714285714285, 0.15, 0.144]\n",
      "std_dev:  0.5312360663933684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|██████████| 2708/2708 [00:00<00:00, 294039.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -17.280975341796875\n",
      "[0.15714285714285714, 0.168, 0.14]\n",
      "std_dev:  0.6093028931287463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122: 100%|██████████| 2708/2708 [00:00<00:00, 292427.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.334848403930664\n",
      "[0.15, 0.154, 0.147]\n",
      "std_dev:  0.9172337764992797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123: 100%|██████████| 2708/2708 [00:00<00:00, 290907.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.024290084838867\n",
      "[0.22142857142857142, 0.152, 0.138]\n",
      "std_dev:  0.6060571136745487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124: 100%|██████████| 2708/2708 [00:00<00:00, 290735.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -17.151018142700195\n",
      "[0.15, 0.138, 0.136]\n",
      "std_dev:  0.5454759589161166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125: 100%|██████████| 2708/2708 [00:00<00:00, 273625.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.193025588989258\n",
      "[0.2, 0.14, 0.138]\n",
      "std_dev:  0.7448140673189746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126: 100%|██████████| 2708/2708 [00:00<00:00, 300123.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.25599479675293\n",
      "[0.17857142857142858, 0.138, 0.142]\n",
      "std_dev:  0.6539606926626169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127: 100%|██████████| 2708/2708 [00:00<00:00, 291586.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.2493953704834\n",
      "[0.17142857142857143, 0.148, 0.131]\n",
      "std_dev:  0.7834569640397384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128: 100%|██████████| 2708/2708 [00:00<00:00, 291586.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.177581787109375\n",
      "[0.17857142857142858, 0.152, 0.149]\n",
      "std_dev:  0.7720594731733764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129: 100%|██████████| 2708/2708 [00:00<00:00, 289564.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.012155532836914\n",
      "[0.15714285714285714, 0.132, 0.149]\n",
      "std_dev:  0.4652481980082162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130: 100%|██████████| 2708/2708 [00:00<00:00, 268318.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.805423736572266\n",
      "[0.16428571428571428, 0.116, 0.122]\n",
      "std_dev:  0.4196312340431603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131: 100%|██████████| 2708/2708 [00:00<00:00, 288659.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -18.934370040893555\n",
      "[0.17142857142857143, 0.134, 0.133]\n",
      "std_dev:  0.35945858996235264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132: 100%|██████████| 2708/2708 [00:00<00:00, 294001.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.282020568847656\n",
      "[0.22142857142857142, 0.132, 0.127]\n",
      "std_dev:  0.367121814647993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133: 100%|██████████| 2708/2708 [00:00<00:00, 268998.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -20.087608337402344\n",
      "[0.18571428571428572, 0.146, 0.131]\n",
      "std_dev:  0.4589455149517175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134: 100%|██████████| 2708/2708 [00:00<00:00, 305952.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.63761329650879\n",
      "[0.14285714285714285, 0.118, 0.125]\n",
      "std_dev:  0.4691947321330433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135: 100%|██████████| 2708/2708 [00:00<00:00, 298005.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -19.406190872192383\n",
      "[0.1357142857142857, 0.116, 0.137]\n",
      "std_dev:  0.3836249821780985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136: 100%|██████████| 2708/2708 [00:00<00:00, 288205.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -20.507930755615234\n",
      "[0.19285714285714287, 0.122, 0.134]\n",
      "std_dev:  0.4544019240216537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137: 100%|██████████| 2708/2708 [00:00<00:00, 287381.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -20.603757858276367\n",
      "[0.16428571428571428, 0.156, 0.119]\n",
      "std_dev:  0.4695330013830818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138: 100%|██████████| 2708/2708 [00:00<00:00, 289166.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -20.327388763427734\n",
      "[0.17857142857142858, 0.156, 0.116]\n",
      "std_dev:  0.4831147052174067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139: 100%|██████████| 2708/2708 [00:00<00:00, 289328.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -20.795454025268555\n",
      "[0.14285714285714285, 0.148, 0.138]\n",
      "std_dev:  0.4851109308891376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140: 100%|██████████| 2708/2708 [00:00<00:00, 272888.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.006423950195312\n",
      "[0.17857142857142858, 0.128, 0.144]\n",
      "std_dev:  0.5985055254084589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141: 100%|██████████| 2708/2708 [00:00<00:00, 295462.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.6265926361084\n",
      "[0.10714285714285714, 0.132, 0.118]\n",
      "std_dev:  0.8877199708674159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142: 100%|██████████| 2708/2708 [00:00<00:00, 307726.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.613496780395508\n",
      "[0.15714285714285714, 0.13, 0.137]\n",
      "std_dev:  0.9471850276136407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143: 100%|██████████| 2708/2708 [00:00<00:00, 291991.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -23.399858474731445\n",
      "[0.14285714285714285, 0.134, 0.119]\n",
      "std_dev:  0.8676174602737803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144: 100%|██████████| 2708/2708 [00:00<00:00, 287410.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.849992752075195\n",
      "[0.15, 0.122, 0.129]\n",
      "std_dev:  0.44860143825685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145: 100%|██████████| 2708/2708 [00:00<00:00, 294291.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.94580078125\n",
      "[0.15714285714285714, 0.122, 0.136]\n",
      "std_dev:  0.28651938145241174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146: 100%|██████████| 2708/2708 [00:00<00:00, 287898.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.86722755432129\n",
      "[0.09285714285714286, 0.12, 0.13]\n",
      "std_dev:  0.25744643573001647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147: 100%|██████████| 2708/2708 [00:00<00:00, 283154.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -23.517728805541992\n",
      "[0.1357142857142857, 0.148, 0.124]\n",
      "std_dev:  0.2841045415326405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148: 100%|██████████| 2708/2708 [00:00<00:00, 264660.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -23.288068771362305\n",
      "[0.15714285714285714, 0.152, 0.137]\n",
      "std_dev:  0.26462683051817726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2708/2708 [00:00<00:00, 294268.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -22.7796630859375\n",
      "[0.17142857142857143, 0.152, 0.133]\n",
      "std_dev:  0.2787050304870994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150: 100%|██████████| 2708/2708 [00:00<00:00, 295885.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  -23.377161026000977\n",
      "[0.12857142857142856, 0.13, 0.134]\n",
      "std_dev:  0.2904217958109664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy,  0.268\n",
      "Best Test Accuracy,  0.269\n",
      "0.269 150\n"
     ]
    }
   ],
   "source": [
    "# cornell5\n",
    "# penn94\n",
    "# johnshopkins55\n",
    "\n",
    "args.log_info = True\n",
    "DATASET_NAME = 'Cora'\n",
    "data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=True, split_no=0); print(\"\")\n",
    "\n",
    "#if DATASET_NAME in ['Squirrel', 'Chameleon']:\n",
    "# data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "# if args.log_info == True:\n",
    "#     print(data.x.shape)\n",
    "\n",
    "best_acc, num_iteration, _ = LINKXperformance(DATASET_NAME, data, dataset, dataset.num_classes, epochs=150,\n",
    "                             train_neighbors=[8,4],test_neighbors=[8,4])    \n",
    "print(best_acc, num_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_experiments(num_run=1):\n",
    "    \n",
    "    ALL_DATASETs= [\n",
    "#         \"Cornell\",\n",
    "        \"Texas\",\n",
    "        \"Wisconsin\",\n",
    "        \"reed98\",\n",
    "        \"amherst41\",\n",
    "        \"penn94\",\n",
    "        \"Roman-empire\",\n",
    "#         \"cornell5\",\n",
    "        \"Squirrel\",\n",
    "        \"johnshopkins55\",\n",
    "        \"AmazonProducts\",\n",
    "        \"Actor\",\n",
    "        \"Minesweeper\",\n",
    "        \"Questions\",\n",
    "        \"Chameleon\",\n",
    "        \"Tolokers\",\n",
    "        \"Flickr\",\n",
    "        \"Yelp\",\n",
    "        \"Amazon-ratings\",\n",
    "        \"genius\",\n",
    "        \"cora\",\n",
    "        \"CiteSeer\",\n",
    "        \"dblp\",\n",
    "        \"Computers\",\n",
    "        \"PubMed\",\n",
    "        \"pubmed\",\n",
    "        \"Reddit\",\n",
    "        \"cora_ml\",\n",
    "        \"Cora\",\n",
    "        \"Reddit2\",\n",
    "        \"CS\",\n",
    "        \"Photo\",\n",
    "        \"Physics\",\n",
    "        \"citeseer\"\n",
    "    ]     \n",
    "#     ALL_DATASETs= [\"Cora\"]\n",
    "    \n",
    "    args.log_info = False\n",
    "    runtime_filename = \"Runtime/AGSLINKX.txt\"\n",
    "    \n",
    "    for DATASET_NAME in ALL_DATASETs:  \n",
    "        print(DATASET_NAME, end=' ')        \n",
    "        result_file = open(\"Results/AGSLINKX.txt\",'a+')                \n",
    "        result_file.write(f'{DATASET_NAME} ')\n",
    "        \n",
    "        acc_file = open(runtime_filename,'a+') \n",
    "        acc_file.write(f'{DATASET_NAME}\\n')\n",
    "        acc_file.close()     \n",
    "        \n",
    "        \n",
    "        accs = []\n",
    "        itrs = []\n",
    "        \n",
    "        for i in range(num_run):\n",
    "            data, dataset = get_data(DATASET_NAME, DIR=None, log=False, h_score=False, split_no=i)       \n",
    "                        \n",
    "            if data.num_nodes>100000:\n",
    "                accs.append(-1)\n",
    "                itrs.append(-1)\n",
    "                break         \n",
    "                \n",
    "            \n",
    "            if len(data.y.shape) > 1:\n",
    "                data.y = data.y.argmax(dim=1)        \n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            else:\n",
    "                num_classes = dataset.num_classes\n",
    "            \n",
    "            if num_classes!= torch.max(data.y)+1:\n",
    "                num_classes = torch.max(data.y).item()+1\n",
    "            if data.num_nodes<100000:\n",
    "                max_epochs = 150\n",
    "            else:\n",
    "                max_epochs = 20\n",
    "                                \n",
    "            accuracy, itr, _ = LINKXperformance(DATASET_NAME, data, dataset, num_classes, epochs=max_epochs,train_neighbors=[8,4],test_neighbors=[8,4])\n",
    "            accs.append(accuracy)\n",
    "            itrs.append(itr)\n",
    "            #print(itr, accuracy)\n",
    "                        \n",
    "        #print(accs, itrs)\n",
    "        print(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}')\n",
    "        result_file.write(f'acc {np.mean(accs):0.4f} sd {np.std(accs):0.4f} itr {int(np.mean(itrs)):d} sd {int(np.std(itrs)):d}\\n')\n",
    "        result_file.close()\n",
    "\n",
    "# start = time.time()\n",
    "# batch_experiments(num_run = 1)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Time spent:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
