{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07e25af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not os.getcwd().endswith(\"Submodular\"):\n",
    "    sys.path.append('../Submodular')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d93d7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e2a07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import BatchNorm1d, Parameter\n",
    "\n",
    "from torch_geometric.nn import inits\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.typing import Adj, OptTensor, SparseTensor\n",
    "# from torch_geometric.utils import spmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9f080d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import torch_geometric.typing\n",
    "from torch_geometric.typing import SparseTensor\n",
    "from torch_geometric.utils import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8648b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import torch_geometric.typing\n",
    "# from torch_geometric import warnings\n",
    "# from torch_geometric.typing import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecd6b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if torch_geometric.typing.WITH_PT112:  # pragma: no cover\n",
    "\n",
    "#     warnings.filterwarnings('ignore', '.*is in beta and the API may change.*')\n",
    "\n",
    "#     def scatter(src: Tensor, index: Tensor, dim: int = 0,\n",
    "#                 dim_size: Optional[int] = None, reduce: str = 'sum') -> Tensor:\n",
    "#         r\"\"\"Reduces all values from the :obj:`src` tensor at the indices\n",
    "#         specified in the :obj:`index` tensor along a given dimension\n",
    "#         :obj:`dim`. See the `documentation\n",
    "#         <https://pytorch-scatter.readthedocs.io/en/latest/functions/\n",
    "#         scatter.html>`__ of the :obj:`torch_scatter` package for more\n",
    "#         information.\n",
    "\n",
    "#         Args:\n",
    "#             src (torch.Tensor): The source tensor.\n",
    "#             index (torch.Tensor): The index tensor.\n",
    "#             dim (int, optional): The dimension along which to index.\n",
    "#                 (default: :obj:`0`)\n",
    "#             dim_size (int, optional): The size of the output tensor at\n",
    "#                 dimension :obj:`dim`. If set to :obj:`None`, will create a\n",
    "#                 minimal-sized output tensor according to\n",
    "#                 :obj:`index.max() + 1`. (default: :obj:`None`)\n",
    "#             reduce (str, optional): The reduce operation (:obj:`\"sum\"`,\n",
    "#                 :obj:`\"mean\"`, :obj:`\"mul\"`, :obj:`\"min\"` or :obj:`\"max\"`,\n",
    "#                 :obj:`\"any\"`). (default: :obj:`\"sum\"`)\n",
    "#         \"\"\"\n",
    "#         if isinstance(index, Tensor) and index.dim() != 1:\n",
    "#             raise ValueError(f\"The `index` argument must be one-dimensional \"\n",
    "#                              f\"(got {index.dim()} dimensions)\")\n",
    "\n",
    "#         dim = src.dim() + dim if dim < 0 else dim\n",
    "\n",
    "#         if isinstance(src, Tensor) and (dim < 0 or dim >= src.dim()):\n",
    "#             raise ValueError(f\"The `dim` argument must lay between 0 and \"\n",
    "#                              f\"{src.dim() - 1} (got {dim})\")\n",
    "\n",
    "#         if dim_size is None:\n",
    "#             dim_size = int(index.max()) + 1 if index.numel() > 0 else 0\n",
    "\n",
    "#         # For now, we maintain various different code paths, based on whether\n",
    "#         # the input requires gradients and whether it lays on the CPU/GPU.\n",
    "#         # For example, `torch_scatter` is usually faster than\n",
    "#         # `torch.scatter_reduce` on GPU, while `torch.scatter_reduce` is faster\n",
    "#         # on CPU.\n",
    "#         # `torch.scatter_reduce` has a faster forward implementation for\n",
    "#         # \"min\"/\"max\" reductions since it does not compute additional arg\n",
    "#         # indices, but is therefore way slower in its backward implementation.\n",
    "#         # More insights can be found in `test/utils/test_scatter.py`.\n",
    "\n",
    "#         size = src.size()[:dim] + (dim_size, ) + src.size()[dim + 1:]\n",
    "\n",
    "#         # For \"any\" reduction, we use regular `scatter_`:\n",
    "#         if reduce == 'any':\n",
    "#             index = broadcast(index, src, dim)\n",
    "#             return src.new_zeros(size).scatter_(dim, index, src)\n",
    "\n",
    "#         # For \"sum\" and \"mean\" reduction, we make use of `scatter_add_`:\n",
    "#         if reduce == 'sum' or reduce == 'add':\n",
    "#             index = broadcast(index, src, dim)\n",
    "#             return src.new_zeros(size).scatter_add_(dim, index, src)\n",
    "\n",
    "#         if reduce == 'mean':\n",
    "#             count = src.new_zeros(dim_size)\n",
    "#             count.scatter_add_(0, index, src.new_ones(src.size(dim)))\n",
    "#             count = count.clamp(min=1)\n",
    "\n",
    "#             index = broadcast(index, src, dim)\n",
    "#             out = src.new_zeros(size).scatter_add_(dim, index, src)\n",
    "\n",
    "#             return out / broadcast(count, out, dim)\n",
    "\n",
    "#         # For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\n",
    "#         # in case the input does not require gradients:\n",
    "#         if reduce == 'min' or reduce == 'max':\n",
    "#             if (not torch_geometric.typing.WITH_TORCH_SCATTER\n",
    "#                     or not src.is_cuda or not src.requires_grad):\n",
    "\n",
    "#                 if src.is_cuda and src.requires_grad:\n",
    "#                     warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
    "#                                   f\"can be accelerated via the 'torch-scatter'\"\n",
    "#                                   f\" package, but it was not found\")\n",
    "\n",
    "#                 index = broadcast(index, src, dim)\n",
    "#                 return src.new_zeros(size).scatter_reduce_(\n",
    "#                     dim, index, src, reduce=f'a{reduce}', include_self=False)\n",
    "\n",
    "#             return torch_scatter.scatter(src, index, dim, dim_size=dim_size,\n",
    "#                                          reduce=reduce)\n",
    "\n",
    "#         # For \"mul\" reduction, we prefer `scatter_reduce_` on CPU:\n",
    "#         if reduce == 'mul':\n",
    "#             if (not torch_geometric.typing.WITH_TORCH_SCATTER\n",
    "#                     or not src.is_cuda):\n",
    "\n",
    "#                 if src.is_cuda:\n",
    "#                     warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
    "#                                   f\"can be accelerated via the 'torch-scatter'\"\n",
    "#                                   f\" package, but it was not found\")\n",
    "\n",
    "#                 index = broadcast(index, src, dim)\n",
    "#                 # We initialize with `one` here to match `scatter_mul` output:\n",
    "#                 return src.new_ones(size).scatter_reduce_(\n",
    "#                     dim, index, src, reduce='prod', include_self=True)\n",
    "\n",
    "#             return torch_scatter.scatter(src, index, dim, dim_size=dim_size,\n",
    "#                                          reduce='mul')\n",
    "\n",
    "#         raise ValueError(f\"Encountered invalid `reduce` argument '{reduce}'\")\n",
    "\n",
    "# else:  # pragma: no cover\n",
    "\n",
    "def scatter(src: Tensor, index: Tensor, dim: int = 0,\n",
    "            dim_size: Optional[int] = None, reduce: str = 'sum') -> Tensor:\n",
    "    r\"\"\"Reduces all values from the :obj:`src` tensor at the indices\n",
    "    specified in the :obj:`index` tensor along a given dimension\n",
    "    :obj:`dim`. See the `documentation\n",
    "    <https://pytorch-scatter.readthedocs.io/en/latest/functions/\n",
    "    scatter.html>`_ of the :obj:`torch_scatter` package for more\n",
    "    information.\n",
    "\n",
    "    Args:\n",
    "        src (torch.Tensor): The source tensor.\n",
    "        index (torch.Tensor): The index tensor.\n",
    "        dim (int, optional): The dimension along which to index.\n",
    "            (default: :obj:`0`)\n",
    "        dim_size (int, optional): The size of the output tensor at\n",
    "            dimension :obj:`dim`. If set to :obj:`None`, will create a\n",
    "            minimal-sized output tensor according to\n",
    "            :obj:`index.max() + 1`. (default: :obj:`None`)\n",
    "        reduce (str, optional): The reduce operation (:obj:`\"sum\"`,\n",
    "            :obj:`\"mean\"`, :obj:`\"mul\"`, :obj:`\"min\"` or :obj:`\"max\"`).\n",
    "            (default: :obj:`\"sum\"`)\n",
    "    \"\"\"\n",
    "    if reduce == 'any':\n",
    "        dim = src.dim() + dim if dim < 0 else dim\n",
    "\n",
    "        if dim_size is None:\n",
    "            dim_size = int(index.max()) + 1 if index.numel() > 0 else 0\n",
    "\n",
    "        size = src.size()[:dim] + (dim_size, ) + src.size()[dim + 1:]\n",
    "\n",
    "        index = broadcast(index, src, dim)\n",
    "        return src.new_zeros(size).scatter_(dim, index, src)\n",
    "\n",
    "    if not torch_geometric.typing.WITH_TORCH_SCATTER:\n",
    "        raise ImportError(\"'scatter' requires the 'torch-scatter' package\")\n",
    "    return torch_scatter.scatter(src, index, dim, dim_size=dim_size,\n",
    "                                 reduce=reduce)\n",
    "\n",
    "\n",
    "def broadcast(src: Tensor, ref: Tensor, dim: int) -> Tensor:\n",
    "    size = ((1, ) * dim) + (-1, ) + ((1, ) * (ref.dim() - dim - 1))\n",
    "    return src.view(size).expand_as(ref)\n",
    "\n",
    "\n",
    "def scatter_argmax(src: Tensor, index: Tensor, dim: int = 0,\n",
    "                   dim_size: Optional[int] = None) -> Tensor:\n",
    "\n",
    "    if torch_geometric.typing.WITH_TORCH_SCATTER:\n",
    "        out = torch_scatter.scatter_max(src, index, dim=dim, dim_size=dim_size)\n",
    "        return out[1]\n",
    "\n",
    "    # Only implemented under certain conditions for now :(\n",
    "    assert src.dim() == 1 and index.dim() == 1\n",
    "    assert dim == 0 or dim == -1\n",
    "    assert src.numel() == index.numel()\n",
    "\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max() + 1 if index.numel() > 0 else 0\n",
    "\n",
    "    if torch_geometric.typing.WITH_PT112:\n",
    "        res = src.new_empty(dim_size)\n",
    "        res.scatter_reduce_(0, index, src.detach(), reduce='amax',\n",
    "                            include_self=False)\n",
    "    elif torch_geometric.typing.WITH_PT111:\n",
    "        res = torch.scatter_reduce(src.detach(), 0, index, reduce='amax',\n",
    "                                   output_size=dim_size)\n",
    "    else:\n",
    "        raise ValueError(\"'scatter_argmax' requires PyTorch >= 1.11\")\n",
    "\n",
    "    out = index.new_full((dim_size, ), fill_value=dim_size - 1)\n",
    "    nonzero = (src == res[index]).nonzero().view(-1)\n",
    "    out[index[nonzero]] = nonzero\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def group_argsort(\n",
    "    src: Tensor,\n",
    "    index: Tensor,\n",
    "    dim: int = 0,\n",
    "    num_groups: Optional[int] = None,\n",
    "    descending: bool = False,\n",
    "    return_consecutive: bool = False,\n",
    "    stable: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Returns the indices that sort the tensor :obj:`src` along a given\n",
    "    dimension in ascending order by value.\n",
    "    In contrast to :meth:`torch.argsort`, sorting is performed in groups\n",
    "    according to the values in :obj:`index`.\n",
    "\n",
    "    Args:\n",
    "        src (torch.Tensor): The source tensor.\n",
    "        index (torch.Tensor): The index tensor.\n",
    "        dim (int, optional): The dimension along which to index.\n",
    "            (default: :obj:`0`)\n",
    "        num_groups (int, optional): The number of groups.\n",
    "            (default: :obj:`None`)\n",
    "        descending (bool, optional): Controls the sorting order (ascending or\n",
    "            descending). (default: :obj:`False`)\n",
    "        return_consecutive (bool, optional): If set to :obj:`True`, will not\n",
    "            offset the output to start from :obj:`0` for each group.\n",
    "            (default: :obj:`False`)\n",
    "        stable (bool, optional): Controls the relative order of equivalent\n",
    "            elements. (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    # Only implemented under certain conditions for now :(\n",
    "    assert src.dim() == 1 and index.dim() == 1\n",
    "    assert dim == 0 or dim == -1\n",
    "    assert src.numel() == index.numel() and src.numel() > 0\n",
    "\n",
    "    # Normalize `src` to range [0, 1]:\n",
    "    src = src - src.min()\n",
    "    src = src / src.max()\n",
    "\n",
    "    # Compute `grouped_argsort`:\n",
    "    src = src - 2 * index if descending else src + 2 * index\n",
    "    if torch_geometric.typing.WITH_PT113:\n",
    "        perm = src.argsort(descending=descending, stable=stable)\n",
    "    else:\n",
    "        perm = src.argsort(descending=descending)\n",
    "        if stable:\n",
    "            warnings.warn(\"Ignoring option `stable=True` in 'group_argsort' \"\n",
    "                          \"since it requires PyTorch >= 1.13.0\")\n",
    "    out = torch.empty_like(index)\n",
    "    out[perm] = torch.arange(index.numel(), device=index.device)\n",
    "\n",
    "    if return_consecutive:\n",
    "        return out\n",
    "\n",
    "    # Compute cumulative sum of number of entries with the same index:\n",
    "    count = scatter(torch.ones_like(index), index, dim=dim,\n",
    "                    dim_size=num_groups, reduce='sum')\n",
    "    ptr = count.new_zeros(count.numel() + 1)\n",
    "    torch.cumsum(count, dim=0, out=ptr[1:])\n",
    "\n",
    "    return out - ptr[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7e630fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def dense_to_sparse(adj: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    r\"\"\"Converts a dense adjacency matrix to a sparse adjacency matrix defined\n",
    "    by edge indices and edge attributes.\n",
    "\n",
    "    Args:\n",
    "        adj (Tensor): The dense adjacency matrix of shape\n",
    "            :obj:`[num_nodes, num_nodes]` or\n",
    "            :obj:`[batch_size, num_nodes, num_nodes]`.\n",
    "\n",
    "    :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> # Forr a single adjacency matrix\n",
    "        >>> adj = torch.tensor([[3, 1],\n",
    "        ...                     [2, 0]])\n",
    "        >>> dense_to_sparse(adj)\n",
    "        (tensor([[0, 0, 1],\n",
    "                [0, 1, 0]]),\n",
    "        tensor([3, 1, 2]))\n",
    "\n",
    "        >>> # For two adjacency matrixes\n",
    "        >>> adj = torch.tensor([[[3, 1],\n",
    "        ...                      [2, 0]],\n",
    "        ...                     [[0, 1],\n",
    "        ...                      [0, 2]]])\n",
    "        >>> dense_to_sparse(adj)\n",
    "        (tensor([[0, 0, 1, 2, 3],\n",
    "                [0, 1, 0, 3, 3]]),\n",
    "        tensor([3, 1, 2, 1, 2]))\n",
    "    \"\"\"\n",
    "    if adj.dim() < 2 or adj.dim() > 3:\n",
    "        raise ValueError(f\"Dense adjacency matrix 'adj' must be 2- or \"\n",
    "                         f\"3-dimensional (got {adj.dim()} dimensions)\")\n",
    "\n",
    "    edge_index = adj.nonzero().t()\n",
    "\n",
    "    if edge_index.size(0) == 2:\n",
    "        edge_attr = adj[edge_index[0], edge_index[1]]\n",
    "        return edge_index, edge_attr\n",
    "    else:\n",
    "        edge_attr = adj[edge_index[0], edge_index[1], edge_index[2]]\n",
    "        row = edge_index[1] + adj.size(-2) * edge_index[0]\n",
    "        col = edge_index[2] + adj.size(-1) * edge_index[0]\n",
    "        return torch.stack([row, col], dim=0), edge_attr\n",
    "\n",
    "\n",
    "def is_torch_sparse_tensor(src: Any) -> bool:\n",
    "    r\"\"\"Returns :obj:`True` if the input :obj:`src` is a\n",
    "    :class:`torch.sparse.Tensor` (in any sparse layout).\n",
    "\n",
    "    Args:\n",
    "        src (Any): The input object to be checked.\n",
    "    \"\"\"\n",
    "    if isinstance(src, Tensor):\n",
    "        if src.layout == torch.sparse_coo:\n",
    "            return True\n",
    "        if src.layout == torch.sparse_csr:\n",
    "            return True\n",
    "        if (torch_geometric.typing.WITH_PT112\n",
    "                and src.layout == torch.sparse_csc):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_sparse(src: Any) -> bool:\n",
    "    r\"\"\"Returns :obj:`True` if the input :obj:`src` is of type\n",
    "    :class:`torch.sparse.Tensor` (in any sparse layout) or of type\n",
    "    :class:`torch_sparse.SparseTensor`.\n",
    "\n",
    "    Args:\n",
    "        src (Any): The input object to be checked.\n",
    "    \"\"\"\n",
    "    return is_torch_sparse_tensor(src) or isinstance(src, SparseTensor)\n",
    "\n",
    "\n",
    "def to_torch_coo_tensor(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    size: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "    is_coalesced: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Converts a sparse adjacency matrix defined by edge indices and edge\n",
    "    attributes to a :class:`torch.sparse.Tensor` with layout\n",
    "    `torch.sparse_coo`.\n",
    "    See :meth:`~torch_geometric.utils.to_edge_index` for the reverse operation.\n",
    "\n",
    "    Args:\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        edge_attr (Tensor, optional): The edge attributes.\n",
    "            (default: :obj:`None`)\n",
    "        size (int or (int, int), optional): The size of the sparse matrix.\n",
    "            If given as an integer, will create a quadratic sparse matrix.\n",
    "            If set to :obj:`None`, will infer a quadratic sparse matrix based\n",
    "            on :obj:`edge_index.max() + 1`. (default: :obj:`None`)\n",
    "        is_coalesced (bool): If set to :obj:`True`, will assume that\n",
    "            :obj:`edge_index` is already coalesced and thus avoids expensive\n",
    "            computation. (default: :obj:`False`)\n",
    "\n",
    "    :rtype: :class:`torch.sparse.Tensor`\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "        ...                            [1, 0, 2, 1, 3, 2]])\n",
    "        >>> to_torch_coo_tensor(edge_index)\n",
    "        tensor(indices=tensor([[0, 1, 1, 2, 2, 3],\n",
    "                               [1, 0, 2, 1, 3, 2]]),\n",
    "               values=tensor([1., 1., 1., 1., 1., 1.]),\n",
    "               size=(4, 4), nnz=6, layout=torch.sparse_coo)\n",
    "\n",
    "    \"\"\"\n",
    "    if size is None:\n",
    "        size = int(edge_index.max()) + 1\n",
    "    if not isinstance(size, (tuple, list)):\n",
    "        size = (size, size)\n",
    "\n",
    "    if not is_coalesced:\n",
    "        edge_index, edge_attr = coalesce(edge_index, edge_attr, max(size))\n",
    "\n",
    "    if edge_attr is None:\n",
    "        edge_attr = torch.ones(edge_index.size(1), device=edge_index.device)\n",
    "\n",
    "    adj = torch.sparse_coo_tensor(\n",
    "        indices=edge_index,\n",
    "        values=edge_attr,\n",
    "        size=tuple(size) + edge_attr.size()[1:],\n",
    "        device=edge_index.device,\n",
    "    )\n",
    "    adj = adj._coalesced_(True)\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "def to_torch_csr_tensor(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    size: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "    is_coalesced: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Converts a sparse adjacency matrix defined by edge indices and edge\n",
    "    attributes to a :class:`torch.sparse.Tensor` with layout\n",
    "    `torch.sparse_csr`.\n",
    "    See :meth:`~torch_geometric.utils.to_edge_index` for the reverse operation.\n",
    "\n",
    "    Args:\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        edge_attr (Tensor, optional): The edge attributes.\n",
    "            (default: :obj:`None`)\n",
    "        size (int or (int, int), optional): The size of the sparse matrix.\n",
    "            If given as an integer, will create a quadratic sparse matrix.\n",
    "            If set to :obj:`None`, will infer a quadratic sparse matrix based\n",
    "            on :obj:`edge_index.max() + 1`. (default: :obj:`None`)\n",
    "        is_coalesced (bool): If set to :obj:`True`, will assume that\n",
    "            :obj:`edge_index` is already coalesced and thus avoids expensive\n",
    "            computation. (default: :obj:`False`)\n",
    "\n",
    "    :rtype: :class:`torch.sparse.Tensor`\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "        ...                            [1, 0, 2, 1, 3, 2]])\n",
    "        >>> to_torch_csr_tensor(edge_index)\n",
    "        tensor(crow_indices=tensor([0, 1, 3, 5, 6]),\n",
    "               col_indices=tensor([1, 0, 2, 1, 3, 2]),\n",
    "               values=tensor([1., 1., 1., 1., 1., 1.]),\n",
    "               size=(4, 4), nnz=6, layout=torch.sparse_csr)\n",
    "\n",
    "    \"\"\"\n",
    "    if size is None:\n",
    "        size = int(edge_index.max()) + 1\n",
    "    if not isinstance(size, (tuple, list)):\n",
    "        size = (size, size)\n",
    "\n",
    "    if not is_coalesced:\n",
    "        edge_index, edge_attr = coalesce(edge_index, edge_attr, max(size))\n",
    "\n",
    "    if edge_attr is None:\n",
    "        edge_attr = torch.ones(edge_index.size(1), device=edge_index.device)\n",
    "\n",
    "    adj = torch.sparse_csr_tensor(\n",
    "        crow_indices=index2ptr(edge_index[0], size[0]),\n",
    "        col_indices=edge_index[1],\n",
    "        values=edge_attr,\n",
    "        size=tuple(size) + edge_attr.size()[1:],\n",
    "        device=edge_index.device,\n",
    "    )\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "def to_torch_csc_tensor(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    size: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "    is_coalesced: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Converts a sparse adjacency matrix defined by edge indices and edge\n",
    "    attributes to a :class:`torch.sparse.Tensor` with layout\n",
    "    `torch.sparse_csc`.\n",
    "    See :meth:`~torch_geometric.utils.to_edge_index` for the reverse operation.\n",
    "\n",
    "    Args:\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        edge_attr (Tensor, optional): The edge attributes.\n",
    "            (default: :obj:`None`)\n",
    "        size (int or (int, int), optional): The size of the sparse matrix.\n",
    "            If given as an integer, will create a quadratic sparse matrix.\n",
    "            If set to :obj:`None`, will infer a quadratic sparse matrix based\n",
    "            on :obj:`edge_index.max() + 1`. (default: :obj:`None`)\n",
    "        is_coalesced (bool): If set to :obj:`True`, will assume that\n",
    "            :obj:`edge_index` is already coalesced and thus avoids expensive\n",
    "            computation. (default: :obj:`False`)\n",
    "\n",
    "    :rtype: :class:`torch.sparse.Tensor`\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "        ...                            [1, 0, 2, 1, 3, 2]])\n",
    "        >>> to_torch_csc_tensor(edge_index)\n",
    "        tensor(ccol_indices=tensor([0, 1, 3, 5, 6]),\n",
    "               row_indices=tensor([1, 0, 2, 1, 3, 2]),\n",
    "               values=tensor([1., 1., 1., 1., 1., 1.]),\n",
    "               size=(4, 4), nnz=6, layout=torch.sparse_csc)\n",
    "\n",
    "    \"\"\"\n",
    "    if not torch_geometric.typing.WITH_PT112:\n",
    "        return torch_geometric.typing.MockTorchCSCTensor(\n",
    "            edge_index, edge_attr, size)\n",
    "\n",
    "    if size is None:\n",
    "        size = int(edge_index.max()) + 1\n",
    "    if not isinstance(size, (tuple, list)):\n",
    "        size = (size, size)\n",
    "\n",
    "    if not is_coalesced:\n",
    "        edge_index, edge_attr = coalesce(edge_index, edge_attr, max(size),\n",
    "                                         sort_by_row=False)\n",
    "\n",
    "    if edge_attr is None:\n",
    "        edge_attr = torch.ones(edge_index.size(1), device=edge_index.device)\n",
    "\n",
    "    adj = torch.sparse_csc_tensor(\n",
    "        ccol_indices=index2ptr(edge_index[1], size[1]),\n",
    "        row_indices=edge_index[0],\n",
    "        values=edge_attr,\n",
    "        size=tuple(size) + edge_attr.size()[1:],\n",
    "        device=edge_index.device,\n",
    "    )\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "def to_torch_sparse_tensor(\n",
    "    edge_index: Tensor,\n",
    "    edge_attr: Optional[Tensor] = None,\n",
    "    size: Optional[Union[int, Tuple[int, int]]] = None,\n",
    "    is_coalesced: bool = False,\n",
    "    layout: torch.layout = torch.sparse_coo,\n",
    "):\n",
    "    r\"\"\"Converts a sparse adjacency matrix defined by edge indices and edge\n",
    "    attributes to a :class:`torch.sparse.Tensor` with custom :obj:`layout`.\n",
    "    See :meth:`~torch_geometric.utils.to_edge_index` for the reverse operation.\n",
    "\n",
    "    Args:\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        edge_attr (Tensor, optional): The edge attributes.\n",
    "            (default: :obj:`None`)\n",
    "        size (int or (int, int), optional): The size of the sparse matrix.\n",
    "            If given as an integer, will create a quadratic sparse matrix.\n",
    "            If set to :obj:`None`, will infer a quadratic sparse matrix based\n",
    "            on :obj:`edge_index.max() + 1`. (default: :obj:`None`)\n",
    "        is_coalesced (bool): If set to :obj:`True`, will assume that\n",
    "            :obj:`edge_index` is already coalesced and thus avoids expensive\n",
    "            computation. (default: :obj:`False`)\n",
    "        layout (torch.layout, optional): The layout of the output sparse tensor\n",
    "            (:obj:`torch.sparse_coo`, :obj:`torch.sparse_csr`,\n",
    "            :obj:`torch.sparse_csc`). (default: :obj:`torch.sparse_coo`)\n",
    "\n",
    "    :rtype: :class:`torch.sparse.Tensor`\n",
    "    \"\"\"\n",
    "    if layout == torch.sparse_coo:\n",
    "        return to_torch_coo_tensor(edge_index, edge_attr, size, is_coalesced)\n",
    "    if layout == torch.sparse_csr:\n",
    "        return to_torch_csr_tensor(edge_index, edge_attr, size, is_coalesced)\n",
    "    if torch_geometric.typing.WITH_PT112 and layout == torch.sparse_csc:\n",
    "        return to_torch_csc_tensor(edge_index, edge_attr, size, is_coalesced)\n",
    "\n",
    "    raise ValueError(f\"Unexpected sparse tensor layout (got '{layout}')\")\n",
    "\n",
    "\n",
    "def to_edge_index(adj: Union[Tensor, SparseTensor]) -> Tuple[Tensor, Tensor]:\n",
    "    r\"\"\"Converts a :class:`torch.sparse.Tensor` or a\n",
    "    :class:`torch_sparse.SparseTensor` to edge indices and edge attributes.\n",
    "\n",
    "    Args:\n",
    "        adj (torch.sparse.Tensor or SparseTensor): The adjacency matrix.\n",
    "\n",
    "    :rtype: (:class:`torch.Tensor`, :class:`torch.Tensor`)\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "        ...                            [1, 0, 2, 1, 3, 2]])\n",
    "        >>> adj = to_torch_coo_tensor(edge_index)\n",
    "        >>> to_edge_index(adj)\n",
    "        (tensor([[0, 1, 1, 2, 2, 3],\n",
    "                [1, 0, 2, 1, 3, 2]]),\n",
    "        tensor([1., 1., 1., 1., 1., 1.]))\n",
    "    \"\"\"\n",
    "    if isinstance(adj, SparseTensor):\n",
    "        row, col, value = adj.coo()\n",
    "        if value is None:\n",
    "            value = torch.ones(row.size(0), device=row.device)\n",
    "        return torch.stack([row, col], dim=0).long(), value\n",
    "\n",
    "    if adj.layout == torch.sparse_coo:\n",
    "        return adj.indices().detach().long(), adj.values()\n",
    "\n",
    "    if adj.layout == torch.sparse_csr:\n",
    "        row = ptr2index(adj.crow_indices().detach())\n",
    "        col = adj.col_indices().detach()\n",
    "        return torch.stack([row, col], dim=0).long(), adj.values()\n",
    "\n",
    "    if torch_geometric.typing.WITH_PT112 and adj.layout == torch.sparse_csc:\n",
    "        col = ptr2index(adj.ccol_indices().detach())\n",
    "        row = adj.row_indices().detach()\n",
    "        return torch.stack([row, col], dim=0).long(), adj.values()\n",
    "\n",
    "    raise ValueError(f\"Unexpected sparse tensor layout (got '{adj.layout}')\")\n",
    "\n",
    "\n",
    "# Helper functions ############################################################\n",
    "\n",
    "\n",
    "def get_sparse_diag(\n",
    "    size: int,\n",
    "    fill_value: float = 1.0,\n",
    "    layout: Optional[int] = None,\n",
    "    dtype: Optional[torch.dtype] = None,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> Tensor:\n",
    "    return torch.sparse.spdiags(\n",
    "        torch.full((1, size), fill_value, dtype=dtype, device=device),\n",
    "        offsets=torch.zeros(1, dtype=torch.long, device=device),\n",
    "        shape=(size, size),\n",
    "        layout=layout,\n",
    "    )\n",
    "\n",
    "\n",
    "def set_sparse_value(adj: Tensor, value: Tensor) -> Tensor:\n",
    "    size = adj.size()\n",
    "\n",
    "    if value.dim() > 1:\n",
    "        size = size + value.size()[1:]\n",
    "\n",
    "    if adj.layout == torch.sparse_coo:\n",
    "        return torch.sparse_coo_tensor(\n",
    "            indices=adj.indices(),\n",
    "            values=value,\n",
    "            size=size,\n",
    "            device=value.device,\n",
    "        ).coalesce()\n",
    "\n",
    "    if adj.layout == torch.sparse_csr:\n",
    "        return torch.sparse_csr_tensor(\n",
    "            crow_indices=adj.crow_indices(),\n",
    "            col_indices=adj.col_indices(),\n",
    "            values=value,\n",
    "            size=size,\n",
    "            device=value.device,\n",
    "        )\n",
    "\n",
    "    if torch_geometric.typing.WITH_PT112 and adj.layout == torch.sparse_csc:\n",
    "        return torch.sparse_csc_tensor(\n",
    "            ccol_indices=adj.ccol_indices(),\n",
    "            row_indices=adj.row_indices(),\n",
    "            values=value,\n",
    "            size=size,\n",
    "            device=value.device,\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Unexpected sparse tensor layout (got '{adj.layout}')\")\n",
    "\n",
    "\n",
    "def ptr2index(ptr: Tensor) -> Tensor:\n",
    "    ind = torch.arange(ptr.numel() - 1, dtype=ptr.dtype, device=ptr.device)\n",
    "    return ind.repeat_interleave(ptr[1:] - ptr[:-1])\n",
    "\n",
    "\n",
    "def index2ptr(index: Tensor, size: int) -> Tensor:\n",
    "    return torch._convert_indices_from_coo_to_csr(\n",
    "        index, size, out_int32=index.dtype == torch.int32)\n",
    "\n",
    "\n",
    "def cat(tensors: List[Tensor], dim: Union[int, Tuple[int, int]]) -> Tensor:\n",
    "    # TODO (matthias) We can make this more efficient by directly operating on\n",
    "    # the individual sparse tensor layouts.\n",
    "    assert dim in {0, 1, (0, 1)}\n",
    "\n",
    "    size = [0, 0]\n",
    "    edge_indices = []\n",
    "    edge_attrs = []\n",
    "    for tensor in tensors:\n",
    "        assert is_torch_sparse_tensor(tensor)\n",
    "        edge_index, edge_attr = to_edge_index(tensor)\n",
    "        edge_index = edge_index.clone()\n",
    "\n",
    "        if dim == 0:\n",
    "            edge_index[0] += size[0]\n",
    "            size[0] += tensor.size(0)\n",
    "            size[1] = max(size[1], tensor.size(1))\n",
    "        elif dim == 1:\n",
    "            edge_index[1] += size[1]\n",
    "            size[0] = max(size[0], tensor.size(0))\n",
    "            size[1] += tensor.size(1)\n",
    "        else:\n",
    "            edge_index[0] += size[0]\n",
    "            edge_index[1] += size[1]\n",
    "            size[0] += tensor.size(0)\n",
    "            size[1] += tensor.size(1)\n",
    "\n",
    "        edge_indices.append(edge_index)\n",
    "        edge_attrs.append(edge_attr)\n",
    "\n",
    "    return to_torch_sparse_tensor(\n",
    "        edge_index=torch.cat(edge_indices, dim=1),\n",
    "        edge_attr=torch.cat(edge_attrs, dim=0),\n",
    "        size=size,\n",
    "        is_coalesced=dim == (0, 1),\n",
    "        layout=tensors[0].layout,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cf0d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import torch_geometric.typing\n",
    "from torch_geometric.typing import Adj, SparseTensor\n",
    "\n",
    "# from torch_geometric.typing import torch_sparse\n",
    "# from torch_geometric.utils import scatter\n",
    "# from torch_geometric.utils import is_torch_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "426e0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def spmm(src, other, reduce):\n",
    "    # type: (Tensor, Tensor, str) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def spmm(src, other, reduce):\n",
    "    # type: (SparseTensor, Tensor, str) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def spmm(src: Adj, other: Tensor, reduce: str = \"sum\") -> Tensor:\n",
    "    \"\"\"Matrix product of sparse matrix with dense matrix.\n",
    "\n",
    "    Args:\n",
    "        src (torch.Tensor or torch_sparse.SparseTensor): The input sparse\n",
    "            matrix, either a :pyg:`PyG` :class:`torch_sparse.SparseTensor` or a\n",
    "            :pytorch:`PyTorch` :class:`torch.sparse.Tensor`.\n",
    "        other (torch.Tensor): The input dense matrix.\n",
    "        reduce (str, optional): The reduce operation to use\n",
    "            (:obj:`\"sum\"`, :obj:`\"mean\"`, :obj:`\"min\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"sum\"`)\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    reduce = 'sum' if reduce == 'add' else reduce\n",
    "\n",
    "    if reduce not in ['sum', 'mean', 'min', 'max']:\n",
    "        raise ValueError(f\"`reduce` argument '{reduce}' not supported\")\n",
    "\n",
    "    if isinstance(src, SparseTensor):\n",
    "        if src.nnz() == 0:\n",
    "            return other.new_zeros(src.size(0), other.size(1))\n",
    "\n",
    "        if (torch_geometric.typing.WITH_PT20 and other.dim() == 2\n",
    "                and not src.is_cuda() and not src.requires_grad()):\n",
    "            # Use optimized PyTorch `torch.sparse.mm` path:\n",
    "            csr = src.to_torch_sparse_csr_tensor().to(other.dtype)\n",
    "            return torch.sparse.mm(csr, other, reduce)\n",
    "        return torch_sparse.matmul(src, other, reduce)\n",
    "\n",
    "    if not is_torch_sparse_tensor(src):\n",
    "        raise ValueError(\"`src` must be a `torch_sparse.SparseTensor` \"\n",
    "                         f\"or a `torch.sparse.Tensor` (got {type(src)}).\")\n",
    "\n",
    "    # `torch.sparse.mm` only supports reductions on CPU for PyTorch>=2.0.\n",
    "    # This will currently throw on error for CUDA tensors.\n",
    "    if torch_geometric.typing.WITH_PT20:\n",
    "\n",
    "        if src.is_cuda and (reduce == 'min' or reduce == 'max'):\n",
    "            raise NotImplementedError(f\"`{reduce}` reduction is not yet \"\n",
    "                                      f\"supported for 'torch.sparse.Tensor' \"\n",
    "                                      f\"on device '{src.device}'\")\n",
    "\n",
    "        # Always convert COO to CSR for more efficient processing:\n",
    "        if src.layout == torch.sparse_coo:\n",
    "            warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
    "                          f\"efficient processing. Consider converting your \"\n",
    "                          f\"sparse tensor to CSR format beforehand to avoid \"\n",
    "                          f\"repeated conversion (got '{src.layout}')\")\n",
    "            src = src.to_sparse_csr()\n",
    "\n",
    "        # Warn in case of CSC format without gradient computation:\n",
    "        if src.layout == torch.sparse_csc and not other.requires_grad:\n",
    "            warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
    "                          f\"efficient processing. Consider converting your \"\n",
    "                          f\"sparse tensor to CSR format beforehand to avoid \"\n",
    "                          f\"repeated conversion (got '{src.layout}')\")\n",
    "\n",
    "        # Use the default code path for `sum` reduction (works on CPU/GPU):\n",
    "        if reduce == 'sum':\n",
    "            return torch.sparse.mm(src, other)\n",
    "\n",
    "        # Use the default code path with custom reduction (works on CPU):\n",
    "        if src.layout == torch.sparse_csr and not src.is_cuda:\n",
    "            return torch.sparse.mm(src, other, reduce)\n",
    "\n",
    "        # Simulate `mean` reduction by dividing by degree:\n",
    "        if reduce == 'mean':\n",
    "            if src.layout == torch.sparse_csr:\n",
    "                ptr = src.crow_indices()\n",
    "                deg = ptr[1:] - ptr[:-1]\n",
    "            else:\n",
    "                assert src.layout == torch.sparse_csc\n",
    "                deg = scatter(torch.ones_like(src.values()), src.row_indices(),\n",
    "                              dim=0, dim_size=src.size(0), reduce='sum')\n",
    "\n",
    "            return torch.sparse.mm(src, other) / deg.view(-1, 1).clamp_(min=1)\n",
    "\n",
    "        # TODO The `torch.sparse.mm` code path with the `reduce` argument does\n",
    "        # not yet support CSC :(\n",
    "        if src.layout == torch.sparse_csc:\n",
    "            warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
    "                          f\"efficient processing. Consider converting your \"\n",
    "                          f\"sparse tensor to CSR format beforehand to avoid \"\n",
    "                          f\"repeated conversion (got '{src.layout}')\")\n",
    "            src = src.to_sparse_csr()\n",
    "\n",
    "        return torch.sparse.mm(src, other, reduce)\n",
    "\n",
    "    # pragma: no cover\n",
    "    # PyTorch < 2.0 only supports sparse COO format:\n",
    "    if reduce == 'sum':\n",
    "        return torch.sparse.mm(src, other)\n",
    "    elif reduce == 'mean':\n",
    "        if src.layout == torch.sparse_csr:\n",
    "            ptr = src.crow_indices()\n",
    "            deg = ptr[1:] - ptr[:-1]\n",
    "        elif (torch_geometric.typing.WITH_PT112\n",
    "              and src.layout == torch.sparse_csc):\n",
    "            assert src.layout == torch.sparse_csc\n",
    "            deg = scatter(torch.ones_like(src.values()), src.row_indices(),\n",
    "                          dim=0, dim_size=src.size(0), reduce='sum')\n",
    "        else:\n",
    "            assert src.layout == torch.sparse_coo\n",
    "            src = src.coalesce()\n",
    "            deg = scatter(torch.ones_like(src.values()),\n",
    "                          src.indices()[0], dim=0, dim_size=src.size(0),\n",
    "                          reduce='sum')\n",
    "\n",
    "        return torch.sparse.mm(src, other) / deg.view(-1, 1).clamp_(min=1)\n",
    "\n",
    "    raise ValueError(f\"`{reduce}` reduction is not supported for \"\n",
    "                     f\"'torch.sparse.Tensor' on device '{src.device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3140656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SparseLinear(MessagePassing):\n",
    "    def __init__(self, in_channels: int, out_channels: int, bias: bool = True):\n",
    "        super().__init__(aggr='add')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.weight = Parameter(torch.empty(in_channels, out_channels))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        inits.kaiming_uniform(self.weight, fan=self.in_channels,\n",
    "                              a=math.sqrt(5))\n",
    "        inits.uniform(self.in_channels, self.bias)\n",
    "\n",
    "    @torch.jit._overload_method\n",
    "    def forward(self, edge_index, edge_weight=None):  # noqa\n",
    "        # type: (Tensor, OptTensor) -> Tensor\n",
    "        pass\n",
    "\n",
    "    @torch.jit._overload_method\n",
    "    def forward(self, edge_index, edge_weight=None):  # noqa\n",
    "        # type: (SparseTensor, OptTensor) -> Tensor\n",
    "        pass\n",
    "\n",
    "    def forward(  # noqa\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        # propagate_type: (weight: Tensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, weight=self.weight,\n",
    "                             edge_weight=edge_weight, size=None)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, weight_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "        if edge_weight is None:\n",
    "            return weight_j\n",
    "        else:\n",
    "            return edge_weight.view(-1, 1) * weight_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor,\n",
    "                              weight: Tensor) -> Tensor:\n",
    "        return spmm(adj_t, weight, reduce=self.aggr)\n",
    "\n",
    "\n",
    "class LINKX(torch.nn.Module):\n",
    "    r\"\"\"The LINKX model from the `\"Large Scale Learning on Non-Homophilous\n",
    "    Graphs: New Benchmarks and Strong Simple Methods\"\n",
    "    <https://arxiv.org/abs/2110.14446>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{H}_{\\mathbf{A}} &= \\textrm{MLP}_{\\mathbf{A}}(\\mathbf{A})\n",
    "\n",
    "        \\mathbf{H}_{\\mathbf{X}} &= \\textrm{MLP}_{\\mathbf{X}}(\\mathbf{X})\n",
    "\n",
    "        \\mathbf{Y} &= \\textrm{MLP}_{f} \\left( \\sigma \\left( \\mathbf{W}\n",
    "        [\\mathbf{H}_{\\mathbf{A}}, \\mathbf{H}_{\\mathbf{X}}] +\n",
    "        \\mathbf{H}_{\\mathbf{A}} + \\mathbf{H}_{\\mathbf{X}} \\right) \\right)\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using LINKX, see `examples/linkx.py <https://\n",
    "        github.com/pyg-team/pytorch_geometric/blob/master/examples/linkx.py>`_.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (int): The number of nodes in the graph.\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        hidden_channels (int): Size of each hidden sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_layers (int): Number of layers of :math:`\\textrm{MLP}_{f}`.\n",
    "        num_edge_layers (int, optional): Number of layers of\n",
    "            :math:`\\textrm{MLP}_{\\mathbf{A}}`. (default: :obj:`1`)\n",
    "        num_node_layers (int, optional): Number of layers of\n",
    "            :math:`\\textrm{MLP}_{\\mathbf{X}}`. (default: :obj:`1`)\n",
    "        dropout (float, optional): Dropout probability of each hidden\n",
    "            embedding. (default: :obj:`0.0`)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        num_edge_layers: int = 1,\n",
    "        num_node_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_edge_layers = num_edge_layers\n",
    "\n",
    "        self.edge_lin = SparseLinear(num_nodes, hidden_channels)\n",
    "\n",
    "        if self.num_edge_layers > 1:\n",
    "            self.edge_norm = BatchNorm1d(hidden_channels)\n",
    "            channels = [hidden_channels] * num_edge_layers\n",
    "            self.edge_mlp = MLP(channels, dropout=0., act_first=True)\n",
    "        else:\n",
    "            self.edge_norm = None\n",
    "            self.edge_mlp = None\n",
    "\n",
    "        channels = [in_channels] + [hidden_channels] * num_node_layers\n",
    "        self.node_mlp = MLP(channels, dropout=0., act_first=True)\n",
    "\n",
    "        self.cat_lin1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.cat_lin2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        channels = [hidden_channels] * num_layers + [out_channels]\n",
    "        self.final_mlp = MLP(channels, dropout=dropout, act_first=True)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        self.edge_lin.reset_parameters()\n",
    "        if self.edge_norm is not None:\n",
    "            self.edge_norm.reset_parameters()\n",
    "        if self.edge_mlp is not None:\n",
    "            self.edge_mlp.reset_parameters()\n",
    "        self.node_mlp.reset_parameters()\n",
    "        self.cat_lin1.reset_parameters()\n",
    "        self.cat_lin2.reset_parameters()\n",
    "        self.final_mlp.reset_parameters()\n",
    "\n",
    "    @torch.jit._overload_method\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # type: (OptTensor, SparseTensor, OptTensor) -> Tensor\n",
    "        pass\n",
    "\n",
    "    @torch.jit._overload_method\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # type: (OptTensor, Tensor, OptTensor) -> Tensor\n",
    "        pass\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: OptTensor,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        out = self.edge_lin(edge_index, edge_weight)\n",
    "\n",
    "        if self.edge_norm is not None and self.edge_mlp is not None:\n",
    "            out = out.relu_()\n",
    "            out = self.edge_norm(out)\n",
    "            out = self.edge_mlp(out)\n",
    "\n",
    "        out = out + self.cat_lin1(out)\n",
    "\n",
    "        if x is not None:\n",
    "            x = self.node_mlp(x)\n",
    "            out = out + x\n",
    "            out = out + self.cat_lin2(x)\n",
    "\n",
    "        return self.final_mlp(out.relu_())\n",
    "\n",
    "    def jittable(self, use_sparse_tensor: bool = False) -> torch.nn.Module:\n",
    "        class EdgeIndexJittable(torch.nn.Module):\n",
    "            def __init__(self, child: LINKX):\n",
    "                super().__init__()\n",
    "                self.child = child\n",
    "\n",
    "            def reset_parameters(self):\n",
    "                self.child.reset_parameters()\n",
    "\n",
    "            def forward(\n",
    "                self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                edge_weight: OptTensor = None,\n",
    "            ) -> Tensor:\n",
    "                return self.child(x, edge_index, edge_weight)\n",
    "\n",
    "            def __repr__(self) -> str:\n",
    "                return str(self.child)\n",
    "\n",
    "        class SparseTensorJittable(torch.nn.Module):\n",
    "            def __init__(self, child: LINKX):\n",
    "                super().__init__()\n",
    "                self.child = child\n",
    "\n",
    "            def reset_parameters(self):\n",
    "                self.child.reset_parameters()\n",
    "\n",
    "            def forward(\n",
    "                self,\n",
    "                x: Tensor,\n",
    "                edge_index: SparseTensor,\n",
    "                edge_weight: OptTensor = None,\n",
    "            ):\n",
    "                return self.child(x, edge_index, edge_weight)\n",
    "\n",
    "            def __repr__(self) -> str:\n",
    "                return str(self.child)\n",
    "\n",
    "        if self.edge_lin.jittable is not None:\n",
    "            self.edge_lin = self.edge_lin.jittable()\n",
    "\n",
    "        if use_sparse_tensor:\n",
    "            return SparseTensorJittable(self)\n",
    "        return EdgeIndexJittable(self)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(num_nodes={self.num_nodes}, '\n",
    "                f'in_channels={self.in_channels}, '\n",
    "                f'out_channels={self.out_channels})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f6cdb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ca243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
